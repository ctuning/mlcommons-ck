[
  {
    "Accuracy": 90.8791726326272,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Dreambrook_Team/results/0e7e43cc4195-reference-gpu-pytorch-cu124/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dreambrook_Team",
    "Platform": "0e7e43cc4195-reference-gpu-pytorch-cu124",
    "Result": 279.352,
    "Scenario": "Offline",
    "SystemName": "0e7e43cc4195",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "GRID A100X-20C",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "4e776a5612ce4f1f",
    "errors": 0,
    "framework": "pytorch",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.1.112-1.el9.elrepo.x86_64-glibc2.35)",
    "system.accelerator_frequency": "1410000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "19.9959716796875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "GRID A100X-20C",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "266G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.1.112-1.el9.elrepo.x86_64-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "Dreambrook_Team",
    "system.sw_notes": "Automated by MLCommons CM v3.2.2. ",
    "system.system_name": "0e7e43cc4195",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "0e7e43cc4195-reference-gpu-pytorch-cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/Dreambrook_Team/results/0e7e43cc4195-reference-gpu-pytorch-cu124/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/Dreambrook_Team/systems/0e7e43cc4195-reference-gpu-pytorch-cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87601905331469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Dreambrook_Team/results/666dfb9811e4-reference-gpu-pytorch-cu124/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dreambrook_Team",
    "Platform": "666dfb9811e4-reference-gpu-pytorch-cu124",
    "Result": 85.4467,
    "Scenario": "Offline",
    "SystemName": "666dfb9811e4",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "GRID A100X-20C",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "a895bba367b644be",
    "errors": 0,
    "framework": "pytorch",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.1.112-1.el9.elrepo.x86_64-glibc2.35)",
    "system.accelerator_frequency": "1410000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "19.9959716796875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "GRID A100X-20C",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "266G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.1.112-1.el9.elrepo.x86_64-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "Dreambrook_Team",
    "system.sw_notes": "Automated by MLCommons CM v3.2.2. ",
    "system.system_name": "666dfb9811e4",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "666dfb9811e4-reference-gpu-pytorch-cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/Dreambrook_Team/results/666dfb9811e4-reference-gpu-pytorch-cu124/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/Dreambrook_Team/systems/666dfb9811e4-reference-gpu-pytorch-cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Dreambrook_Team/results/a65eca5827dc-reference-cpu-pytorch_v2.4.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dreambrook_Team",
    "Platform": "a65eca5827dc-reference-cpu-pytorch_v2.4.1-default_config",
    "Result": 3.19276,
    "Scenario": "Offline",
    "SystemName": "a65eca5827dc",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "6ebf823f8877405f",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 32,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.1.112-1.el9.elrepo.x86_64-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "125G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1 MiB (32 instances), L1i cache: 1 MiB (32 instances), L2 cache: 16 MiB (32 instances), L3 cache: 1 GiB (32 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "32",
    "system.host_storage_capacity": "333G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.1.112-1.el9.elrepo.x86_64-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "Dreambrook_Team",
    "system.sw_notes": "Automated by MLCommons CM v3.2.1. ",
    "system.system_name": "a65eca5827dc",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "a65eca5827dc-reference-cpu-pytorch_v2.4.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/Dreambrook_Team/results/a65eca5827dc-reference-cpu-pytorch_v2.4.1-default_config/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/Dreambrook_Team/systems/a65eca5827dc-reference-cpu-pytorch_v2.4.1-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.569556221365929,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/05c9134fd82d-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "05c9134fd82d-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.13939,
    "Scenario": "Offline",
    "SystemName": "05c9134fd82d",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "9df4c3c5e55d414e",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "05c9134fd82d",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "05c9134fd82d-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/05c9134fd82d-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/05c9134fd82d-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/13fce262fb79-reference-gpu-pytorch_v2.4.1-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "13fce262fb79-reference-gpu-pytorch_v2.4.1-scc24-base",
    "Result": 0.375843,
    "Scenario": "Offline",
    "SystemName": "13fce262fb79",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "73ae4983ca524a5c",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "13fce262fb79",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "13fce262fb79-reference-gpu-pytorch_v2.4.1-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/13fce262fb79-reference-gpu-pytorch_v2.4.1-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/13fce262fb79-reference-gpu-pytorch_v2.4.1-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.78126573562622,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/2c11da85618f-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "2c11da85618f-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.14155,
    "Scenario": "Offline",
    "SystemName": "2c11da85618f",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "3094453d1ed240f3",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "2c11da85618f",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "2c11da85618f-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/2c11da85618f-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/2c11da85618f-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/2ea99d9fdd48-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "2ea99d9fdd48-reference-gpu-pytorch_v2.4.1-scc24-base_cu124",
    "Result": 0.176157,
    "Scenario": "Offline",
    "SystemName": "2ea99d9fdd48",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "f2d55ec88c9349dc",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "2ea99d9fdd48",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "2ea99d9fdd48-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/2ea99d9fdd48-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/2ea99d9fdd48-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/3b07702db56d-reference-gpu-pytorch_v2.4.1-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "3b07702db56d-reference-gpu-pytorch_v2.4.1-scc24-base",
    "Result": 0.374549,
    "Scenario": "Offline",
    "SystemName": "3b07702db56d",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "d583bc4388584c3d",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "3b07702db56d",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "3b07702db56d-reference-gpu-pytorch_v2.4.1-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/3b07702db56d-reference-gpu-pytorch_v2.4.1-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/3b07702db56d-reference-gpu-pytorch_v2.4.1-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.649463787674904,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/3c7f9df24e39-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "3c7f9df24e39-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.14095,
    "Scenario": "Offline",
    "SystemName": "3c7f9df24e39",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "9d22794ae0024f69",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "3c7f9df24e39",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "3c7f9df24e39-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/3c7f9df24e39-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/3c7f9df24e39-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/41485dfb4f36-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "41485dfb4f36-reference-gpu-pytorch_v2.4.1-scc24-base_cu124",
    "Result": 0.375138,
    "Scenario": "Offline",
    "SystemName": "41485dfb4f36",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "7627bf12f8be4abd",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "41485dfb4f36",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "41485dfb4f36-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/41485dfb4f36-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/41485dfb4f36-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/415f0692c960-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "415f0692c960-reference-gpu-pytorch_v2.4.1-scc24-base_cu124",
    "Result": 0.375643,
    "Scenario": "Offline",
    "SystemName": "415f0692c960",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "e92d5b7b8f14495c",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "415f0692c960",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "415f0692c960-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/415f0692c960-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/415f0692c960-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.586050063371658,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/48ed6105bd85-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "48ed6105bd85-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.13598,
    "Scenario": "Offline",
    "SystemName": "48ed6105bd85",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "82be4b0355ed4ba1",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.6. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520.000000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.6. ",
    "system.system_name": "48ed6105bd85",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "48ed6105bd85-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/48ed6105bd85-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/48ed6105bd85-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.586050063371658,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/48ed6105bd85-nvidia-gpu-TensorRT-scc24-main/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "48ed6105bd85-nvidia-gpu-TensorRT-scc24-main",
    "Result": 1.13292,
    "Scenario": "Offline",
    "SystemName": "48ed6105bd85",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "d768e9e77e2c4ac6",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.6. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520.000000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.6. ",
    "system.system_name": "48ed6105bd85",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "48ed6105bd85-nvidia-gpu-TensorRT-scc24-main.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/48ed6105bd85-nvidia-gpu-TensorRT-scc24-main/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/48ed6105bd85-nvidia-gpu-TensorRT-scc24-main.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.236237794160843,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/48ed6105bd85-reference-gpu-pytorch_v2.1.0a0-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "48ed6105bd85-reference-gpu-pytorch_v2.1.0a0-scc24-base",
    "Result": 0.373636,
    "Scenario": "Offline",
    "SystemName": "48ed6105bd85",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "20da4cceb72a4a0f",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.6. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520.000000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.6. ",
    "system.system_name": "48ed6105bd85",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "48ed6105bd85-reference-gpu-pytorch_v2.1.0a0-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/48ed6105bd85-reference-gpu-pytorch_v2.1.0a0-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/48ed6105bd85-reference-gpu-pytorch_v2.1.0a0-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/53f27922dbd5-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "53f27922dbd5-reference-gpu-pytorch_v2.4.1-scc24-base_cu124",
    "Result": 0.376164,
    "Scenario": "Offline",
    "SystemName": "53f27922dbd5",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "c72ccda8ce1f4c6b",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "53f27922dbd5",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "53f27922dbd5-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/53f27922dbd5-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/53f27922dbd5-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/6e3eecbcf50d-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "6e3eecbcf50d-reference-gpu-pytorch_v2.4.1-scc24-base_cu124",
    "Result": 0.376963,
    "Scenario": "Offline",
    "SystemName": "6e3eecbcf50d",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "d03384980a6d4fa3",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "6e3eecbcf50d",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "6e3eecbcf50d-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/6e3eecbcf50d-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/6e3eecbcf50d-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.180260419845581,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/705b75a6e915-reference-gpu-pytorch_v2.5.0-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "705b75a6e915-reference-gpu-pytorch_v2.5.0-scc24-base_cu124",
    "Result": 0.369758,
    "Scenario": "Offline",
    "SystemName": "705b75a6e915",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "9c24f1baa9d14ac3",
    "errors": 0,
    "framework": "pytorch v2.5.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.5. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.5.0",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v3.2.5. ",
    "system.system_name": "705b75a6e915",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "705b75a6e915-reference-gpu-pytorch_v2.5.0-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/705b75a6e915-reference-gpu-pytorch_v2.5.0-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/705b75a6e915-reference-gpu-pytorch_v2.5.0-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/814f0bc3f38f-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "814f0bc3f38f-reference-gpu-pytorch_v2.4.1-scc24-base_cu124",
    "Result": 0.376351,
    "Scenario": "Offline",
    "SystemName": "814f0bc3f38f",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "aab5e1ad3b304b08",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "814f0bc3f38f",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "814f0bc3f38f-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/814f0bc3f38f-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/814f0bc3f38f-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.683020070195198,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/87891b324cb3-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "87891b324cb3-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.1417,
    "Scenario": "Offline",
    "SystemName": "87891b324cb3",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "b81db987ec564300",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "87891b324cb3",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "87891b324cb3-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/87891b324cb3-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/87891b324cb3-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.661652073264122,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/897760fb5a09-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "897760fb5a09-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.18002,
    "Scenario": "Offline",
    "SystemName": "897760fb5a09",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "982643c87b0645b2",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.4. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v3.2.4. ",
    "system.system_name": "897760fb5a09",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "897760fb5a09-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/897760fb5a09-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/897760fb5a09-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.478164181113243,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/97c3ec750d0e-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "97c3ec750d0e-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.14052,
    "Scenario": "Offline",
    "SystemName": "97c3ec750d0e",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "8516973ebf5f42c1",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "97c3ec750d0e",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "97c3ec750d0e-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/97c3ec750d0e-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/97c3ec750d0e-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/a2437f3a512c-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "a2437f3a512c-reference-gpu-pytorch_v2.4.1-scc24-base_cu124",
    "Result": 0.375614,
    "Scenario": "Offline",
    "SystemName": "a2437f3a512c",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "8a5ca8779fed4205",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "a2437f3a512c",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "a2437f3a512c-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/a2437f3a512c-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/a2437f3a512c-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/a51568200dc1-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "a51568200dc1-reference-gpu-pytorch_v2.4.1-scc24-base_cu124",
    "Result": 0.375287,
    "Scenario": "Offline",
    "SystemName": "a51568200dc1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "3397ebd2c4a24ca0",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "a51568200dc1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "a51568200dc1-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/a51568200dc1-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/a51568200dc1-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.444628179073334,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/ad34f02bda42-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "ad34f02bda42-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.17889,
    "Scenario": "Offline",
    "SystemName": "ad34f02bda42",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "30e5762ebff54e29",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.5. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v3.2.5. ",
    "system.system_name": "ad34f02bda42",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "ad34f02bda42-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/ad34f02bda42-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/ad34f02bda42-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/b1fcd0c956f2-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "b1fcd0c956f2-reference-gpu-pytorch_v2.4.1-scc24-base_cu124",
    "Result": 0.377055,
    "Scenario": "Offline",
    "SystemName": "b1fcd0c956f2",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "413ce259bfc840ec",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "b1fcd0c956f2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "b1fcd0c956f2-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/b1fcd0c956f2-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/b1fcd0c956f2-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.180260419845581,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/b5c0891ab663-reference-gpu-pytorch_v2.5.0-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "b5c0891ab663-reference-gpu-pytorch_v2.5.0-scc24-base_cu124",
    "Result": 0.369148,
    "Scenario": "Offline",
    "SystemName": "b5c0891ab663",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "a19a9c4d3a0347ad",
    "errors": 0,
    "framework": "pytorch v2.5.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.5. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.5.0",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v3.2.5. ",
    "system.system_name": "b5c0891ab663",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "b5c0891ab663-reference-gpu-pytorch_v2.5.0-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/b5c0891ab663-reference-gpu-pytorch_v2.5.0-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/b5c0891ab663-reference-gpu-pytorch_v2.5.0-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.180260419845581,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/ba096989170c-reference-gpu-pytorch_v2.5.0-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "ba096989170c-reference-gpu-pytorch_v2.5.0-scc24-base_cu124",
    "Result": 0.369623,
    "Scenario": "Offline",
    "SystemName": "ba096989170c",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "f5d2ae86412f4e36",
    "errors": 0,
    "framework": "pytorch v2.5.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.4. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.5.0",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v3.2.4. ",
    "system.system_name": "ba096989170c",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "ba096989170c-reference-gpu-pytorch_v2.5.0-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/ba096989170c-reference-gpu-pytorch_v2.5.0-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/ba096989170c-reference-gpu-pytorch_v2.5.0-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.425002038478851,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/c62ef8beba30-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "c62ef8beba30-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.18075,
    "Scenario": "Offline",
    "SystemName": "c62ef8beba30",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "867d861b518e4d3a",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.5. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v3.2.5. ",
    "system.system_name": "c62ef8beba30",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "c62ef8beba30-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/c62ef8beba30-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/c62ef8beba30-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.615820929408073,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/c933bf5bd417-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "c933bf5bd417-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.13966,
    "Scenario": "Offline",
    "SystemName": "c933bf5bd417",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "38dcce3447714423",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "c933bf5bd417",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "c933bf5bd417-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/c933bf5bd417-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/c933bf5bd417-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.476153820753098,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/d714f54675c3-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "d714f54675c3-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.13923,
    "Scenario": "Offline",
    "SystemName": "d714f54675c3",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "9f56eb762b2b4113",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "d714f54675c3",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "d714f54675c3-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/d714f54675c3-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/d714f54675c3-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/e44bdf36b499-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "e44bdf36b499-reference-gpu-pytorch_v2.4.1-scc24-base_cu124",
    "Result": 0.37689,
    "Scenario": "Offline",
    "SystemName": "e44bdf36b499",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "e0cf4e178bfe42ad",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "e44bdf36b499",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "e44bdf36b499-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/e44bdf36b499-reference-gpu-pytorch_v2.4.1-scc24-base_cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/e44bdf36b499-reference-gpu-pytorch_v2.4.1-scc24-base_cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.617164582014084,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/e8dbfdd7ca14-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "e8dbfdd7ca14-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.13976,
    "Scenario": "Offline",
    "SystemName": "e8dbfdd7ca14",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "b3a48d20855b409e",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB, L1i cache: 768 KiB, L2 cache: 48 MiB, L3 cache: 45 MiB",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "7.0T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "e8dbfdd7ca14",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "e8dbfdd7ca14-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/e8dbfdd7ca14-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/e8dbfdd7ca14-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/f9ac88850adc-reference-gpu-pytorch_v2.4.1-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "f9ac88850adc-reference-gpu-pytorch_v2.4.1-scc24-base",
    "Result": 0.376944,
    "Scenario": "Offline",
    "SystemName": "f9ac88850adc",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "2d8868139d4842a2",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "f9ac88850adc",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "f9ac88850adc-reference-gpu-pytorch_v2.4.1-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/f9ac88850adc-reference-gpu-pytorch_v2.4.1-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/f9ac88850adc-reference-gpu-pytorch_v2.4.1-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/gh_action-reference-gpu-pytorch_v2.4.1-cu124/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "gh_action-reference-gpu-pytorch_v2.4.1-cu124",
    "Result": 0.345763,
    "Scenario": "Offline",
    "SystemName": "gh_action",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "2b026332444547f8",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.9. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.9. ",
    "system.system_name": "gh_action",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "gh_action-reference-gpu-pytorch_v2.4.1-cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/gh_action-reference-gpu-pytorch_v2.4.1-cu124/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/gh_action-reference-gpu-pytorch_v2.4.1-cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": "None",
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/gh_action-reference-gpu-pytorch_v2.4.1-default_config/gptj-99/offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "MLCommons",
    "Platform": "gh_action-reference-gpu-pytorch_v2.4.1-default_config",
    "Result": 52.9478,
    "Scenario": "Offline",
    "SystemName": "gh_action",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "d44bc85edeeb4429",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.4. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.4. ",
    "system.system_name": "gh_action",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "gh_action-reference-gpu-pytorch_v2.4.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/gh_action-reference-gpu-pytorch_v2.4.1-default_config/gptj-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/gh_action-reference-gpu-pytorch_v2.4.1-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.18544016778469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/MLCommons/results/gh_action-reference-gpu-pytorch_v2.4.1-default_config/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "MLCommons",
    "Platform": "gh_action-reference-gpu-pytorch_v2.4.1-default_config",
    "Result": 0.345721,
    "Scenario": "Offline",
    "SystemName": "gh_action",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "b3ea50ee5eba4042",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.4. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.accelerator_frequency": "2520000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "192G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "MLCommons",
    "system.sw_notes": "Automated by MLCommons CM v2.3.4. ",
    "system.system_name": "gh_action",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "gh_action-reference-gpu-pytorch_v2.4.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/results/gh_action-reference-gpu-pytorch_v2.4.1-default_config/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/MLCommons/systems/gh_action-reference-gpu-pytorch_v2.4.1-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.704176977276802,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NTUHPC/results/8297ae0eca20-nvidia-gpu-TensorRT-scc24-main/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NTUHPC",
    "Platform": "8297ae0eca20-nvidia-gpu-TensorRT-scc24-main",
    "Result": 2.66695,
    "Scenario": "Offline",
    "SystemName": "8297ae0eca20",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 PCIe",
    "accelerators_per_node": 4,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "1bb5f5cc417d4383",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.4.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.5.0-27-generic-glibc2.31)",
    "system.accelerator_frequency": "1755000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "79.09674072265625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA H100 PCIe",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "1.5T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 6 MiB, L1i cache: 6 MiB, L2 cache: 192 MiB, L3 cache: 768 MiB",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "3707.8120",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4.7T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.5.0-27-generic-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "NTUHPC",
    "system.sw_notes": "Automated by MLCommons CM v2.4.0. ",
    "system.system_name": "8297ae0eca20",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "8297ae0eca20-nvidia-gpu-TensorRT-scc24-main.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/NTUHPC/results/8297ae0eca20-nvidia-gpu-TensorRT-scc24-main/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/NTUHPC/systems/8297ae0eca20-nvidia-gpu-TensorRT-scc24-main.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 88.74428571428572,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc102/results/scc102_gpu0.novalocal-reference-gpu-pytorch-cu118/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc102",
    "Platform": "scc102_gpu0.novalocal-reference-gpu-pytorch-cu118",
    "Result": 46.2795,
    "Scenario": "Offline",
    "SystemName": "scc102_gpu0.novalocal",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "GRID A100X-20C",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "ecf598fac9c447bb",
    "errors": 0,
    "framework": "pytorch",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.8. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "1410000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "19.9959716796875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "GRID A100X-20C",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "107G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.9.18, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "scc102",
    "system.sw_notes": "Automated by MLCommons CM v3.2.8. ",
    "system.system_name": "scc102_gpu0.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc102_gpu0.novalocal-reference-gpu-pytorch-cu118.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc102/results/scc102_gpu0.novalocal-reference-gpu-pytorch-cu118/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc102/systems/scc102_gpu0.novalocal-reference-gpu-pytorch-cu118.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc104-ZJUSCT/results/scc104_cpu1.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc104-ZJUSCT",
    "Platform": "scc104_cpu1.novalocal-reference-cpu-pytorch_v2.5.0-default_config",
    "Result": 2.35587,
    "Scenario": "Offline",
    "SystemName": "scc104_cpu1.novalocal",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "27c4fbd52b1141db",
    "errors": 0,
    "framework": "pytorch v2.5.0",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 32,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.4. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.5.0",
    "system.host_memory_capacity": "125G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1 MiB (32 instances), L1i cache: 1 MiB (32 instances), L2 cache: 16 MiB (32 instances), L3 cache: 1 GiB (32 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "32",
    "system.host_storage_capacity": "158G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.10.15, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "scc104-ZJUSCT",
    "system.sw_notes": "Automated by MLCommons CM v3.2.4. ",
    "system.system_name": "scc104_cpu1.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc104_cpu1.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc104-ZJUSCT/results/scc104_cpu1.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc104-ZJUSCT/systems/scc104_cpu1.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc104-ZJUSCT/results/scc104_gpu0.novalocal-reference-gpu-pytorch-cu122/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc104-ZJUSCT",
    "Platform": "scc104_gpu0.novalocal-reference-gpu-pytorch-cu122",
    "Result": 47.9697,
    "Scenario": "Offline",
    "SystemName": "scc104_gpu0.novalocal",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "GRID A100X-20C",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "ccfac19ad0d94032",
    "errors": 0,
    "framework": "pytorch",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.4. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "1410000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "19.9959716796875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "GRID A100X-20C",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "107G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.10.15, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "scc104-ZJUSCT",
    "system.sw_notes": "Automated by MLCommons CM v3.2.4. ",
    "system.system_name": "scc104_gpu0.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc104_gpu0.novalocal-reference-gpu-pytorch-cu122.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc104-ZJUSCT/results/scc104_gpu0.novalocal-reference-gpu-pytorch-cu122/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc104-ZJUSCT/systems/scc104_gpu0.novalocal-reference-gpu-pytorch-cu122.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc107/results/mlperf2-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc107",
    "Platform": "mlperf2-reference-cpu-pytorch_v2.5.0-default_config",
    "Result": 5.42229,
    "Scenario": "Offline",
    "SystemName": "mlperf2",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "6667fb89aba74218",
    "errors": 0,
    "framework": "pytorch v2.5.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "AMD EPYC 7B13",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.7. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.8.0-1016-gcp-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.5.0",
    "system.host_memory_capacity": "112G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 896 KiB (28 instances), L1i cache: 896 KiB (28 instances), L2 cache: 14 MiB (28 instances), L3 cache: 224 MiB (7 instances)",
    "system.host_processor_core_count": "28",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7B13",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "185G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.8.0-1016-gcp-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "scc107",
    "system.sw_notes": "Automated by MLCommons CM v3.2.7. ",
    "system.system_name": "mlperf2",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "mlperf2-reference-cpu-pytorch_v2.5.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc107/results/mlperf2-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc107/systems/mlperf2-reference-cpu-pytorch_v2.5.0-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.80558974686677,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc112/results/scc112_cpu2.novalocal-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "scc112",
    "Platform": "scc112_cpu2.novalocal-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 99.173,
    "Scenario": "Offline",
    "SystemName": "scc112_cpu2.novalocal",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "d6e0c80a3fb94349",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 32,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.5. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "125G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1 MiB (32 instances), L1i cache: 1 MiB (32 instances), L2 cache: 16 MiB (32 instances), L3 cache: 1 GiB (32 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "32",
    "system.host_storage_capacity": "158G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.9.18, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "scc112",
    "system.sw_notes": "Automated by MLCommons CM v3.2.5. ",
    "system.system_name": "scc112_cpu2.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc112_cpu2.novalocal-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc112/results/scc112_cpu2.novalocal-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-base_quant-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc112/systems/scc112_cpu2.novalocal-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.81268530031994,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc122/results/scc122_cpu0.novalocal-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "scc122",
    "Platform": "scc122_cpu0.novalocal-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 16.1242,
    "Scenario": "Offline",
    "SystemName": "scc122_cpu0.novalocal",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "aa706b40eebd44fe",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 32,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.7. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "125G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1 MiB (32 instances), L1i cache: 1 MiB (32 instances), L2 cache: 16 MiB (32 instances), L3 cache: 1 GiB (32 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "32",
    "system.host_storage_capacity": "146G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.9.18, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "scc122",
    "system.sw_notes": "Automated by MLCommons CM v3.2.7. ",
    "system.system_name": "scc122_cpu0.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc122_cpu0.novalocal-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc122/results/scc122_cpu0.novalocal-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-base_quant-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc122/systems/scc122_cpu0.novalocal-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87601905331469,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc123-Shanxi_University/results/b7828419c93b-reference-gpu-pytorch-cu124/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc123-Shanxi_University",
    "Platform": "b7828419c93b-reference-gpu-pytorch-cu124",
    "Result": 83.4708,
    "Scenario": "Offline",
    "SystemName": "b7828419c93b",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "GRID A100X-20C",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "07772239c27b4082",
    "errors": 0,
    "framework": "pytorch",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.6. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.35)",
    "system.accelerator_frequency": "1410000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "19.9959716796875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "GRID A100X-20C",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "234G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "scc123-Shanxi_University",
    "system.sw_notes": "Automated by MLCommons CM v3.2.6. ",
    "system.system_name": "b7828419c93b",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "b7828419c93b-reference-gpu-pytorch-cu124.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc123-Shanxi_University/results/b7828419c93b-reference-gpu-pytorch-cu124/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc123-Shanxi_University/systems/b7828419c93b-reference-gpu-pytorch-cu124.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc123-Shanxi_University/results/scc123_cpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc123-Shanxi_University",
    "Platform": "scc123_cpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config",
    "Result": 3.26888,
    "Scenario": "Offline",
    "SystemName": "scc123_cpu0.novalocal",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "2c6d73263e444f08",
    "errors": 0,
    "framework": "pytorch v2.5.0",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 32,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.6. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.5.0",
    "system.host_memory_capacity": "125G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1 MiB (32 instances), L1i cache: 1 MiB (32 instances), L2 cache: 16 MiB (32 instances), L3 cache: 1 GiB (32 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "32",
    "system.host_storage_capacity": "158G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.9.18, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "scc123-Shanxi_University",
    "system.sw_notes": "Automated by MLCommons CM v3.2.6. ",
    "system.system_name": "scc123_cpu0.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc123_cpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc123-Shanxi_University/results/scc123_cpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc123-Shanxi_University/systems/scc123_cpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc131/results/scc131_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc131",
    "Platform": "scc131_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config",
    "Result": 1.89828,
    "Scenario": "Offline",
    "SystemName": "scc131_gpu0.novalocal",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "GRID A100X-20C",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "d6e417c030aa4fa7",
    "errors": 0,
    "framework": "pytorch",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.3. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "1410000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "19.9959716796875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "GRID A100X-20C",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "107G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.11.0, LLVM-16.0.3",
    "system.status": "available",
    "system.submitter": "scc131",
    "system.sw_notes": "Automated by MLCommons CM v3.2.3. ",
    "system.system_name": "scc131_gpu0.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc131_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc131/results/scc131_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc131/systems/scc131_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc131/results/scc131_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc131",
    "Platform": "scc131_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config",
    "Result": 579.913177,
    "Scenario": "SingleStream",
    "SystemName": "scc131_gpu0.novalocal",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "GRID A100X-20C",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "372115d098d24d34",
    "errors": 0,
    "framework": "pytorch",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.3. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "1410000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "19.9959716796875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "GRID A100X-20C",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "107G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.11.0, LLVM-16.0.3",
    "system.status": "available",
    "system.submitter": "scc131",
    "system.sw_notes": "Automated by MLCommons CM v3.2.3. ",
    "system.system_name": "scc131_gpu0.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc131_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc131/results/scc131_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/singlestream",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc131/systems/scc131_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc131/results/scc131_gpu0.novalocal-reference-gpu-pytorch-cu118/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc131",
    "Platform": "scc131_gpu0.novalocal-reference-gpu-pytorch-cu118",
    "Result": 47.4872,
    "Scenario": "Offline",
    "SystemName": "scc131_gpu0.novalocal",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "GRID A100X-20C",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "306772d85b15446d",
    "errors": 0,
    "framework": "pytorch",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.3. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "1410000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "19.9959716796875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "GRID A100X-20C",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "107G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.11.0, LLVM-16.0.3",
    "system.status": "available",
    "system.submitter": "scc131",
    "system.sw_notes": "Automated by MLCommons CM v3.2.3. ",
    "system.system_name": "scc131_gpu0.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc131_gpu0.novalocal-reference-gpu-pytorch-cu118.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc131/results/scc131_gpu0.novalocal-reference-gpu-pytorch-cu118/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc131/systems/scc131_gpu0.novalocal-reference-gpu-pytorch-cu118.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc131/results/scc131_gpu0.novalocal-reference-gpu-pytorch-cu118/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc131",
    "Platform": "scc131_gpu0.novalocal-reference-gpu-pytorch-cu118",
    "Result": 20.794328,
    "Scenario": "SingleStream",
    "SystemName": "scc131_gpu0.novalocal",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "GRID A100X-20C",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "c8e140aca6fb464a",
    "errors": 0,
    "framework": "pytorch",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.3. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "1410000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "19.9959716796875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "GRID A100X-20C",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "107G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.11.0, LLVM-16.0.3",
    "system.status": "available",
    "system.submitter": "scc131",
    "system.sw_notes": "Automated by MLCommons CM v3.2.3. ",
    "system.system_name": "scc131_gpu0.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc131_gpu0.novalocal-reference-gpu-pytorch-cu118.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc131/results/scc131_gpu0.novalocal-reference-gpu-pytorch-cu118/bert-99/singlestream",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc131/systems/scc131_gpu0.novalocal-reference-gpu-pytorch-cu118.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc132/results/scc132_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc132",
    "Platform": "scc132_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config",
    "Result": 1.96994,
    "Scenario": "Offline",
    "SystemName": "scc132_gpu0.novalocal",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "74f3d8b41eb3457f",
    "errors": 0,
    "framework": "pytorch v2.5.0",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.6. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.5.0",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "107G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.11.7, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "scc132",
    "system.sw_notes": "Automated by MLCommons CM v3.2.6. ",
    "system.system_name": "scc132_gpu0.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc132_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc132/results/scc132_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc132/systems/scc132_gpu0.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc135/results/scc135_cpu1.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc135",
    "Platform": "scc135_cpu1.novalocal-reference-cpu-pytorch_v2.5.0-default_config",
    "Result": 3.35681,
    "Scenario": "Offline",
    "SystemName": "scc135_cpu1.novalocal",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "e709a7c6d5dd4d91",
    "errors": 0,
    "framework": "pytorch v2.5.0",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 32,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.7. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.112-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.5.0",
    "system.host_memory_capacity": "125G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1 MiB (32 instances), L1i cache: 1 MiB (32 instances), L2 cache: 16 MiB (32 instances), L3 cache: 1 GiB (32 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "32",
    "system.host_storage_capacity": "158G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.112-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.9.18, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "scc135",
    "system.sw_notes": "Automated by MLCommons CM v3.2.7. ",
    "system.system_name": "scc135_cpu1.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc135_cpu1.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc135/results/scc135_cpu1.novalocal-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc135/systems/scc135_cpu1.novalocal-reference-cpu-pytorch_v2.5.0-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/scc135/results/scc135_gpu0.novalocal-reference-gpu-pytorch-cu118/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "scc135",
    "Platform": "scc135_gpu0.novalocal-reference-gpu-pytorch-cu118",
    "Result": 48.0956,
    "Scenario": "Offline",
    "SystemName": "scc135_gpu0.novalocal",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "GRID A100X-20C",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "e3f7dacb947a4b75",
    "errors": 0,
    "framework": "pytorch",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.7. ",
    "number_of_nodes": 1,
    "operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.accelerator_frequency": "1410000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "19.9959716796875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "GRID A100X-20C",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "107G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky 9.4 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.34)",
    "system.other_software_stack": "Python: 3.9.18, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "scc135",
    "system.sw_notes": "Automated by MLCommons CM v3.2.7. ",
    "system.system_name": "scc135_gpu0.novalocal",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "scc135_gpu0.novalocal-reference-gpu-pytorch-cu118.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc135/results/scc135_gpu0.novalocal-reference-gpu-pytorch-cu118/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/scc135/systems/scc135_gpu0.novalocal-reference-gpu-pytorch-cu118.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/SYSU-LPC-Expects/results/210fdd372d21-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "SYSU-LPC-Expects",
    "Platform": "210fdd372d21-reference-cpu-pytorch_v2.5.0-default_config",
    "Result": 3.76647,
    "Scenario": "Offline",
    "SystemName": "210fdd372d21",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "5b6230c5b1394554",
    "errors": 0,
    "framework": "pytorch v2.5.0",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 32,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.6. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.5.0",
    "system.host_memory_capacity": "125G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1 MiB (32 instances), L1i cache: 1 MiB (32 instances), L2 cache: 16 MiB (32 instances), L3 cache: 1 GiB (32 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "32",
    "system.host_storage_capacity": "333G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "SYSU-LPC-Expects",
    "system.sw_notes": "Automated by MLCommons CM v3.2.6. ",
    "system.system_name": "210fdd372d21",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "210fdd372d21-reference-cpu-pytorch_v2.5.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/SYSU-LPC-Expects/results/210fdd372d21-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/SYSU-LPC-Expects/systems/210fdd372d21-reference-cpu-pytorch_v2.5.0-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.43411501470122,
    "Availability": "available",
    "Division": "open",
    "Location": "open/SYSU-LPC-Expects/results/b2b4f72c06b8-nvidia-gpu-TensorRT-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "SYSU-LPC-Expects",
    "Platform": "b2b4f72c06b8-nvidia-gpu-TensorRT-default_config",
    "Result": 3470.62,
    "Scenario": "Offline",
    "SystemName": "b2b4f72c06b8",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "GRID A100X-20C",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "dbfc67c346514b35",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.4. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.31)",
    "system.accelerator_frequency": "1410000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "19.9959716796875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "GRID A100X-20C",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB, L1i cache: 512 KiB, L2 cache: 8 MiB, L3 cache: 512 MiB",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "266G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "SYSU-LPC-Expects",
    "system.sw_notes": "Automated by MLCommons CM v3.2.4. ",
    "system.system_name": "b2b4f72c06b8",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "b2b4f72c06b8-nvidia-gpu-TensorRT-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/SYSU-LPC-Expects/results/b2b4f72c06b8-nvidia-gpu-TensorRT-default_config/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/SYSU-LPC-Expects/systems/b2b4f72c06b8-nvidia-gpu-TensorRT-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.87487229720105,
    "Availability": "available",
    "Division": "open",
    "Location": "open/SYSU-LPC-Expects/results/c1979786bc1c-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "SYSU-LPC-Expects",
    "Platform": "c1979786bc1c-reference-cpu-pytorch_v2.5.0-default_config",
    "Result": 2.30891,
    "Scenario": "Offline",
    "SystemName": "c1979786bc1c",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "78bd927e916946f7",
    "errors": 0,
    "framework": "pytorch v2.5.0",
    "has_power": false,
    "host_processor_core_count": 1,
    "host_processor_model_name": "AMD EPYC-Milan Processor",
    "host_processors_per_node": 16,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.2.5. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.5.0",
    "system.host_memory_capacity": "60G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 8 MiB (16 instances), L3 cache: 512 MiB (16 instances)",
    "system.host_processor_core_count": "1",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC-Milan Processor",
    "system.host_processors_per_node": "16",
    "system.host_storage_capacity": "237G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.1.110-1.el9.elrepo.x86_64-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "SYSU-LPC-Expects",
    "system.sw_notes": "Automated by MLCommons CM v3.2.5. ",
    "system.system_name": "c1979786bc1c",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "c1979786bc1c-reference-cpu-pytorch_v2.5.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/SYSU-LPC-Expects/results/c1979786bc1c-reference-cpu-pytorch_v2.5.0-default_config/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/SYSU-LPC-Expects/systems/c1979786bc1c-reference-cpu-pytorch_v2.5.0-default_config.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 16.679284781217575,
    "Availability": "available",
    "Division": "open",
    "Location": "open/thu/results/9f7dcf9a6c28-nvidia_original-gpu-tensorrt-vdefault-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "thu",
    "Platform": "9f7dcf9a6c28-nvidia_original-gpu-tensorrt-vdefault-scc24-base",
    "Result": 1.39895,
    "Scenario": "Offline",
    "SystemName": "9f7dcf9a6c28",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 PCIe",
    "accelerators_per_node": 6,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "cfe015b4e4b841c8",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 9754 128-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.1.0-11-amd64-glibc2.31)",
    "system.accelerator_frequency": "1755000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "79.20880126953125 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA H100 PCIe",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "6",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "1.5T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 8 MiB, L1i cache: 8 MiB, L2 cache: 256 MiB, L3 cache: 512 MiB",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "3100.3411",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9754 128-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4.1T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.1.0-11-amd64-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "thu",
    "system.sw_notes": "Automated by MLCommons CM v3.3.3. ",
    "system.system_name": "9f7dcf9a6c28",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "9f7dcf9a6c28-nvidia_original-gpu-tensorrt-vdefault-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/thu/results/9f7dcf9a6c28-nvidia_original-gpu-tensorrt-vdefault-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/thu/systems/9f7dcf9a6c28-nvidia_original-gpu-tensorrt-vdefault-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 16.679284781217575,
    "Availability": "available",
    "Division": "open",
    "Location": "open/thu/results/9f7dcf9a6c28-nvidia_original-gpu-tensorrt-vdefault-scc24-main/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "thu",
    "Platform": "9f7dcf9a6c28-nvidia_original-gpu-tensorrt-vdefault-scc24-main",
    "Result": 6.6076,
    "Scenario": "Offline",
    "SystemName": "9f7dcf9a6c28",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 PCIe",
    "accelerators_per_node": 6,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "de541d1c9799434d",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 9754 128-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.1.0-11-amd64-glibc2.31)",
    "system.accelerator_frequency": "1755000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "79.20880126953125 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA H100 PCIe",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "6",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "1.5T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 8 MiB, L1i cache: 8 MiB, L2 cache: 256 MiB, L3 cache: 512 MiB",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "3100.3411",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9754 128-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4.1T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.1.0-11-amd64-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "thu",
    "system.sw_notes": "Automated by MLCommons CM v3.3.3. ",
    "system.system_name": "9f7dcf9a6c28",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "9f7dcf9a6c28-nvidia_original-gpu-tensorrt-vdefault-scc24-main.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/thu/results/9f7dcf9a6c28-nvidia_original-gpu-tensorrt-vdefault-scc24-main/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/thu/systems/9f7dcf9a6c28-nvidia_original-gpu-tensorrt-vdefault-scc24-main.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.140117883682251,
    "Availability": "available",
    "Division": "open",
    "Location": "open/UNM-Roadrunners/results/4751fbf98487-reference-cpu-pytorch_v2.4.1-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "UNM-Roadrunners",
    "Platform": "4751fbf98487-reference-cpu-pytorch_v2.4.1-scc24-base",
    "Result": 0.0144109,
    "Scenario": "Offline",
    "SystemName": "4751fbf98487",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 NVL",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "cd68d286697442b1",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.0.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.35)",
    "system.accelerator_frequency": "1785000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "93.11541748046875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA H100 NVL",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "2.1T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 5.6 MiB (120 instances), L1i cache: 3.8 MiB (120 instances), L2 cache: 240 MiB (120 instances), L3 cache: 600 MiB (2 instances)",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "17T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "UNM-Roadrunners",
    "system.sw_notes": "Automated by MLCommons CM v3.0.1. ",
    "system.system_name": "4751fbf98487",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "4751fbf98487-reference-cpu-pytorch_v2.4.1-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/results/4751fbf98487-reference-cpu-pytorch_v2.4.1-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/systems/4751fbf98487-reference-cpu-pytorch_v2.4.1-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.170220836997032,
    "Availability": "available",
    "Division": "open",
    "Location": "open/UNM-Roadrunners/results/4751fbf98487-reference-gpu-pytorch_v2.4.1-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "UNM-Roadrunners",
    "Platform": "4751fbf98487-reference-gpu-pytorch_v2.4.1-scc24-base",
    "Result": 0.666646,
    "Scenario": "Offline",
    "SystemName": "4751fbf98487",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 NVL",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "e858fa39af6a45a5",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.0.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.35)",
    "system.accelerator_frequency": "1785000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "93.11541748046875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA H100 NVL",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "2.1T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 5.6 MiB (120 instances), L1i cache: 3.8 MiB (120 instances), L2 cache: 240 MiB (120 instances), L3 cache: 600 MiB (2 instances)",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "17T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "UNM-Roadrunners",
    "system.sw_notes": "Automated by MLCommons CM v3.0.1. ",
    "system.system_name": "4751fbf98487",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "4751fbf98487-reference-gpu-pytorch_v2.4.1-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/results/4751fbf98487-reference-gpu-pytorch_v2.4.1-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/systems/4751fbf98487-reference-gpu-pytorch_v2.4.1-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 13.906862080842256,
    "Availability": "available",
    "Division": "open",
    "Location": "open/UNM-Roadrunners/results/4751fbf98487-reference-gpu-pytorch_v2.4.1-scc24-main/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "UNM-Roadrunners",
    "Platform": "4751fbf98487-reference-gpu-pytorch_v2.4.1-scc24-main",
    "Result": 0.665545,
    "Scenario": "Offline",
    "SystemName": "4751fbf98487",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 NVL",
    "accelerators_per_node": 1,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "626e8ce9c1a64594",
    "errors": 0,
    "framework": "pytorch v2.4.1",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v3.0.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.35)",
    "system.accelerator_frequency": "1785000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "93.11541748046875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA H100 NVL",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.4.1",
    "system.host_memory_capacity": "2.1T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 5.6 MiB (120 instances), L1i cache: 3.8 MiB (120 instances), L2 cache: 240 MiB (120 instances), L3 cache: 600 MiB (2 instances)",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "17T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "UNM-Roadrunners",
    "system.sw_notes": "Automated by MLCommons CM v3.0.1. ",
    "system.system_name": "4751fbf98487",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "4751fbf98487-reference-gpu-pytorch_v2.4.1-scc24-main.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/results/4751fbf98487-reference-gpu-pytorch_v2.4.1-scc24-main/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/systems/4751fbf98487-reference-gpu-pytorch_v2.4.1-scc24-main.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.527581945061684,
    "Availability": "available",
    "Division": "open",
    "Location": "open/UNM-Roadrunners/results/7b06989ff188-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "UNM-Roadrunners",
    "Platform": "7b06989ff188-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.61853,
    "Scenario": "Offline",
    "SystemName": "7b06989ff188",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 NVL",
    "accelerators_per_node": 4,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "38dbf057235d4f3a",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.4.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.31)",
    "system.accelerator_frequency": "1785000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "93.11541748046875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA H100 NVL",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "2.1T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 5.6 MiB, L1i cache: 3.8 MiB, L2 cache: 240 MiB, L3 cache: 600 MiB",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "17T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "UNM-Roadrunners",
    "system.sw_notes": "Automated by MLCommons CM v2.4.0. ",
    "system.system_name": "7b06989ff188",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "7b06989ff188-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/results/7b06989ff188-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/systems/7b06989ff188-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.527581945061684,
    "Availability": "available",
    "Division": "open",
    "Location": "open/UNM-Roadrunners/results/7b06989ff188-nvidia-gpu-TensorRT-scc24-main/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "UNM-Roadrunners",
    "Platform": "7b06989ff188-nvidia-gpu-TensorRT-scc24-main",
    "Result": 1.61013,
    "Scenario": "Offline",
    "SystemName": "7b06989ff188",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 NVL",
    "accelerators_per_node": 4,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "ae375fa6fc90482f",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.4.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.31)",
    "system.accelerator_frequency": "1785000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "93.11541748046875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA H100 NVL",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "2.1T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 5.6 MiB, L1i cache: 3.8 MiB, L2 cache: 240 MiB, L3 cache: 600 MiB",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "17T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "UNM-Roadrunners",
    "system.sw_notes": "Automated by MLCommons CM v2.4.0. ",
    "system.system_name": "7b06989ff188",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "7b06989ff188-nvidia-gpu-TensorRT-scc24-main.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/results/7b06989ff188-nvidia-gpu-TensorRT-scc24-main/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/systems/7b06989ff188-nvidia-gpu-TensorRT-scc24-main.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.495350807905197,
    "Availability": "available",
    "Division": "open",
    "Location": "open/UNM-Roadrunners/results/d8727d7820f0-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "UNM-Roadrunners",
    "Platform": "d8727d7820f0-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.61345,
    "Scenario": "Offline",
    "SystemName": "d8727d7820f0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 NVL",
    "accelerators_per_node": 4,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "ef1ae5d6330c4c88",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.4.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.31)",
    "system.accelerator_frequency": "1785000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "93.11541748046875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA H100 NVL",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "2.1T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 5.6 MiB, L1i cache: 3.8 MiB, L2 cache: 240 MiB, L3 cache: 600 MiB",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "17T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "UNM-Roadrunners",
    "system.sw_notes": "Automated by MLCommons CM v2.4.0. ",
    "system.system_name": "d8727d7820f0",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "d8727d7820f0-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/results/d8727d7820f0-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/systems/d8727d7820f0-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.495350807905197,
    "Availability": "available",
    "Division": "open",
    "Location": "open/UNM-Roadrunners/results/d8727d7820f0-nvidia-gpu-TensorRT-scc24-main/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "UNM-Roadrunners",
    "Platform": "d8727d7820f0-nvidia-gpu-TensorRT-scc24-main",
    "Result": 1.61009,
    "Scenario": "Offline",
    "SystemName": "d8727d7820f0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 NVL",
    "accelerators_per_node": 4,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "6fdb5718fa1248b1",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.4.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.31)",
    "system.accelerator_frequency": "1785000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "93.11541748046875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA H100 NVL",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "2.1T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 5.6 MiB, L1i cache: 3.8 MiB, L2 cache: 240 MiB, L3 cache: 600 MiB",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "17T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "UNM-Roadrunners",
    "system.sw_notes": "Automated by MLCommons CM v2.4.0. ",
    "system.system_name": "d8727d7820f0",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "d8727d7820f0-nvidia-gpu-TensorRT-scc24-main.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/results/d8727d7820f0-nvidia-gpu-TensorRT-scc24-main/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/systems/d8727d7820f0-nvidia-gpu-TensorRT-scc24-main.json",
    "version": "v4.1"
  },
  {
    "Accuracy": 15.527581945061684,
    "Availability": "available",
    "Division": "open",
    "Location": "open/UNM-Roadrunners/results/roadrunner-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "UNM-Roadrunners",
    "Platform": "roadrunner-nvidia-gpu-TensorRT-scc24-base",
    "Result": 1.60725,
    "Scenario": "Offline",
    "SystemName": "roadrunner",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 NVL",
    "accelerators_per_node": 4,
    "benchmark_branch": "mlperf-inference-results-scc24",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "scc24-live",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "d4872a3b69364c1c",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.4.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.31)",
    "system.accelerator_frequency": "1785000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "93.11541748046875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA H100 NVL",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "2.1T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 5.6 MiB, L1i cache: 3.8 MiB, L2 cache: 240 MiB, L3 cache: 600 MiB",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "17T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-5.14.0-427.37.1.el9_4.x86_64-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "UNM-Roadrunners",
    "system.sw_notes": "Automated by MLCommons CM v2.4.0. ",
    "system.system_name": "roadrunner",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "roadrunner-nvidia-gpu-TensorRT-scc24-base.json",
    "url_repo": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24",
    "url_result": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/results/roadrunner-nvidia-gpu-TensorRT-scc24-base/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/cm4mlperf-inference/tree/mlperf-inference-results-scc24/open/UNM-Roadrunners/systems/roadrunner-nvidia-gpu-TensorRT-scc24-base.json",
    "version": "v4.1"
  }
]
