[
  {
    "Accuracy": "ROUGE1: 44.5321  ROUGE2: 22.1191  ROUGEL: 28.7225  TOKENS_PER_SAMPLE: 293.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "AMD",
    "Platform": "1xMI300X_2xEPYC-9374F",
    "Result": 3062.72,
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "35f0fc8c41514f86",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Micron MTC40F2046S1RC48BA1 MHCC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC 9374F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1xMI300X_2xEPYC-9374F.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/1xMI300X_2xEPYC-9374F.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5105  ROUGE2: 22.0812  ROUGEL: 28.727  TOKENS_PER_SAMPLE: 292.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "AMD",
    "Platform": "1xMI300X_2xEPYC-9374F",
    "Result": 2520.27,
    "Scenario": "Server",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b6174c2dc1934a27",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Micron MTC40F2046S1RC48BA1 MHCC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC 9374F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1xMI300X_2xEPYC-9374F.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/1xMI300X_2xEPYC-9374F.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5321  ROUGE2: 22.1191  ROUGEL: 28.7225  TOKENS_PER_SAMPLE: 293.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "AMD",
    "Platform": "1xMI300X_2xEPYC-9374F",
    "Result": 3062.72,
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "18b85f4a40224238",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Micron MTC40F2046S1RC48BA1 MHCC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC 9374F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1xMI300X_2xEPYC-9374F.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/1xMI300X_2xEPYC-9374F.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5105  ROUGE2: 22.0812  ROUGEL: 28.727  TOKENS_PER_SAMPLE: 292.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "AMD",
    "Platform": "1xMI300X_2xEPYC-9374F",
    "Result": 2520.27,
    "Scenario": "Server",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d700665763a947d1",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Micron MTC40F2046S1RC48BA1 MHCC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC 9374F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1xMI300X_2xEPYC-9374F.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/1xMI300X_2xEPYC-9374F.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5633  ROUGE2: 22.1252  ROUGEL: 28.7479  TOKENS_PER_SAMPLE: 292.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-9374F",
    "Result": 23514.8,
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c8f03f636b034c64",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Micron MTC40F2046S1RC48BA1 MHCC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC 9374F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "8xMI300X_2xEPYC-9374F.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/8xMI300X_2xEPYC-9374F.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5522  ROUGE2: 22.1184  ROUGEL: 28.7592  TOKENS_PER_SAMPLE: 293.5",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-9374F",
    "Result": 21028.2,
    "Scenario": "Server",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e588c67b637a4c15",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Micron MTC40F2046S1RC48BA1 MHCC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC 9374F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "8xMI300X_2xEPYC-9374F.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/8xMI300X_2xEPYC-9374F.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5633  ROUGE2: 22.1252  ROUGEL: 28.7479  TOKENS_PER_SAMPLE: 292.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-9374F",
    "Result": 23514.8,
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "295405ed05384e52",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Micron MTC40F2046S1RC48BA1 MHCC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC 9374F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "8xMI300X_2xEPYC-9374F.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/8xMI300X_2xEPYC-9374F.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5522  ROUGE2: 22.1184  ROUGEL: 28.7592  TOKENS_PER_SAMPLE: 293.5",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-9374F",
    "Result": 21028.2,
    "Scenario": "Server",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "274b274fb2d74c5a",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Micron MTC40F2046S1RC48BA1 MHCC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC 9374F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "8xMI300X_2xEPYC-9374F.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/8xMI300X_2xEPYC-9374F.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5633  ROUGE2: 22.1252  ROUGEL: 28.7479  TOKENS_PER_SAMPLE: 292.7",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-TURIN",
    "Result": 24109.8,
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d429608173e1483f",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": "N/A",
    "host_processor_model_name": "2xAMD EPYC TURIN",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Preview due to using AMD next-generation EPYC CPU",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.6 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Samsung M321R8GA0PB1-CCPXC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "N/A",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC TURIN",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Preview due to using AMD next-generation EPYC CPU",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.6 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "8xMI300X_2xEPYC-TURIN.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/8xMI300X_2xEPYC-TURIN.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5555  ROUGE2: 22.0993  ROUGEL: 28.7204  TOKENS_PER_SAMPLE: 292.8",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-TURIN",
    "Result": 22020.9,
    "Scenario": "Server",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "aadd4b7855bb4ee9",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": "N/A",
    "host_processor_model_name": "2xAMD EPYC TURIN",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Preview due to using AMD next-generation EPYC CPU",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.6 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Samsung M321R8GA0PB1-CCPXC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "N/A",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC TURIN",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Preview due to using AMD next-generation EPYC CPU",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.6 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "8xMI300X_2xEPYC-TURIN.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/8xMI300X_2xEPYC-TURIN.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5633  ROUGE2: 22.1252  ROUGEL: 28.7479  TOKENS_PER_SAMPLE: 292.7",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-TURIN",
    "Result": 24109.8,
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "78892e53075a4e4e",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": "N/A",
    "host_processor_model_name": "2xAMD EPYC TURIN",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Preview due to using AMD next-generation EPYC CPU",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.6 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Samsung M321R8GA0PB1-CCPXC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "N/A",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC TURIN",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Preview due to using AMD next-generation EPYC CPU",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.6 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "8xMI300X_2xEPYC-TURIN.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/8xMI300X_2xEPYC-TURIN.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5555  ROUGE2: 22.0993  ROUGEL: 28.7204  TOKENS_PER_SAMPLE: 292.8",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-TURIN",
    "Result": 22020.9,
    "Scenario": "Server",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bee373bfb56c4bfe",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "has_power": false,
    "host_processor_core_count": "N/A",
    "host_processor_model_name": "2xAMD EPYC TURIN",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Preview due to using AMD next-generation EPYC CPU",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.6 LTS (Jammy Jellyfish)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "system.host_memory_capacity": "1.5TiB",
    "system.host_memory_configuration": "24x 64GB Samsung M321R8GA0PB1-CCPXC",
    "system.host_network_card_count": "1x BCM57416 NetXtreme-E Dual-Media 10G RDMA Ethernet Controller, 1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "10G Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "N/A",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "2xAMD EPYC TURIN",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "900G boot disk, 2x 3.5T data disk",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Preview due to using AMD next-generation EPYC CPU",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.6 LTS (Jammy Jellyfish)",
    "system.other_hardware": "",
    "system.other_software_stack": "hipblaslt-8b71e7a, flash-attn-23a2b1c, vllm-a8cff57",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "AMD",
    "system.sw_notes": "",
    "system.system_name": "Supermicro AS-8125GS-TNMR2",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "8xMI300X_2xEPYC-TURIN.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/AMD/systems/8xMI300X_2xEPYC-TURIN.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 21.5153,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b0ea39a0260044d2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 21.5153,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8f13b30197854777",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 24173.2,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "709e507543fd4e3e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 17001.6,
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1c2fd34d3cd84555",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 20380,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b5eb89c8035a4859",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.91239681252058",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 16002.5,
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "89bd6fd5b182428b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 197140,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "329938ef8ee14079",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 129386,
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3ee27dbd01804910",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 113651,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "832debbdc00f478b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 100009,
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4ca5113c9be6458c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 6985.51,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0f05b05f21ee4577",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1008  ROUGE2: 20.1119  ROUGEL: 29.9747  GEN_LEN: 4114209",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 6070.26,
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "be3cd76ebdfc4847",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 6985.51,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9bf0f8b6cbb84613",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1008  ROUGE2: 20.1119  ROUGEL: 29.9747  GEN_LEN: 4114209",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 6070.26,
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c65bfac5f9164f49",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5664  ROUGE2: 22.1601  ROUGEL: 28.7722  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 6673.95,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f7b3b5565a0e4fbd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5664  ROUGE2: 22.16  ROUGEL: 28.7714  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 5788.29,
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b5183957cffa47db",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5664  ROUGE2: 22.1601  ROUGEL: 28.7722  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 6673.95,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0699f8c8dd65443d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5664  ROUGE2: 22.16  ROUGEL: 28.7714  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 5788.29,
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f9641ebfc5e84a65",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 270891,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "76c32b4bec9b4117",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 233275,
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d03f18335c784325",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.358",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 5288.58,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ef099070ea844abb",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.300",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 2647.04,
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9779fd185eee415d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.788790368437766  FID_SCORE: 23.667217941120498",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 5.89745,
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8ef3f8b97c304f8c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.792681410610676  FID_SCORE: 23.5106454823362",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 5.3739,
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "98dcac63bd334f50",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "768 GB",
    "system.host_memory_configuration": "12x64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "1x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "3.8 TB SSD, 7.7 TB ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC4000A_E12_4XH100_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC4000A_E12_4XH100_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86111",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 37.1373,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6e7842d34b034743",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86111",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 37.1373,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7adb6060f6b841e3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 45409.8,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2ff16586c25946e9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 35365.6,
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b80a2faa5ac841f4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 38464.2,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9e91a68ac02e4c06",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 91.00656884822276",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 32007.7,
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9cd243e346c44c76",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 368654,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "07d2114c740b4528",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 170023,
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "44dcc19758084d60",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 211128,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "87b51aeea77e4b9d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 170021,
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d585c666240f4408",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1261  ROUGE2: 20.1655  ROUGEL: 30.025  GEN_LEN: 4101272",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 13078.5,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cf2b2d16101c4fd3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.126  ROUGE2: 20.1652  ROUGEL: 30.026  GEN_LEN: 4101320",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 7986.46,
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "12427f59e7174c01",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1261  ROUGE2: 20.1655  ROUGEL: 30.025  GEN_LEN: 4101272",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 13078.5,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8a71d9a3a52240fe",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.126  ROUGE2: 20.1652  ROUGEL: 30.026  GEN_LEN: 4101320",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 7986.46,
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6210a9ddec944ffb",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.566  ROUGE2: 22.16  ROUGEL: 28.7719  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 9281.5,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cee820b2b74f46f5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5654  ROUGE2: 22.1595  ROUGEL: 28.7714  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 8094.27,
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7432347905d64a03",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.566  ROUGE2: 22.16  ROUGEL: 28.7719  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 9281.5,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "83f4f86faa854d9f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5654  ROUGE2: 22.1595  ROUGEL: 28.7714  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 8094.27,
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6e853cc5010046c7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 450364,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dce15277f5564320",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 410103,
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "88cc6ae100844cb9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.348",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 9421.13,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e597a4e602b44f92",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.299",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 8801.91,
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0888677309544307",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.791771094799042  FID_SCORE: 23.552132690785243",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 9.83763,
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "43f56f52552740a6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.788641649782658  FID_SCORE: 23.407718881605092",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 7.84131,
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "486c0e9d8dfc4244",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "16x 64GB ",
    "system.host_network_card_count": " 2x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB SSD SSDPF2KX038TZ",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54.15 , DALI 1.36.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC8000A_E12_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC8000A_E12_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 51.6944,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "38a33ba0e01c4ed7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 51.6944,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "935815e4f6b14e74",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 70661.2,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "638cbcdab9494073",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 57005.2,
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c22a21a9f2db4fc4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 62371.4,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c20741bd72324f04",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.96370616061077",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 51213.8,
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3e25899921b34e23",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 591476,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6dd3514dd59d4f51",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 516159,
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "670b7e8f47c94cdc",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 363048,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cfba8af97fe648de",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 330066,
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "949bf69ef4e7400e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 19877.6,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "37142e4de369468f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0994  ROUGE2: 20.1115  ROUGEL: 29.9734  GEN_LEN: 4114014",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 19226.9,
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bdbe0065bc364f93",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 19877.6,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "470400f6286041d4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0994  ROUGE2: 20.1115  ROUGEL: 29.9734  GEN_LEN: 4114014",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 19226.9,
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3294217f1018476e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5663  ROUGE2: 22.1602  ROUGEL: 28.7722  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 24323.6,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c48c41f490494846",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5663  ROUGE2: 22.1597  ROUGEL: 28.7718  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 20605.3,
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5a15a1aa967f49dd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5663  ROUGE2: 22.1602  ROUGEL: 28.7722  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 24323.6,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "60e58a20d0d14a5c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5663  ROUGE2: 22.1597  ROUGEL: 28.7718  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 20605.3,
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "370ad43bbf614577",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 709920,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "95907127dfe24bc6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 630229,
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d1004a7ebc474404",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.338",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 14432.8,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7881986a71f04afd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.349",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 13763,
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "75582bc387e24924",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.782806473374368  FID_SCORE: 23.56935466190987",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 16.4176,
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6a5eb279d22e4a66",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.800740675926207  FID_SCORE: 23.553461650934764",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 15.7041,
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e5cd2ff612ff42f0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "NVMe SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "16x 96GB M321RYGA0PB2-CCPPC",
    "system.host_network_card_count": "10x MT2910 Family [ConnectX-7]",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 3.84TB NVMe SSD + 4x 3.84TB NVMe SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "ASUSTeK",
    "system.sw_notes": "",
    "system.system_name": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "ESC_N8_E11_H100x8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ASUSTeK/systems/ESC_N8_E11_H100x8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86175",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 1.93148,
    "Scenario": "Offline",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "89b1c5b703bb491d",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS C240 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "C240M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 1678.45,
    "Scenario": "Offline",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "941ed9e409c64fb6",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS C240 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "C240M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 1321.65,
    "Scenario": "Server",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e182cf8c462b4394",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS C240 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "C240M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.23785974349185",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 10404.5,
    "Scenario": "Offline",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f33227448b5d4bb5",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS C240 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "C240M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.23785974349185",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 9102.39,
    "Scenario": "Server",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "115f740fbb9544cd",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS C240 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "C240M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 42.9978  ROUGE2: 20.1167  ROUGEL: 29.9517  GEN_LEN: 4110904",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 252.597,
    "Scenario": "Offline",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1424a7b0d0104d2e",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS C240 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "C240M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "ROUGE1: 43.1689  ROUGE2: 20.2066  ROUGEL: 30.0076  GEN_LEN: 4115304",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 113.739,
    "Scenario": "Server",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b95365a154bf4c3c",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS C240 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "C240M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 25643.7,
    "Scenario": "Offline",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5ea3e773a8514ca3",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS C240 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "C240M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 22501.7,
    "Scenario": "Server",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "780acd50a2b14897",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS C240 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "C240M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.357",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 388.142,
    "Scenario": "Offline",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "64bc8e21d96248fc",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS C240 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "C240M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.357",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 285.454,
    "Scenario": "Server",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c1295de24aa84ccb",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS C240 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "C240M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "F1: 90.23535730698143",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 6684.77,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "aad8f20f4c5b4156",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel Xeon Gold 6448H",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7_L40Sx2_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.25897829249658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 6761.33,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0908bfcc631d4d54",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel Xeon Gold 6448H",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7_L40Sx2_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0843  ROUGE2: 20.0853  ROUGEL: 29.9346  GEN_LEN: 4114897",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 1747.67,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "841a093b7c904a3a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel Xeon Gold 6448H",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7_L40Sx2_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0858  ROUGE2: 20.0866  ROUGEL: 29.9354  GEN_LEN: 4114953",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 1734.03,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "22434e83419244f4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel Xeon Gold 6448H",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7_L40Sx2_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 87978.3,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "91097f89b34f43a0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel Xeon Gold 6448H",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7_L40Sx2_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 91209.1,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4f049e5eb1374089",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel Xeon Gold 6448H",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7_L40Sx2_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.322",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 1642.06,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c1a901db52c94367",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel Xeon Gold 6448H",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7_L40Sx2_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.304",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 1580.59,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "84f24d6463744c93",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel Xeon Gold 6448H",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7_L40Sx2_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.800232116281986  FID_SCORE: 23.43146245513202",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 1.36759,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "42b425ef769b4a35",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel Xeon Gold 6448H",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80976548939943  FID_SCORE: 23.350301539147438",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 1.25757,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "24b0ddfb18d84c6c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel Xeon Gold 6448H",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C240M7_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C240M7_L40Sx2_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C240M7_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 11576,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "382f630a431e47ad",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 9060.77,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6f219796c20f46cf",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0362  ROUGE2: 20.0871  ROUGEL: 29.9403  GEN_LEN: 4123417",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 3268.94,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "88627be45d77446e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0354  ROUGE2: 20.0871  ROUGEL: 29.9398  GEN_LEN: 4123289",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 3258.83,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f1bd4191427a4c85",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 113422,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6c0209f887854707",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 102012,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9cecc40739b34c3d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.294",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 2349.22,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c2a64ba7550e4fbd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.246",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 2101.87,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6891e917055e47c5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.77801339238882  FID_SCORE: 23.510160963987232",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 2.4685,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bf9027be060944f1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.77801339238882  FID_SCORE: 23.510160963986095",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 2.1963,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d9c1f913a7b9421e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "F1: 90.23535730698143",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 6844.6,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a5c3a5f366754159",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_L40Sx2_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.25897829249658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 6741.2,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0e9cfc05122249c0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_L40Sx2_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0605  ROUGE2: 20.1151  ROUGEL: 29.9703  GEN_LEN: 4112035",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 1729.6,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f7f74fc7bdb84bb5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_L40Sx2_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0621  ROUGE2: 20.1162  ROUGEL: 29.9713  GEN_LEN: 4112159",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 1725.54,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "146462df29d14ae6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_L40Sx2_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 86700.2,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "937dfbc99dde4d57",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_L40Sx2_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 90612.1,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "712d095257e74dc9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_L40Sx2_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.312",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 1655.57,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "69677dca280445d6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_L40Sx2_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.307",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 1600.42,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "85bd6eae662f40a1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_L40Sx2_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79840782493353  FID_SCORE: 23.330933005015027",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 1.35121,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3d6aabcfcf0c445a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_L40Sx2_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.806383980810644  FID_SCORE: 23.194885900125996",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 1.25759,
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "83beaf69e6a145fe",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "C245M8_L40Sx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/C245M8_L40Sx2_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/C245M8_L40Sx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.23535730698143",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 6590.32,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "025485f2cd234e71",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210c_L40SX2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210c_L40SX2_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210c_L40SX2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.25897829249658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 6781.43,
    "Scenario": "Server",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "78b729668d374cda",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210c_L40SX2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210c_L40SX2_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210c_L40SX2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0605  ROUGE2: 20.1151  ROUGEL: 29.9703  GEN_LEN: 4112035",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1746.46,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3c0207fbdad24113",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210c_L40SX2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210c_L40SX2_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210c_L40SX2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0605  ROUGE2: 20.1151  ROUGEL: 29.9703  GEN_LEN: 4112037",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1725.98,
    "Scenario": "Server",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a9fc6459f46e4f7b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210c_L40SX2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210c_L40SX2_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210c_L40SX2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0605  ROUGE2: 20.1151  ROUGEL: 29.9703  GEN_LEN: 4112035",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1746.46,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "80b104a93db249c5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210c_L40SX2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210c_L40SX2_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210c_L40SX2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0605  ROUGE2: 20.1151  ROUGEL: 29.9703  GEN_LEN: 4112037",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1725.98,
    "Scenario": "Server",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b489c4f7a6ed4de4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210c_L40SX2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210c_L40SX2_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210c_L40SX2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "mAP: 37.354",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1648.81,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3fc6b4e1baaf49e7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210c_L40SX2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210c_L40SX2_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210c_L40SX2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.347",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1600.42,
    "Scenario": "Server",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "714332eeb43748a5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210c_L40SX2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210c_L40SX2_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210c_L40SX2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.810964519679548  FID_SCORE: 23.249897715238035",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1.37501,
    "Scenario": "Offline",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "51cb1f3df6ba416e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210c_L40SX2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210c_L40SX2_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210c_L40SX2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.804661527872085  FID_SCORE: 23.217464706632768",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1.26746,
    "Scenario": "Server",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "810f00890a8b4715",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB HMCG94MEBRA109N",
    "system.host_network_card_count": "2x 100Gbe",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4 TB NVMe SSDs",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "CISCO",
    "system.sw_notes": "",
    "system.system_name": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210c_L40SX2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210c_L40SX2_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210c_L40SX2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86175",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Cisco",
    "Platform": "X210M7-1-node-2S-EMR-PyTorch",
    "Result": 1.93062,
    "Scenario": "Offline",
    "SystemName": "X210M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "423b1c2191774202",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS X210 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS X210 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "X210M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0544  ROUGE2: 20.1806  ROUGEL: 29.9753  GEN_LEN: 4097091",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "X210M7-1-node-2S-EMR-PyTorch",
    "Result": 206.119,
    "Scenario": "Offline",
    "SystemName": "X210M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e04823b683584a36",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS X210 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS X210 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "X210M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "ROUGE1: 43.1261  ROUGE2: 20.1851  ROUGEL: 29.9821  GEN_LEN: 4117279",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "X210M7-1-node-2S-EMR-PyTorch",
    "Result": 113.739,
    "Scenario": "Server",
    "SystemName": "X210M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "469e9c7e5a2441c4",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS X210 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS X210 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "X210M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "X210M7-1-node-2S-EMR-PyTorch",
    "Result": 25482.9,
    "Scenario": "Offline",
    "SystemName": "X210M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "445fa7512db143a8",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS X210 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS X210 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "X210M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Cisco",
    "Platform": "X210M7-1-node-2S-EMR-PyTorch",
    "Result": 22501.8,
    "Scenario": "Server",
    "SystemName": "X210M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1d2345fe67db4968",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS X210 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 100G",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Cisco UCS X210 M7",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.3 LTS",
    "system.other_software_stack": "5.15.0-102-generic",
    "system.status": "available",
    "system.submitter": "Cisco",
    "system.sw_notes": "N/A",
    "system.system_name": "X210M7-1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "X210M7-1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Cisco/systems/X210M7-1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "ROUGE1: 42.9363  ROUGE2: 20.1275  ROUGEL: 29.9464  GEN_LEN: 4048420",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ConnectTechInc/results/Orin_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ConnectTechInc",
    "Platform": "Orin_TRT",
    "Result": 64.0078,
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin 64G (TensorRT) + CTI Forge Carrier (AGX201)",
    "SystemType": "edge",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9eb24197506c4831",
    "errors": 0,
    "framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "CTI Forge Carrier for AGX Orin (AGX201) us used as the carrier board. Using default kernel paging size",
    "number_of_nodes": 1,
    "operating_system": "Jetson r36.3.0 L4T",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "Shared with host",
    "system.accelerator_memory_configuration": "LPDDR5",
    "system.accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Active Heatsink (12V fan)",
    "system.disk_controllers": "eMMC 5.1",
    "system.disk_drives": "eMMC 5.1",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "64GB 256-bit LPDDR5",
    "system.host_network_card_count": "1 Integrated",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "802.3 Cat6 RJ45 Copper",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "12",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "64 GB eMMC, 500GB NVMe",
    "system.host_storage_type": "eMMC 5.1, PCIe gen4 NVMe disk storage",
    "system.hw_notes": "CTI Forge Carrier for AGX Orin (AGX201) us used as the carrier board",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Jetson r36.3.0 L4T",
    "system.other_hardware": "",
    "system.other_software_stack": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2, cuDNN 8.9.4",
    "system.power_management": "",
    "system.power_supply_details": "Mean Well 252W Adapter (GST280A12-C6P)",
    "system.power_supply_quantity_and_rating_watts": "252W",
    "system.status": "available",
    "system.submitter": "ConnectTechInc",
    "system.sw_notes": "Using default kernel paging size",
    "system.system_name": "NVIDIA Jetson AGX Orin 64G (TensorRT) + CTI Forge Carrier (AGX201)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Orin_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ConnectTechInc/results/Orin_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ConnectTechInc/systems/Orin_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 42.9655  ROUGE2: 20.1445  ROUGEL: 29.9678  GEN_LEN: 4047613",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ConnectTechInc/results/Orin_TRT/gptj-99/SingleStream",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ConnectTechInc",
    "Platform": "Orin_TRT",
    "Result": 4145.572039,
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Jetson AGX Orin 64G (TensorRT) + CTI Forge Carrier (AGX201)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "898d2ddb2dfa4f29",
    "errors": 0,
    "framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "CTI Forge Carrier for AGX Orin (AGX201) us used as the carrier board. Using default kernel paging size",
    "number_of_nodes": 1,
    "operating_system": "Jetson r36.3.0 L4T",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "Shared with host",
    "system.accelerator_memory_configuration": "LPDDR5",
    "system.accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Active Heatsink (12V fan)",
    "system.disk_controllers": "eMMC 5.1",
    "system.disk_drives": "eMMC 5.1",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "64GB 256-bit LPDDR5",
    "system.host_network_card_count": "1 Integrated",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "802.3 Cat6 RJ45 Copper",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "12",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "64 GB eMMC, 500GB NVMe",
    "system.host_storage_type": "eMMC 5.1, PCIe gen4 NVMe disk storage",
    "system.hw_notes": "CTI Forge Carrier for AGX Orin (AGX201) us used as the carrier board",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Jetson r36.3.0 L4T",
    "system.other_hardware": "",
    "system.other_software_stack": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2, cuDNN 8.9.4",
    "system.power_management": "",
    "system.power_supply_details": "Mean Well 252W Adapter (GST280A12-C6P)",
    "system.power_supply_quantity_and_rating_watts": "252W",
    "system.status": "available",
    "system.submitter": "ConnectTechInc",
    "system.sw_notes": "Using default kernel paging size",
    "system.system_name": "NVIDIA Jetson AGX Orin 64G (TensorRT) + CTI Forge Carrier (AGX201)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Orin_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ConnectTechInc/results/Orin_TRT/gptj-99/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/ConnectTechInc/systems/Orin_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "DICE: 0.86175",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1.87014,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8ccb5e64f31844eb",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1536GB",
    "system.host_memory_configuration": "8 slots / 96GB each / per socket",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Mesh",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4TB",
    "system.host_storage_type": "NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 24.04",
    "system.other_software_stack": "6.8.0-36-generic",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "INT4 for GPT-J, and INT8 for all other models",
    "system.system_name": "Dell PowerEdge R760",
    "system.system_type": "datacenter",
    "system.system_type_detail": "Single node dual 5th Gen Xeon CPUs",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1685.75,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b9f52dcac2a94cae",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1536GB",
    "system.host_memory_configuration": "8 slots / 96GB each / per socket",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Mesh",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4TB",
    "system.host_storage_type": "NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 24.04",
    "system.other_software_stack": "6.8.0-36-generic",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "INT4 for GPT-J, and INT8 for all other models",
    "system.system_name": "Dell PowerEdge R760",
    "system.system_type": "datacenter",
    "system.system_type_detail": "Single node dual 5th Gen Xeon CPUs",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1321.72,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e3cb52d551b747b5",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1536GB",
    "system.host_memory_configuration": "8 slots / 96GB each / per socket",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Mesh",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4TB",
    "system.host_storage_type": "NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 24.04",
    "system.other_software_stack": "6.8.0-36-generic",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "INT4 for GPT-J, and INT8 for all other models",
    "system.system_name": "Dell PowerEdge R760",
    "system.system_type": "datacenter",
    "system.system_type_detail": "Single node dual 5th Gen Xeon CPUs",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/1-node-2S-EMR-PyTorch/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.23785974349185",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 9830.18,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "baf801b472154cc8",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1536GB",
    "system.host_memory_configuration": "8 slots / 96GB each / per socket",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Mesh",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4TB",
    "system.host_storage_type": "NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 24.04",
    "system.other_software_stack": "6.8.0-36-generic",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "INT4 for GPT-J, and INT8 for all other models",
    "system.system_name": "Dell PowerEdge R760",
    "system.system_type": "datacenter",
    "system.system_type_detail": "Single node dual 5th Gen Xeon CPUs",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.23785974349185",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 9101.57,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f54570708add4d83",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1536GB",
    "system.host_memory_configuration": "8 slots / 96GB each / per socket",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Mesh",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4TB",
    "system.host_storage_type": "NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 24.04",
    "system.other_software_stack": "6.8.0-36-generic",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "INT4 for GPT-J, and INT8 for all other models",
    "system.system_name": "Dell PowerEdge R760",
    "system.system_type": "datacenter",
    "system.system_type_detail": "Single node dual 5th Gen Xeon CPUs",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0227  ROUGE2: 20.0991  ROUGEL: 29.9402  GEN_LEN: 4109364",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 248.601,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a8cba9c85a55411a",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1536GB",
    "system.host_memory_configuration": "8 slots / 96GB each / per socket",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Mesh",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4TB",
    "system.host_storage_type": "NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 24.04",
    "system.other_software_stack": "6.8.0-36-generic",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "INT4 for GPT-J, and INT8 for all other models",
    "system.system_name": "Dell PowerEdge R760",
    "system.system_type": "datacenter",
    "system.system_type_detail": "Single node dual 5th Gen Xeon CPUs",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "ROUGE1: 43.13  ROUGE2: 20.1897  ROUGEL: 29.9789  GEN_LEN: 4122116",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 113.715,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f0d87cc9c8264cc4",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1536GB",
    "system.host_memory_configuration": "8 slots / 96GB each / per socket",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Mesh",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4TB",
    "system.host_storage_type": "NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 24.04",
    "system.other_software_stack": "6.8.0-36-generic",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "INT4 for GPT-J, and INT8 for all other models",
    "system.system_name": "Dell PowerEdge R760",
    "system.system_type": "datacenter",
    "system.system_type_detail": "Single node dual 5th Gen Xeon CPUs",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/1-node-2S-EMR-PyTorch/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 25105.8,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "54e208a680ce4a76",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1536GB",
    "system.host_memory_configuration": "8 slots / 96GB each / per socket",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Mesh",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4TB",
    "system.host_storage_type": "NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 24.04",
    "system.other_software_stack": "6.8.0-36-generic",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "INT4 for GPT-J, and INT8 for all other models",
    "system.system_name": "Dell PowerEdge R760",
    "system.system_type": "datacenter",
    "system.system_type_detail": "Single node dual 5th Gen Xeon CPUs",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/1-node-2S-EMR-PyTorch/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 22501.7,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a8b74be583904df6",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1536GB",
    "system.host_memory_configuration": "8 slots / 96GB each / per socket",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Mesh",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4TB",
    "system.host_storage_type": "NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 24.04",
    "system.other_software_stack": "6.8.0-36-generic",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "INT4 for GPT-J, and INT8 for all other models",
    "system.system_name": "Dell PowerEdge R760",
    "system.system_type": "datacenter",
    "system.system_type_detail": "Single node dual 5th Gen Xeon CPUs",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/1-node-2S-EMR-PyTorch/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.357",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 373.596,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "522b9d85b3224ebd",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1536GB",
    "system.host_memory_configuration": "8 slots / 96GB each / per socket",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Mesh",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4TB",
    "system.host_storage_type": "NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 24.04",
    "system.other_software_stack": "6.8.0-36-generic",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "INT4 for GPT-J, and INT8 for all other models",
    "system.system_name": "Dell PowerEdge R760",
    "system.system_type": "datacenter",
    "system.system_type_detail": "Single node dual 5th Gen Xeon CPUs",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/1-node-2S-EMR-PyTorch/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.358",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 285.452,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f28f857dc1e2482f",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1536GB",
    "system.host_memory_configuration": "8 slots / 96GB each / per socket",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Mesh",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.4TB",
    "system.host_storage_type": "NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 24.04",
    "system.other_software_stack": "6.8.0-36-generic",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "INT4 for GPT-J, and INT8 for all other models",
    "system.system_name": "Dell PowerEdge R760",
    "system.system_type": "datacenter",
    "system.system_type_detail": "Single node dual 5th Gen Xeon CPUs",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "DICE: 0.86105",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 22.2878,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3687115b22934589",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86105",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 22.2825,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "64cf4b0bbd5246d4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 24851.2,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "45d62cc1c26b4098",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 20104.7,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2669f680fe594335",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 20729.6,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "141cec9fb87c4145",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.98233351769602",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 17600.1,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c4eea58771d14795",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 208212,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9dddc9033b814841",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 155014,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c7db38ee38fe4c79",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 123033,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4a73779d9066460d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 118009,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6fbc8f086de542a0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0343  ROUGE2: 20.0912  ROUGEL: 29.9254  GEN_LEN: 4102194",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 7191.41,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1eb1d7220dd047bb",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0347  ROUGE2: 20.0913  ROUGEL: 29.9262  GEN_LEN: 4102176",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 6337.64,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5f361da4bc634e39",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.076",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 250296,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "84a63e4488794829",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.076",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 220027,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ce8998a8a65f4b57",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.335",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 5438.57,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f992017681474222",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.307",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 4802.53,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "529c50a6227844e7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.77609215259552  FID_SCORE: 23.600158768173742",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 6.13275,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "51953c151c1343bf",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.780787407159806  FID_SCORE: 23.564359510632016",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 4.87198,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1b7b6fe2f25447bd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100NVL_PCIe_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86111",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 18.6131,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a54fa8dbd22f4a88",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "2x 100GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86111",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 18.6131,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e7766d23ff664fa1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "2x 100GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 23238.4,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "561f9e730b754af8",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "2x 100GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 17880,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ca9abb11e70f4a31",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "2x 100GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 196365,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ed28203c57104327",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "2x 100GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 206529,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7fd104c70b1a4fe8",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "2x 100GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.369",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 4690.54,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fba7904f06be4a3c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "2x 100GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.324",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 4502.63,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1e1a7a6a1c224572",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "2x 100GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "4 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.23535730698143",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 13903.8,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5ab7909e59e447c7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB 3200 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "3.5 TB",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.1",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_L40Sx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_L40Sx4_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_L40Sx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.25897829249658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 13853.7,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5cf422faaa5e4ca9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB 3200 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "3.5 TB",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.1",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_L40Sx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_L40Sx4_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_L40Sx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 180613,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "41ee64cdf81541b2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB 3200 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "3.5 TB",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.1",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_L40Sx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_L40Sx4_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_L40Sx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 181231,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4cd6c51f76674449",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB 3200 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "3.5 TB",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.1",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_L40Sx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_L40Sx4_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_L40Sx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.352",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 3345.71,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5ecf9e8250da4795",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB 3200 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "3.5 TB",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.1",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_L40Sx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_L40Sx4_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_L40Sx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.296",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 3152.43,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7edd47b6a3194d7e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB 3200 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "3.5 TB",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.1",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760xa_L40Sx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760xa_L40Sx4_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760xa_L40Sx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86111",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 9.31163,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3f5dc1c6344148c2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86111",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 9.31163,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "80a4cd894f9d4aa5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 11758.6,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8860457628554dc8",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 9145.69,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3a4c0132c9fc4ecb",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 10138.8,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a9957199153b4863",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.98642546088244",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 8252.92,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7d0edd7d8ea14746",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1259  ROUGE2: 20.1653  ROUGEL: 30.0252  GEN_LEN: 4101368",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 3317.08,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f75fcfc0ee5346a2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1239  ROUGE2: 20.1642  ROUGEL: 30.0234  GEN_LEN: 4101242",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 2759.33,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "084ba415382246b4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1259  ROUGE2: 20.1653  ROUGEL: 30.0252  GEN_LEN: 4101368",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 3317.08,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "af668264b7694dfe",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1239  ROUGE2: 20.1642  ROUGEL: 30.0234  GEN_LEN: 4101242",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 2759.33,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bb50fb28f7f144fb",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 112968,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9267e290251d4bc3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 103012,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1000516ce42d4416",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.333",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 2314.75,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1ba7dfaafc2d4397",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.274",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 2201.86,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9eccd9c6cf3b4888",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect": "PCIe 4.0 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB 4400 MT/s",
    "system.host_network_card_count": "2x 1GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "120",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "5 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "R760_H100_PCIe_80GBx2_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/R760_H100_PCIe_80GBx2_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 25.6625,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bfd3bd66fc5448a1",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 25.6625,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "07f12a7da6d04c34",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 35524.8,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c569790f1b884a69",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 28667.8,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f3ac324751164465",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 31392.5,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5e6ee4fb2c6b48d7",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.9702628671786",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 25392.6,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "291d3b1d882e49a3",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 9966.79,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b280b7c45b474596",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0994  ROUGE2: 20.1104  ROUGEL: 29.9725  GEN_LEN: 4114148",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 9990.24,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4a65e7569cbc4744",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 9966.79,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "258fb2aad9a64eb1",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0994  ROUGE2: 20.1104  ROUGEL: 29.9725  GEN_LEN: 4114148",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 9990.24,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5dc56b69ce1f4618",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5354  ROUGE2: 22.0994  ROUGEL: 28.7324  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 10699.6,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cfcd38edc5e64109",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5352  ROUGE2: 22.0997  ROUGEL: 28.7319  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 9522.2,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "455a90879f2143da",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5354  ROUGE2: 22.0994  ROUGEL: 28.7324  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 10699.6,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "796c2e3b04cc44c3",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5352  ROUGE2: 22.0997  ROUGEL: 28.7319  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 9522.2,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "804690cc2f984290",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3721  ROUGE2: 23.2543  ROUGEL: 30.3259  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.12  mbxp_accuracy: 59.84",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 26824.4,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ceb5e2e8fda84379",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3594  ROUGE2: 23.2482  ROUGEL: 30.3186  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.08  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 25707,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fd0d7d46818d4f72",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 356320,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "130b52554c7b4956",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 310333,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bc010399d09d4234",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.298",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 7195.55,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6288be82226c4084",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.325",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 6791.24,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "33042d2a108c448e",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.774510281085966  FID_SCORE: 23.69704147144745",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 8.22546,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "603bc6631f224da7",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.780136460363863  FID_SCORE: 23.537936834663242",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 7.85802,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "06ff4b93de394fa3",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Assisted Air-Cooled (LAAC)",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE8640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE8640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 36051.2,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dd261bf6d1cb4430",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 28348.3,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5d9fd28bcd414837",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 31412.4,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8b95061fdee748a1",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97285154061707",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 24854.8,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "15b1b3b2bd884813",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6147  ROUGE2: 22.1787  ROUGEL: 28.7997  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 10594.1,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "44fb5ffd2ec346f1",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6141  ROUGE2: 22.1791  ROUGEL: 28.7992  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 8937.82,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "35d47cf53534483c",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6147  ROUGE2: 22.1787  ROUGEL: 28.7997  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 10594.1,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "602a462a88ef433e",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6141  ROUGE2: 22.1791  ROUGEL: 28.7992  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 8937.82,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4dea4754be4547c8",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "mAP: 37.329",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 7149.42,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "54ba8dd4aabd4c89",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.310",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 6738.09,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2f5de9424b0346bf",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.797761486172675  FID_SCORE: 23.55327548688939",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 8.31658,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "89a82e0fb59d418d",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80400671750307  FID_SCORE: 23.548984534026317",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 6.36178,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cf4c696182ab4cba",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid Cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "16x 64GB DDR5",
    "system.host_network_card_count": "4x 400Gb Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252.06GB/s; PCIe-NIC: 200GB/s",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.6",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9640_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9640_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 51.8056,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5c170d91895f4f0a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 51.8056,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "797d32338b8b4cd6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 70594,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "47e7fd04e99146a9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 56011.6,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1785e177d5ae4888",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 61736.4,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "39ebd8a087804dc4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97894846062128",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 49611.8,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e674bf3e12754279",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6153  ROUGE2: 22.1789  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 24086.7,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5bdd2db2f94e4f15",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6146  ROUGE2: 22.1791  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 21589.2,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fe38c2c139584c30",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6153  ROUGE2: 22.1789  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 24086.7,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "abd349b8fc3e4451",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6146  ROUGE2: 22.1791  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 21589.2,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2810aeb514ed492e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 709849,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8d3a4c7a49694f3e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 584207,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "905f377afe034a7f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 54.6196,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "461410543c7043fc",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 54.6196,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f4fd55dcafd14e35",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 73791,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d17ca3d9ba104660",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 58091.3,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0c094553d10f4605",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 65322.6,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "87bbfbb9a19a4704",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97277645539535",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 51213.5,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7d94a62975294877",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 20238.4,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c2c404b80b2a4db2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1012  ROUGE2: 20.113  ROUGEL: 29.9749  GEN_LEN: 4114492",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 20139,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b813b246af934f7e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 20238.4,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8ce03760c4a94b95",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1012  ROUGE2: 20.113  ROUGEL: 29.9749  GEN_LEN: 4114492",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 20139,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b97ca43a351c42b6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5883  ROUGE2: 22.1723  ROUGEL: 28.7904  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 32124.3,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "15ba2e1689df41e0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5856  ROUGE2: 22.1708  ROUGEL: 28.7886  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 29739.9,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "073e7a449773429a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5883  ROUGE2: 22.1723  ROUGEL: 28.7904  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 32124.3,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c5eba7433de54fc9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5856  ROUGE2: 22.1708  ROUGEL: 28.7886  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 29739.9,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "603130f8d69e4a0f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 768235,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9dc7c254dcbe4fe6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 630226,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5ab032651d1c4e2a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.329",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 14760.1,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ce8b3c1a765049aa",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.328",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 13603.8,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "52230f4c07f14394",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.773352163136007  FID_SCORE: 23.58108029744642",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 17.6742,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "17b96302f907424d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.7751819768548  FID_SCORE: 23.507124682633332",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 16.6945,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2bce0dc508df4fd7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "NVLINK",
    "system.accelerator_interconnect_topology": "NVLINK Switch",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5205  ROUGE2: 22.0831  ROUGEL: 28.7052  TOKENS_PER_SAMPLE: 293.6",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9680_MI300X_192GBx8",
    "Result": 22677.6,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x MI300X_192GB, vLLM)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3fd5b298ea744d8a",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "Mesh",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.0",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "40",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "Driver version TBD",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x MI300X_192GB, vLLM)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_MI300X_192GBx8.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_MI300X_192GBx8.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.4783  ROUGE2: 22.0575  ROUGEL: 28.6859  TOKENS_PER_SAMPLE: 293.8",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9680_MI300X_192GBx8",
    "Result": 19886.1,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x MI300X_192GB, vLLM)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3bb8db54c9af40a3",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "Mesh",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.0",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "40",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "Driver version TBD",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x MI300X_192GB, vLLM)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_MI300X_192GBx8.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_MI300X_192GBx8.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5205  ROUGE2: 22.0831  ROUGEL: 28.7052  TOKENS_PER_SAMPLE: 293.6",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_MI300X_192GBx8",
    "Result": 22677.6,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x MI300X_192GB, vLLM)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2ac4403522ac43eb",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "Mesh",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.0",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "40",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "Driver version TBD",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x MI300X_192GB, vLLM)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_MI300X_192GBx8.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_MI300X_192GBx8.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.4783  ROUGE2: 22.0575  ROUGEL: 28.6859  TOKENS_PER_SAMPLE: 293.8",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_MI300X_192GBx8",
    "Result": 19886.1,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x MI300X_192GB, vLLM)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "AMD MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "60997427285d4baa",
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "XGMI",
    "system.accelerator_interconnect_topology": "Mesh",
    "system.accelerator_memory_capacity": "192 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "AMD MI300X-NPS1-SPX-192GB-750W",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.0",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gb Infiniband",
    "system.host_networking": "Infiniband:Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "40",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7.68 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "Driver version TBD",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XE9680 (8x MI300X_192GB, vLLM)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "XE9680_MI300X_192GBx8.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XE9680_MI300X_192GBx8.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "mAP: 37.360",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR8620_L4x1_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR8620_L4x1_TRT",
    "Result": 42.019927,
    "Scenario": "MultiStream",
    "SystemName": "Dell PowerEdge XR8620t (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8729cf0cf73841cd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6433N",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "251GB",
    "system.host_memory_configuration": "8x 32GB DDR5",
    "system.host_network_card_count": "4x 25GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6433N",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2x 1.92 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XR8620t (1x L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "XR8620_L4x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XR8620_L4x1_TRT/retinanet/MultiStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XR8620_L4x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.350",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR8620_L4x1_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR8620_L4x1_TRT",
    "Result": 222.619,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR8620t (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9216b4791e594f6d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6433N",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "251GB",
    "system.host_memory_configuration": "8x 32GB DDR5",
    "system.host_network_card_count": "4x 25GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6433N",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2x 1.92 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XR8620t (1x L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "XR8620_L4x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XR8620_L4x1_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XR8620_L4x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.357",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR8620_L4x1_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR8620_L4x1_TRT",
    "Result": 4.830777,
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR8620t (1x L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "40a01e718cd6447c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6433N",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "251GB",
    "system.host_memory_configuration": "8x 32GB DDR5",
    "system.host_network_card_count": "4x 25GbE",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6433N",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2x 1.92 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Dell",
    "system.sw_notes": "",
    "system.system_name": "Dell PowerEdge XR8620t (1x L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "XR8620_L4x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/results/XR8620_L4x1_TRT/retinanet/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Dell/systems/XR8620_L4x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86017",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx16_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx16_TRT",
    "Result": 61.09,
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (16x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 16,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "36f885a03b4d42e9",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "16",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB M321R8GA0BB0-CQKZJ",
    "system.host_network_card_count": "5x1Gbe, 1x200Gb",
    "system.host_networking": "Intel I210, I350x4 (Gib Eth), Mellanox MT28908 ConnectX-6 (IB 200Gib)",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "L1d:3MiB, L1i:2MiB, L2:128MiB, L3:120MiB",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "3.4GHz",
    "system.host_processor_interconnect": "UPI",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "745.2GBx8",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 8.6.3, CUDA 12.4, cuDNN 9.1.0.70, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "PRIMERGY CDI (16x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "CDI_L40Sx16_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/CDI_L40Sx16_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx16_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.336",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx16_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx16_TRT",
    "Result": 12048.3,
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (16x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 16,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "225071bb37664b22",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "16",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB M321R8GA0BB0-CQKZJ",
    "system.host_network_card_count": "5x1Gbe, 1x200Gb",
    "system.host_networking": "Intel I210, I350x4 (Gib Eth), Mellanox MT28908 ConnectX-6 (IB 200Gib)",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "L1d:3MiB, L1i:2MiB, L2:128MiB, L3:120MiB",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "3.4GHz",
    "system.host_processor_interconnect": "UPI",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "745.2GBx8",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 8.6.3, CUDA 12.4, cuDNN 9.1.0.70, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "PRIMERGY CDI (16x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "CDI_L40Sx16_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/CDI_L40Sx16_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx16_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.333",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx16_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx16_TRT",
    "Result": 11948.7,
    "Scenario": "Server",
    "SystemName": "PRIMERGY CDI (16x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 16,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0bd960208d284d0e",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "16",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB M321R8GA0BB0-CQKZJ",
    "system.host_network_card_count": "5x1Gbe, 1x200Gb",
    "system.host_networking": "Intel I210, I350x4 (Gib Eth), Mellanox MT28908 ConnectX-6 (IB 200Gib)",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "L1d:3MiB, L1i:2MiB, L2:128MiB, L3:120MiB",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "3.4GHz",
    "system.host_processor_interconnect": "UPI",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "745.2GBx8",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 8.6.3, CUDA 12.4, cuDNN 9.1.0.70, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "PRIMERGY CDI (16x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "CDI_L40Sx16_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/CDI_L40Sx16_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx16_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1387  ROUGE2: 20.1794  ROUGEL: 30.0469  GEN_LEN: 4112577",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 6911.78,
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "351d16ed51fc4378",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB M321R8GA0BB0-CQKZJ",
    "system.host_network_card_count": "5x1Gbe, 1x200Gb",
    "system.host_networking": "Intel I210, I350x4 (Gib Eth), Mellanox MT28908 ConnectX-6 (IB 200Gib)",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "L1d:3MiB, L1i:2MiB, L2:128MiB, L3:120MiB",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "3.4GHz",
    "system.host_processor_interconnect": "UPI",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "745.2GBx8",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 8.6.3, CUDA 12.4, cuDNN 9.1.0.70, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "PRIMERGY CDI (8x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "CDI_L40Sx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1388  ROUGE2: 20.1792  ROUGEL: 30.0469  GEN_LEN: 4112636",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 6903.45,
    "Scenario": "Server",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "86780b1e2d854202",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB M321R8GA0BB0-CQKZJ",
    "system.host_network_card_count": "5x1Gbe, 1x200Gb",
    "system.host_networking": "Intel I210, I350x4 (Gib Eth), Mellanox MT28908 ConnectX-6 (IB 200Gib)",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "L1d:3MiB, L1i:2MiB, L2:128MiB, L3:120MiB",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "3.4GHz",
    "system.host_processor_interconnect": "UPI",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "745.2GBx8",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 8.6.3, CUDA 12.4, cuDNN 9.1.0.70, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "PRIMERGY CDI (8x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "CDI_L40Sx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1387  ROUGE2: 20.1794  ROUGEL: 30.0469  GEN_LEN: 4112577",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 6911.78,
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b8dce90ba91e4ce4",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB M321R8GA0BB0-CQKZJ",
    "system.host_network_card_count": "5x1Gbe, 1x200Gb",
    "system.host_networking": "Intel I210, I350x4 (Gib Eth), Mellanox MT28908 ConnectX-6 (IB 200Gib)",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "L1d:3MiB, L1i:2MiB, L2:128MiB, L3:120MiB",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "3.4GHz",
    "system.host_processor_interconnect": "UPI",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "745.2GBx8",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 8.6.3, CUDA 12.4, cuDNN 9.1.0.70, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "PRIMERGY CDI (8x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "CDI_L40Sx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1388  ROUGE2: 20.1792  ROUGEL: 30.0469  GEN_LEN: 4112636",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 6903.45,
    "Scenario": "Server",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "897360d1a8ca4abb",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB M321R8GA0BB0-CQKZJ",
    "system.host_network_card_count": "5x1Gbe, 1x200Gb",
    "system.host_networking": "Intel I210, I350x4 (Gib Eth), Mellanox MT28908 ConnectX-6 (IB 200Gib)",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "L1d:3MiB, L1i:2MiB, L2:128MiB, L3:120MiB",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "3.4GHz",
    "system.host_processor_interconnect": "UPI",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "745.2GBx8",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 8.6.3, CUDA 12.4, cuDNN 9.1.0.70, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "PRIMERGY CDI (8x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "CDI_L40Sx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5205  ROUGE2: 22.0796  ROUGEL: 28.6977  TOKENS_PER_SAMPLE: 292.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 3717.74,
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5b416452ce7e4646",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB M321R8GA0BB0-CQKZJ",
    "system.host_network_card_count": "5x1Gbe, 1x200Gb",
    "system.host_networking": "Intel I210, I350x4 (Gib Eth), Mellanox MT28908 ConnectX-6 (IB 200Gib)",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "L1d:3MiB, L1i:2MiB, L2:128MiB, L3:120MiB",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "3.4GHz",
    "system.host_processor_interconnect": "UPI",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "745.2GBx8",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 8.6.3, CUDA 12.4, cuDNN 9.1.0.70, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "PRIMERGY CDI (8x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "CDI_L40Sx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5132  ROUGE2: 22.0915  ROUGEL: 28.7055  TOKENS_PER_SAMPLE: 293.0",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 3218.55,
    "Scenario": "Server",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1a30fc434c1f4876",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB M321R8GA0BB0-CQKZJ",
    "system.host_network_card_count": "5x1Gbe, 1x200Gb",
    "system.host_networking": "Intel I210, I350x4 (Gib Eth), Mellanox MT28908 ConnectX-6 (IB 200Gib)",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "L1d:3MiB, L1i:2MiB, L2:128MiB, L3:120MiB",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "3.4GHz",
    "system.host_processor_interconnect": "UPI",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "745.2GBx8",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 8.6.3, CUDA 12.4, cuDNN 9.1.0.70, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "PRIMERGY CDI (8x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "CDI_L40Sx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5205  ROUGE2: 22.0796  ROUGEL: 28.6977  TOKENS_PER_SAMPLE: 292.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 3717.74,
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4f46a8a7a99842c2",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB M321R8GA0BB0-CQKZJ",
    "system.host_network_card_count": "5x1Gbe, 1x200Gb",
    "system.host_networking": "Intel I210, I350x4 (Gib Eth), Mellanox MT28908 ConnectX-6 (IB 200Gib)",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "L1d:3MiB, L1i:2MiB, L2:128MiB, L3:120MiB",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "3.4GHz",
    "system.host_processor_interconnect": "UPI",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "745.2GBx8",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 8.6.3, CUDA 12.4, cuDNN 9.1.0.70, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "PRIMERGY CDI (8x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "CDI_L40Sx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5132  ROUGE2: 22.0915  ROUGEL: 28.7055  TOKENS_PER_SAMPLE: 293.0",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 3218.55,
    "Scenario": "Server",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "23aa52bd393e4d72",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB M321R8GA0BB0-CQKZJ",
    "system.host_network_card_count": "5x1Gbe, 1x200Gb",
    "system.host_networking": "Intel I210, I350x4 (Gib Eth), Mellanox MT28908 ConnectX-6 (IB 200Gib)",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "L1d:3MiB, L1i:2MiB, L2:128MiB, L3:120MiB",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "3.4GHz",
    "system.host_processor_interconnect": "UPI",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "745.2GBx8",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 8.6.3, CUDA 12.4, cuDNN 9.1.0.70, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "PRIMERGY CDI (8x L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "CDI_L40Sx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/CDI_L40Sx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 25.6741,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dd3a2c4f490e4f39",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 25.6741,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1d04e16a57e14b0d",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 36110.8,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f06c3b3959ec4771",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 28605.3,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1622cf7628e34896",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 31575.2,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9971cc24daf24550",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97175154211877",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 25504.8,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "708c4dc216da4f28",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 303974,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4c48ecb946654528",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 293303,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dddb7b9e70bb4d58",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 190162,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "39f050de7d774499",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 179024,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a70515c6c922499e",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 9960.74,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6b761b8973b841ce",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0991  ROUGE2: 20.1109  ROUGEL: 29.9733  GEN_LEN: 4114114",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 9602.79,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "27095ac40d494a1a",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 9960.74,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "adfb27bd460a4079",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0991  ROUGE2: 20.1109  ROUGEL: 29.9733  GEN_LEN: 4114114",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 9602.79,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3818828683c346ef",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6147  ROUGE2: 22.1787  ROUGEL: 28.7997  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 10133.3,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "611d64bf6de74aae",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6146  ROUGE2: 22.1791  ROUGEL: 28.8001  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 9493.99,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d467f4699a9c4134",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6147  ROUGE2: 22.1787  ROUGEL: 28.7997  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 10133.3,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c9daff768e904e11",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6146  ROUGE2: 22.1791  ROUGEL: 28.8001  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 9493.99,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "61cbfe3131bb4bb7",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3504  ROUGE2: 23.2436  ROUGEL: 30.3147  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.08  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 26641.6,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cb77c0599ada4141",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3591  ROUGE2: 23.2517  ROUGEL: 30.3173  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 25358.5,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "56a93d420b2f4988",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 351603,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d24566c21ae94f5a",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 301304,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2a6114c536ce488c",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.284",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 7041.1,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "70eb06137fb247f0",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.323",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 6801.47,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f29b417891564e69",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.78535566031933  FID_SCORE: 23.559521939641286",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 8.06901,
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bd16a193eca64a1d",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.78535566031933  FID_SCORE: 23.55952193964106",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 7.84386,
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9f83039ec90f44cb",
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "6x 4th Gen NVLINK, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": "32x 32GB DDR5",
    "system.host_network_card_count": "2x10Gb(ethernet), 2x200Gb (infiniband)",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "Ethernet on switching network; Infiniband on peer to peer network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "877GB (NVMe SSD) + 14TB (SATA SSD) + 7TB(PCIe SSD)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Fujitsu",
    "system.sw_notes": "",
    "system.system_name": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GX2560M7_H100_SXM_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Fujitsu/systems/GX2560M7_H100_SXM_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 54.3608,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "aa2b7af4e68245e5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 54.3608,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d7fc7dd98ff84848",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 73765.6,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ce548e74f7644eb6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 58090.2,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "58483df9f1dd416b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 64368.8,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ffbe22722b884c85",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.969453067966",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 51213.6,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "07644a4f031b4372",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 639512,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "de69ac6357dc4a18",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 585209,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "aadf704236104bd1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 394489,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b8dadfcc1de7469c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 370085,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bc6ea7e74a0e465f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 20041.3,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5c2b7c9c5fef4ee5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1004  ROUGE2: 20.1119  ROUGEL: 29.9737  GEN_LEN: 4114146",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 19250.4,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ff06eb82764a40c5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 20041.3,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "35b4b94e51be4de2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1004  ROUGE2: 20.1119  ROUGEL: 29.9737  GEN_LEN: 4114146",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 19250.4,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "aaee26d8ea754b10",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5884  ROUGE2: 22.1723  ROUGEL: 28.7905  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 31263.8,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e7d36afea30846d6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5891  ROUGE2: 22.1726  ROUGEL: 28.7906  TOKENS_PER_SAMPLE: 291.6",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 29715.3,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "78e88fbf1c2a44a2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5884  ROUGE2: 22.1723  ROUGEL: 28.7905  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 31263.8,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6d3d8cbbfa4c48df",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5891  ROUGE2: 22.1726  ROUGEL: 28.7906  TOKENS_PER_SAMPLE: 291.6",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 29715.3,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "56c1065f1f494c9c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3568  ROUGE2: 23.2496  ROUGEL: 30.3171  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 59334.8,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "38470b18dc7e44cc",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3551  ROUGE2: 23.245  ROUGEL: 30.3156  TOKENS_PER_SAMPLE: 146.0  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 57174.1,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cc3317c06f794c13",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 757446,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1c66a26611c9475d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 681328,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fb5178305f754a90",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.320",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 14988,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f8b34450f9624956",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.316",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 14012.2,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "eeb051a606454dda",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.779202078580855  FID_SCORE: 23.659997118977458",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 17.3717,
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bdf5166889dd456e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.792413492798804  FID_SCORE: 23.680384323151713",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 16.5912,
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2659e54437dc427d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "N/A",
    "system.host_networking": "N/A",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1 TB SSD, 27.9 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "GigaComputing",
    "system.sw_notes": "",
    "system.system_name": "GIGABYTE G593-SD1",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/GigaComputing/systems/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 51.3841,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "89c6c386aba54e52",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 51.3841,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9ddad1e2c960485c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 375565,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4e95d4ef1e3243c0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 340068,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "26ba377329c14dda",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 44.6156  ROUGE2: 22.1792  ROUGEL: 28.8002  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 24133.7,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5772acdace8c444e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6146  ROUGE2: 22.1791  ROUGEL: 28.7999  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 21588.3,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "21d74a9a24b845c5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6156  ROUGE2: 22.1792  ROUGEL: 28.8002  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 24133.7,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "41f703faa8e6486c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6146  ROUGE2: 22.1791  ROUGEL: 28.7999  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 21588.3,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5a0ab3e8c9534831",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3671  ROUGE2: 23.2507  ROUGEL: 30.3151  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 52524.4,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e7a9d4a3f9cf4f34",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3561  ROUGE2: 23.2477  ROUGEL: 30.3155  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.08  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 50798.8,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cc753adf51ee430c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79170623779297  FID_SCORE: 23.68643775617602",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 16.2613,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5270a287c0944895",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.78315771371126  FID_SCORE: 23.54028166661533",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 15.8185,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9642e03e905a4440",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "8+1",
    "system.host_networking": "Maximum network bandwidth speed: 1800 Gbps",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "2.70GHz (Base Clock)",
    "system.host_processor_interconnect": "Intel Ultra Path Interconnect (UPI)",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.732986239790918  FID_SCORE: 23.53670956283503",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/tpu_v5e_x4_flax/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "tpu_v5e_x4_flax",
    "Result": 1.75335,
    "Scenario": "Offline",
    "SystemName": "tpu-v5e-4",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "TPU v5e",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8c391f6ce5094fb6",
    "errors": 0,
    "framework": "flax",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7B13",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Linux version 5.19.0-1030-gcp (buildd@bos03-amd64-050) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.1.0-2ubuntu1~22.04) 12.1.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #32~22.04.1-Ubuntu SMP Thu Jul 13 09:36:23 UTC 2023",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "ICI 1600 Gbps",
    "system.accelerator_interconnect_topology": "2D Torus",
    "system.accelerator_memory_capacity": "16 GB",
    "system.accelerator_memory_configuration": "HBM2",
    "system.accelerator_model_name": "TPU v5e",
    "system.accelerator_on-chip_memories": "48 MiB",
    "system.accelerators_per_node": "4",
    "system.cooling": "TODO",
    "system.division": "closed",
    "system.framework": "flax",
    "system.host_memory_capacity": "192 GB",
    "system.host_memory_configuration": "TODO",
    "system.host_network_card_count": "TODO",
    "system.host_networking": "TODO",
    "system.host_networking_topology": "TODO",
    "system.host_processor_caches": "L1d: 1.8 MiB; L1i: 1.8 MiB; L2: 28 MiB; L3: 224 MiB",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "2200 MHz (base); 3500 MHz (turbo)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7B13",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "SSD: 100 GB; HDD: 100 GB",
    "system.host_storage_type": "SSD; HDD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Linux version 5.19.0-1030-gcp (buildd@bos03-amd64-050) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.1.0-2ubuntu1~22.04) 12.1.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #32~22.04.1-Ubuntu SMP Thu Jul 13 09:36:23 UTC 2023",
    "system.other_software_stack.JAX TPU runtime": "flax==0.8.5, jax[tpu]==0.4.30",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "tpu-v5e-4",
    "system.system_type": "datacenter",
    "system.system_type_detail": "cloud instance",
    "system_file_name": "tpu_v5e_x4_flax.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/tpu_v5e_x4_flax/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/tpu_v5e_x4_flax.json",
    "version": "v4.1",
    "weight_data_types": "bf16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.732986239790918  FID_SCORE: 23.536709562834687",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/tpu_v5e_x4_flax/stable-diffusion-xl/server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "tpu_v5e_x4_flax",
    "Result": 1.54554,
    "Scenario": "Server",
    "SystemName": "tpu-v5e-4",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "TPU v5e",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a0f0439787004fea",
    "errors": 0,
    "framework": "flax",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7B13",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Linux version 5.19.0-1030-gcp (buildd@bos03-amd64-050) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.1.0-2ubuntu1~22.04) 12.1.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #32~22.04.1-Ubuntu SMP Thu Jul 13 09:36:23 UTC 2023",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen3 x16",
    "system.accelerator_interconnect": "ICI 1600 Gbps",
    "system.accelerator_interconnect_topology": "2D Torus",
    "system.accelerator_memory_capacity": "16 GB",
    "system.accelerator_memory_configuration": "HBM2",
    "system.accelerator_model_name": "TPU v5e",
    "system.accelerator_on-chip_memories": "48 MiB",
    "system.accelerators_per_node": "4",
    "system.cooling": "TODO",
    "system.division": "closed",
    "system.framework": "flax",
    "system.host_memory_capacity": "192 GB",
    "system.host_memory_configuration": "TODO",
    "system.host_network_card_count": "TODO",
    "system.host_networking": "TODO",
    "system.host_networking_topology": "TODO",
    "system.host_processor_caches": "L1d: 1.8 MiB; L1i: 1.8 MiB; L2: 28 MiB; L3: 224 MiB",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "2200 MHz (base); 3500 MHz (turbo)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7B13",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "SSD: 100 GB; HDD: 100 GB",
    "system.host_storage_type": "SSD; HDD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Linux version 5.19.0-1030-gcp (buildd@bos03-amd64-050) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.1.0-2ubuntu1~22.04) 12.1.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #32~22.04.1-Ubuntu SMP Thu Jul 13 09:36:23 UTC 2023",
    "system.other_software_stack.JAX TPU runtime": "flax==0.8.5, jax[tpu]==0.4.30",
    "system.status": "available",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "tpu-v5e-4",
    "system.system_type": "datacenter",
    "system.system_type_detail": "cloud instance",
    "system_file_name": "tpu_v5e_x4_flax.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/tpu_v5e_x4_flax/stable-diffusion-xl/server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/tpu_v5e_x4_flax.json",
    "version": "v4.1",
    "weight_data_types": "bf16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.738648088574408  FID_SCORE: 23.499357657650307",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Google/results/tpu_v6_x4_flax/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "tpu_v6_x4_flax",
    "Result": 5.43896,
    "Scenario": "Offline",
    "SystemName": "tpu-v6-4",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "TPU v6",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d7394276a8274d80",
    "errors": 0,
    "framework": "flax",
    "has_power": false,
    "host_processor_core_count": 180,
    "host_processor_model_name": "AMD EPYC 9B14",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Linux version 6.2.0-1019-gcp (buildd@lcy02-amd64-032) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #21~22.04.1-Ubuntu SMP Thu Nov 16 18:18:34 UTC 2023",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "TODO",
    "system.accelerator_interconnect": "TODO",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "32 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "TPU v6",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "TODO",
    "system.division": "closed",
    "system.framework": "flax",
    "system.host_memory_capacity": "720 GB",
    "system.host_memory_configuration": "TODO",
    "system.host_network_card_count": "TODO",
    "system.host_networking": "TODO",
    "system.host_networking_topology": "TODO",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "180",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9B14",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "SSD: 100 GB; HDD: 100 GB",
    "system.host_storage_type": "SSD; HDD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Linux version 6.2.0-1019-gcp (buildd@lcy02-amd64-032) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #21~22.04.1-Ubuntu SMP Thu Nov 16 18:18:34 UTC 2023",
    "system.other_software_stack.JAX TPU runtime": "flax==0.8.5, jax[tpu]==0.4.30",
    "system.status": "preview",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "tpu-v6-4",
    "system.system_type": "datacenter",
    "system.system_type_detail": "cloud instance",
    "system_file_name": "tpu_v6_x4_flax.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/tpu_v6_x4_flax/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/tpu_v6_x4_flax.json",
    "version": "v4.1",
    "weight_data_types": "bf16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.736226662099362  FID_SCORE: 23.487969515738655",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Google/results/tpu_v6_x4_flax/stable-diffusion-xl/server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Google",
    "Platform": "tpu_v6_x4_flax",
    "Result": 4.48577,
    "Scenario": "Server",
    "SystemName": "tpu-v6-4",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "TPU v6",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "31b5cf9ec9af4407",
    "errors": 0,
    "framework": "flax",
    "has_power": false,
    "host_processor_core_count": 180,
    "host_processor_model_name": "AMD EPYC 9B14",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Linux version 6.2.0-1019-gcp (buildd@lcy02-amd64-032) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #21~22.04.1-Ubuntu SMP Thu Nov 16 18:18:34 UTC 2023",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "TODO",
    "system.accelerator_interconnect": "TODO",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "32 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "TPU v6",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "TODO",
    "system.division": "closed",
    "system.framework": "flax",
    "system.host_memory_capacity": "720 GB",
    "system.host_memory_configuration": "TODO",
    "system.host_network_card_count": "TODO",
    "system.host_networking": "TODO",
    "system.host_networking_topology": "TODO",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "180",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9B14",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "SSD: 100 GB; HDD: 100 GB",
    "system.host_storage_type": "SSD; HDD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Linux version 6.2.0-1019-gcp (buildd@lcy02-amd64-032) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.3.0-1ubuntu1~22.04) 12.3.0, GNU ld (GNU Binutils for Ubuntu) 2.38) #21~22.04.1-Ubuntu SMP Thu Nov 16 18:18:34 UTC 2023",
    "system.other_software_stack.JAX TPU runtime": "flax==0.8.5, jax[tpu]==0.4.30",
    "system.status": "preview",
    "system.submitter": "Google",
    "system.sw_notes": "",
    "system.system_name": "tpu-v6-4",
    "system.system_type": "datacenter",
    "system.system_type_detail": "cloud instance",
    "system_file_name": "tpu_v6_x4_flax.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/results/tpu_v6_x4_flax/stable-diffusion-xl/server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Google/systems/tpu_v6_x4_flax.json",
    "version": "v4.1",
    "weight_data_types": "bf16"
  },
  {
    "Accuracy": "DICE: 0.86175",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1.86652,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b639726641064c41",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 8",
    "system.other_software_stack": "6.6.8-1.el8.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "N/A",
    "system.system_name": "HPE ProLiant DL380 Gen11",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1608.87,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7ee332a1361f4f73",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 8",
    "system.other_software_stack": "6.6.8-1.el8.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "N/A",
    "system.system_name": "HPE ProLiant DL380 Gen11",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1301.7,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "36906edd6a984d96",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 8",
    "system.other_software_stack": "6.6.8-1.el8.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "N/A",
    "system.system_name": "HPE ProLiant DL380 Gen11",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/1-node-2S-EMR-PyTorch/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0958  ROUGE2: 20.1844  ROUGEL: 30.0166  GEN_LEN: 4108239",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 251.298,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "62b40ea04e594e7b",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 8",
    "system.other_software_stack": "6.6.8-1.el8.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "N/A",
    "system.system_name": "HPE ProLiant DL380 Gen11",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "ROUGE1: 43.1253  ROUGE2: 20.21  ROUGEL: 30.0012  GEN_LEN: 4120951",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 113.735,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "46f3c351d5904e47",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 8",
    "system.other_software_stack": "6.6.8-1.el8.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "N/A",
    "system.system_name": "HPE ProLiant DL380 Gen11",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/1-node-2S-EMR-PyTorch/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 25356.7,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d640eea6dbea4cde",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 8",
    "system.other_software_stack": "6.6.8-1.el8.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "N/A",
    "system.system_name": "HPE ProLiant DL380 Gen11",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/1-node-2S-EMR-PyTorch/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 22501.7,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "18cd43878a67439a",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 8",
    "system.other_software_stack": "6.6.8-1.el8.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "N/A",
    "system.system_name": "HPE ProLiant DL380 Gen11",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/1-node-2S-EMR-PyTorch/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.357",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 370.727,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "784272ca3cbe489e",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 8",
    "system.other_software_stack": "6.6.8-1.el8.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "N/A",
    "system.system_name": "HPE ProLiant DL380 Gen11",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/1-node-2S-EMR-PyTorch/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.357",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 275.531,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5da42f99d2a5480c",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 8",
    "system.other_software_stack": "6.6.8-1.el8.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "N/A",
    "system.system_name": "HPE ProLiant DL380 Gen11",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 87052.7,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "42c73e64410246f0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 81009.6,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7f26f54c17324fec",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 53611.9,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f6ba4631544f4cf9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 51014.2,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d1b78c10325746bf",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2632.76,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c14a3d84c0774058",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1002  ROUGE2: 20.1114  ROUGEL: 29.9742  GEN_LEN: 4114259",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2512.89,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "187a784531de4493",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2632.76,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "29a6c1e05c0f4014",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1002  ROUGE2: 20.1114  ROUGEL: 29.9742  GEN_LEN: 4114259",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2512.89,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f5b8a0e9da3249cb",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5631  ROUGE2: 22.1578  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 4084.3,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a4aac70681614b69",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.563  ROUGE2: 22.1577  ROUGEL: 28.7741  TOKENS_PER_SAMPLE: 291.3",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 3884.16,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "44fb91d79cfa4566",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5631  ROUGE2: 22.1578  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 4084.3,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5401414114074d9d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.563  ROUGE2: 22.1577  ROUGEL: 28.7741  TOKENS_PER_SAMPLE: 291.3",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 3884.16,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4da84d7e93844b4c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3565  ROUGE2: 23.2488  ROUGEL: 30.3157  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.9",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 8063.02,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "64bf3ffb97a64254",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3563  ROUGE2: 23.2486  ROUGEL: 30.3162  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.94",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 7450.72,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3165e4ad4fb44efe",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.776026719808577  FID_SCORE: 23.544066499357825",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.30503,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4c2d2bb2fd4e430d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.780244728624822  FID_SCORE: 23.755905597900437",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.01813,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "37eb7cf316014b56",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 52.0396,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a2ef48ce4faf45dd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 52.0344,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b9022f89a0eb4c86",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 71560.3,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "35f83881ca55490b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 56729.3,
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b8b0d275deca484c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 62207.3,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cd9d37f28eeb4ee0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97012946937284",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 51210.8,
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "af191a769ad34be5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0343  ROUGE2: 20.0912  ROUGEL: 29.9254  GEN_LEN: 4102194",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 19751.9,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f1a35ef201f74997",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0345  ROUGE2: 20.0914  ROUGEL: 29.9253  GEN_LEN: 4102160",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 19502.6,
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "94fe52da4671446c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.535  ROUGE2: 22.0991  ROUGEL: 28.7319  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 24528.3,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6445c436a3f04274",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5353  ROUGE2: 22.0997  ROUGEL: 28.7319  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 23132.8,
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a035dcdac0554817",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.535  ROUGE2: 22.0991  ROUGEL: 28.7319  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 24424.7,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fba4777a50f149ad",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5353  ROUGE2: 22.0997  ROUGEL: 28.732  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 23144,
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2e3f6e8e41814a00",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3566  ROUGE2: 23.2487  ROUGEL: 30.3174  TOKENS_PER_SAMPLE: 146.0  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 52395.1,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1f82570acc854582",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3565  ROUGE2: 23.249  ROUGEL: 30.3137  TOKENS_PER_SAMPLE: 146.0  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 50798.5,
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2fe89086851f4953",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 707695,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "53737ecaa6834c2c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 620228,
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8519579c574e4de7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.316",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 14410,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "93a3782e27254803",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.291",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 13763,
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "18272301d1f94001",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79560137182474  FID_SCORE: 23.603033702848677",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 16.202,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8b0cd498e5a14883",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79274706661701  FID_SCORE: 23.504448322230132",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 15.8155,
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "eaf8bd8c61f14e1b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 21.5112,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "14ee7ac28d904c94",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 21.5112,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "446ac8b261814e74",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 23937.5,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "66ff9c61a8b54a08",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 19202.4,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "56f014c1470f4e2f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 20087.7,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "803f780214ce41e6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97467263774264",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 15003.9,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9bfa2970c9b344d3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6113  ROUGE2: 22.1451  ROUGEL: 28.7779  TOKENS_PER_SAMPLE: 290.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 8858.78,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bebca7d994ef4ed3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6118  ROUGE2: 22.1456  ROUGEL: 28.7778  TOKENS_PER_SAMPLE: 290.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 6927.8,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9d4f6b34ff2e4c0f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6113  ROUGE2: 22.1451  ROUGEL: 28.7779  TOKENS_PER_SAMPLE: 290.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 8858.78,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a63bc04d461b413b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6118  ROUGE2: 22.1456  ROUGEL: 28.7778  TOKENS_PER_SAMPLE: 290.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 6927.8,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d6fda6fd06c14da9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 242572,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fbf7e4e953b94e37",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 240031,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "07ea800ab8d147f7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.308",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 5285.27,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6d2175755b0e448a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.296",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 5003,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4d23f3092d9f45eb",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.785679597854614  FID_SCORE: 23.58312861291523",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 5.80657,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e8bbdc0af70b4af1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79951359838247  FID_SCORE: 23.704401384992025",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 3.9493,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9037ff6071cc4a99",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86017",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 15.4388,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "78d4cc94372943f1",
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 Switch",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.0.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB 36ASF8G72PZ-3G2E1",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "1Gbe",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.4, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.15707103092267",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 12981.8,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "80176ef6e5f64c12",
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 Switch",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.0.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB 36ASF8G72PZ-3G2E1",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "1Gbe",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.4, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.19415645264598",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 12904.6,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dd816a074e664b29",
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 Switch",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.0.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB 36ASF8G72PZ-3G2E1",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "1Gbe",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.4, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 172857,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2c3d9aaf160647ea",
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 Switch",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.0.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB 36ASF8G72PZ-3G2E1",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "1Gbe",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.4, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 176025,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e06f75e34deb4740",
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 Switch",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.0.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB 36ASF8G72PZ-3G2E1",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "1Gbe",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.4, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.349",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 3273.27,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c184f62b11aa4a79",
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 Switch",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.0.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB 36ASF8G72PZ-3G2E1",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "1Gbe",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.4, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.319",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 3102.23,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "08e99f41ea9e42af",
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 Switch",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.0.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB 36ASF8G72PZ-3G2E1",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "1Gbe",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.4, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/HPE/systems/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86175",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1.93632,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dda0a9bb901443f4",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86175",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1.93632,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f000f9fe7d2c408f",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1666.82,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "166c0a0cde034e82",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1281.58,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "29aa2518d9ff42fa",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.24119408703937",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 9949.2,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "626edd4b1187476a",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.24119408703937",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 9731.54,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "51cae27e749f48b7",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.24119408703937",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 9949.2,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ba22af1e36524e8c",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.24119408703937",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 9731.54,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "32e75c88689b45b0",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0704  ROUGE2: 20.1637  ROUGEL: 29.9748  GEN_LEN: 4103762",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 254.724,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cc592ac807604e6c",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "ROUGE1: 43.1201  ROUGE2: 20.1783  ROUGEL: 29.9726  GEN_LEN: 4121372",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 113.74,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ae410c9aa33c428e",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 25204.5,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "55aebdd04a3b4bf6",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 22501.8,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "26780cdd50174ea1",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.357",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 377.53,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b0234c078282458f",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.357",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 285.455,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8c39a9758df74a55",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.9.7-1.el9.elrepo.x86_64",
    "system.status": "available",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "DICE: 0.86175",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 3.28548,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f97489f186d94425",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86175",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 3.28548,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "625a306eee3a4661",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 3024.03,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "712466510bce4802",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 2436.99,
    "Scenario": "Server",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fca776f912c74bfd",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.24119408703937",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 18326.6,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "541ee6a4d2a64ecd",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.24119408703937",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 17749.5,
    "Scenario": "Server",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c7cba9a0c7c94394",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.24119408703937",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 18326.6,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "58e74c7d25b046aa",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.24119408703937",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 17749.5,
    "Scenario": "Server",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f065c0c8f6504d2d",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.082  ROUGE2: 20.1511  ROUGEL: 29.9707  GEN_LEN: 4113914",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 498.316,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a89abfe8b0f742dd",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "ROUGE1: 43.204  ROUGE2: 20.2488  ROUGEL: 30.0484  GEN_LEN: 4114960",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 217.466,
    "Scenario": "Server",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0e8c2dddc6664fc2",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 45617.3,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "192747949c8043d8",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 39798.3,
    "Scenario": "Server",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b20174f5bff8472d",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.357",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 746.647,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dd2e227674a24a47",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.358",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 595.785,
    "Scenario": "Server",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ac10a1380031446a",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "2304GB",
    "system.host_memory_configuration": "12 slots per socket / 96GB each / 8800 MT/s DDR5 (MRDIMM)",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "128",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "Intel AvenueCity",
    "system.number_of_nodes": "1",
    "system.operating_system": "CentOS Stream 9",
    "system.other_software_stack": "6.6.0-gnr.bkc.6.6.16.8.23.x86_64",
    "system.status": "preview",
    "system.submitter": "Intel",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-GNR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-GNR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/results/1-node-2S-GNR-PyTorch/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Intel/systems/1-node-2S-GNR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "ROUGE1: 44.6047  ROUGE2: 22.1268  ROUGEL: 28.7705  TOKENS_PER_SAMPLE: 291.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx16_TRT",
    "Result": 41672.4,
    "Scenario": "Offline",
    "SystemName": "2x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b03a31db50504cb7",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "NVLink",
    "system.accelerator_interconnect_topology": "rail-optimized",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "2.0 TB",
    "system.host_memory_configuration": "32 slots / 64 GB each/ Total = 2 TB /DDR4  3200 MHz",
    "system.host_network_card_count": "8",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on Juniper switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "2",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "JuniperNetworks",
    "system.sw_notes": "",
    "system.system_name": "2x8xH100-SXM-80GB",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx16_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/systems/DGX-H100_H100-SXM-80GBx16_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6052  ROUGE2: 22.1275  ROUGEL: 28.7709  TOKENS_PER_SAMPLE: 291.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx16_TRT",
    "Result": 41091.6,
    "Scenario": "Server",
    "SystemName": "2x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "13d079231fd54dfa",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "NVLink",
    "system.accelerator_interconnect_topology": "rail-optimized",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "2.0 TB",
    "system.host_memory_configuration": "32 slots / 64 GB each/ Total = 2 TB /DDR4  3200 MHz",
    "system.host_network_card_count": "8",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on Juniper switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "2",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "JuniperNetworks",
    "system.sw_notes": "",
    "system.system_name": "2x8xH100-SXM-80GB",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx16_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/systems/DGX-H100_H100-SXM-80GBx16_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6047  ROUGE2: 22.1268  ROUGEL: 28.7705  TOKENS_PER_SAMPLE: 291.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx16_TRT",
    "Result": 41672.4,
    "Scenario": "Offline",
    "SystemName": "2x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3fa08230362d4ae6",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "NVLink",
    "system.accelerator_interconnect_topology": "rail-optimized",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "2.0 TB",
    "system.host_memory_configuration": "32 slots / 64 GB each/ Total = 2 TB /DDR4  3200 MHz",
    "system.host_network_card_count": "8",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on Juniper switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "2",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "JuniperNetworks",
    "system.sw_notes": "",
    "system.system_name": "2x8xH100-SXM-80GB",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx16_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/systems/DGX-H100_H100-SXM-80GBx16_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6052  ROUGE2: 22.1275  ROUGEL: 28.7709  TOKENS_PER_SAMPLE: 291.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx16_TRT",
    "Result": 41091.6,
    "Scenario": "Server",
    "SystemName": "2x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ba6c84f08d2645a9",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "NVLink",
    "system.accelerator_interconnect_topology": "rail-optimized",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "2.0 TB",
    "system.host_memory_configuration": "32 slots / 64 GB each/ Total = 2 TB /DDR4  3200 MHz",
    "system.host_network_card_count": "8",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on Juniper switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "2",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "JuniperNetworks",
    "system.sw_notes": "",
    "system.system_name": "2x8xH100-SXM-80GB",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx16_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/systems/DGX-H100_H100-SXM-80GBx16_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6048  ROUGE2: 22.1273  ROUGEL: 28.7697  TOKENS_PER_SAMPLE: 291.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx32_TRT",
    "Result": 82749.6,
    "Scenario": "Offline",
    "SystemName": "4x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2b9a57fa390c4521",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "NVLink",
    "system.accelerator_interconnect_topology": "rail-optimized",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "2.0 TB",
    "system.host_memory_configuration": "32 slots / 64 GB each/ Total = 2 TB /DDR4  3200 MHz",
    "system.host_network_card_count": "8",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on Juniper switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "4",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "JuniperNetworks",
    "system.sw_notes": "",
    "system.system_name": "4x8xH100-SXM-80GB",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx32_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/systems/DGX-H100_H100-SXM-80GBx32_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6056  ROUGE2: 22.1274  ROUGEL: 28.7709  TOKENS_PER_SAMPLE: 291.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx32_TRT",
    "Result": 82273.2,
    "Scenario": "Server",
    "SystemName": "4x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "203986133b5c42ce",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "NVLink",
    "system.accelerator_interconnect_topology": "rail-optimized",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "2.0 TB",
    "system.host_memory_configuration": "32 slots / 64 GB each/ Total = 2 TB /DDR4  3200 MHz",
    "system.host_network_card_count": "8",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on Juniper switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "4",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "JuniperNetworks",
    "system.sw_notes": "",
    "system.system_name": "4x8xH100-SXM-80GB",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx32_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/systems/DGX-H100_H100-SXM-80GBx32_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6048  ROUGE2: 22.1273  ROUGEL: 28.7697  TOKENS_PER_SAMPLE: 291.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx32_TRT",
    "Result": 82749.6,
    "Scenario": "Offline",
    "SystemName": "4x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1f3b63740e144aba",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "NVLink",
    "system.accelerator_interconnect_topology": "rail-optimized",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "2.0 TB",
    "system.host_memory_configuration": "32 slots / 64 GB each/ Total = 2 TB /DDR4  3200 MHz",
    "system.host_network_card_count": "8",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on Juniper switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "4",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "JuniperNetworks",
    "system.sw_notes": "",
    "system.system_name": "4x8xH100-SXM-80GB",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx32_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/systems/DGX-H100_H100-SXM-80GBx32_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6056  ROUGE2: 22.1274  ROUGEL: 28.7709  TOKENS_PER_SAMPLE: 291.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx32_TRT",
    "Result": 82273.2,
    "Scenario": "Server",
    "SystemName": "4x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f0d176ad37e34749",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "NVLink",
    "system.accelerator_interconnect_topology": "rail-optimized",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "2.0 TB",
    "system.host_memory_configuration": "32 slots / 64 GB each/ Total = 2 TB /DDR4  3200 MHz",
    "system.host_network_card_count": "8",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on Juniper switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "4",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 20.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "JuniperNetworks",
    "system.sw_notes": "",
    "system.system_name": "4x8xH100-SXM-80GB",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx32_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/JuniperNetworks/systems/DGX-H100_H100-SXM-80GBx32_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 54.3653,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "91cdd8726742413b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 54.3653,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3481d777606d40b0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 70319.1,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "75072c4e25ad4051",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 56811.1,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e9e21085b6054253",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 62102.5,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8203f3d8c3e84a74",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97055862194885",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 51211,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c02711da6f114a17",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0773  ROUGE2: 20.0872  ROUGEL: 29.9583  GEN_LEN: 4107356",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 19859.2,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "828a2c1a8930482f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0786  ROUGE2: 20.0893  ROUGEL: 29.9596  GEN_LEN: 4107309",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 19716,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ae403719735f41ee",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6249  ROUGE2: 22.1876  ROUGEL: 28.8076  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 31917,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6dd468249e8646b9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6256  ROUGE2: 22.1883  ROUGEL: 28.808  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 30068.5,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bd6d4b0912a14d2b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6249  ROUGE2: 22.1876  ROUGEL: 28.8076  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 31917,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c30a2b878c3e40c2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6256  ROUGE2: 22.1883  ROUGEL: 28.808  TOKENS_PER_SAMPLE: 290.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 30068.5,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "308c7beb01cc48eb",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "mAP: 37.296",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 15015.4,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c74211ffb5ed4678",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.310",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 13164,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fc40513e94b54a30",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.789565710127352  FID_SCORE: 23.678407455981755",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 17.1877,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3c6f1aafa4ba4e8f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.800972669124604  FID_SCORE: 23.856732098940086",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 16.645,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6c1a6e6a057c4caf",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB HMCG94MEBRA121N",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9454",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "7 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200_SXM_141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/H200_SXM_141GBx8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/H200_SXM_141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86017",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 7.79867,
    "Scenario": "Offline",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "61ceedce5250482e",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86017",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/3d-unet-99/SingleStream",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 492.066482,
    "Scenario": "SingleStream",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f58dd347062f4cf0",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/3d-unet-99/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.23535730698143",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 6502.66,
    "Scenario": "Offline",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0807ec0ea0e24d1c",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.26682135974633",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/bert-99/SingleStream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 1.118678,
    "Scenario": "SingleStream",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9df764204a744d54",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/bert-99/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0266  ROUGE2: 20.1037  ROUGEL: 29.9635  GEN_LEN: 4086524",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 1718.33,
    "Scenario": "Offline",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6e13e5328dce458c",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 42.9974  ROUGE2: 20.1045  ROUGEL: 29.9342  GEN_LEN: 4082745",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/gptj-99/SingleStream",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 1437.183344,
    "Scenario": "SingleStream",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6ea6c84a6baf4867",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/gptj-99/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/resnet50/MultiStream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 0.525463,
    "Scenario": "MultiStream",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "64b90a70d9bc42f0",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/resnet50/MultiStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 86304.6,
    "Scenario": "Offline",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e478c8aeb12f4a84",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.064",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/resnet50/SingleStream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 0.332412,
    "Scenario": "SingleStream",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "65f1b8659e174d28",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/resnet50/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.326",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 10.391624,
    "Scenario": "MultiStream",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fbffdf8252d842a4",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/retinanet/MultiStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.331",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 1629.08,
    "Scenario": "Offline",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c31faa357ff9447c",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.341",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL40S_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL40S_TRT",
    "Result": 1.809631,
    "Scenario": "SingleStream",
    "SystemName": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "95b686296e1b4f29",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.3",
    "system.host_memory_capacity": "128 GB",
    "system.host_memory_configuration": "4x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 545.23.08, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE455 V3 (2x NVIDIA L40S, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL40S_TRT/retinanet/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86003",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL4_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL4_TRT",
    "Result": 2.21588,
    "Scenario": "Offline",
    "SystemName": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "316e359a0bc64f62",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Ethernet",
    "system.accelerator_interconnect": "None",
    "system.accelerator_interconnect_topology": "None",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.5",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "4x 64GB M393A8G40CB4-CWE",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.5, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL4_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86003",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL4_TRT/3d-unet-99/SingleStream",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL4_TRT",
    "Result": 1737.387316,
    "Scenario": "SingleStream",
    "SystemName": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1cd72f705ef24ab1",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Ethernet",
    "system.accelerator_interconnect": "None",
    "system.accelerator_interconnect_topology": "None",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.5",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "4x 64GB M393A8G40CB4-CWE",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.5, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL4_TRT/3d-unet-99/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.23535730698143",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL4_TRT",
    "Result": 1928.07,
    "Scenario": "Offline",
    "SystemName": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c10caad997604790",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Ethernet",
    "system.accelerator_interconnect": "None",
    "system.accelerator_interconnect_topology": "None",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.5",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "4x 64GB M393A8G40CB4-CWE",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.5, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL4_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.26682135974633",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL4_TRT/bert-99/SingleStream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL4_TRT",
    "Result": 2.138389,
    "Scenario": "SingleStream",
    "SystemName": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9ec50eb90be74c4f",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Ethernet",
    "system.accelerator_interconnect": "None",
    "system.accelerator_interconnect_topology": "None",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.5",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "4x 64GB M393A8G40CB4-CWE",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.5, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL4_TRT/bert-99/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL4_TRT/resnet50/MultiStream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL4_TRT",
    "Result": 0.750563,
    "Scenario": "MultiStream",
    "SystemName": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "05a3eef41804480d",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Ethernet",
    "system.accelerator_interconnect": "None",
    "system.accelerator_interconnect_topology": "None",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.5",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "4x 64GB M393A8G40CB4-CWE",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.5, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL4_TRT/resnet50/MultiStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL4_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL4_TRT",
    "Result": 25600,
    "Scenario": "Offline",
    "SystemName": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7d6860b998c84b9d",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Ethernet",
    "system.accelerator_interconnect": "None",
    "system.accelerator_interconnect_topology": "None",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.5",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "4x 64GB M393A8G40CB4-CWE",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.5, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL4_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.064",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL4_TRT/resnet50/SingleStream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL4_TRT",
    "Result": 0.386829,
    "Scenario": "SingleStream",
    "SystemName": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4b1151b971a745fa",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Ethernet",
    "system.accelerator_interconnect": "None",
    "system.accelerator_interconnect_topology": "None",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.5",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "4x 64GB M393A8G40CB4-CWE",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.5, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL4_TRT/resnet50/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.324",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL4_TRT/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL4_TRT",
    "Result": 32.190689,
    "Scenario": "MultiStream",
    "SystemName": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bedff04e6be947fc",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Ethernet",
    "system.accelerator_interconnect": "None",
    "system.accelerator_interconnect_topology": "None",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.5",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "4x 64GB M393A8G40CB4-CWE",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.5, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL4_TRT/retinanet/MultiStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.311",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL4_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL4_TRT",
    "Result": 453.667,
    "Scenario": "Offline",
    "SystemName": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6d46544ff87543e1",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Ethernet",
    "system.accelerator_interconnect": "None",
    "system.accelerator_interconnect_topology": "None",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.5",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "4x 64GB M393A8G40CB4-CWE",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.5, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL4_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.317",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_2xL4_TRT/retinanet/SingleStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "Lenovo_2xL4_TRT",
    "Result": 3.814301,
    "Scenario": "SingleStream",
    "SystemName": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fa852ee3a00b43b8",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Ethernet",
    "system.accelerator_interconnect": "None",
    "system.accelerator_interconnect_topology": "None",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.5",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "4x 64GB M393A8G40CB4-CWE",
    "system.host_network_card_count": "2",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) D-2775TE",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.5, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkEdge SE360 V2 (2x NVIDIA L4, TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_2xL4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_2xL4_TRT/retinanet/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_2xL4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 54.5565,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "98e6830f1ce74acd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 54.5565,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5bfef4b585324278",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 70369.8,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d860593fc4ba445c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 56012.5,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "82b1f09f842f4e6c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 64983.6,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6f32f41aed584b00",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.96818533538325",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 52814,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a5150952cb22483f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.102  ROUGE2: 20.1124  ROUGEL: 29.9753  GEN_LEN: 4114427",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 20552.1,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "27b24f7ee627439d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.101  ROUGE2: 20.1122  ROUGEL: 29.9738  GEN_LEN: 4114231",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 19785,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b5899af5e0094c7c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.102  ROUGE2: 20.1124  ROUGEL: 29.9753  GEN_LEN: 4114427",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 20552.1,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7a4405625fb44984",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.101  ROUGE2: 20.1122  ROUGEL: 29.9738  GEN_LEN: 4114231",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 19785,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9f522fe48b5a404f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5884  ROUGE2: 22.1723  ROUGEL: 28.7905  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 31973.7,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0cdf2ba561884829",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5866  ROUGE2: 22.1706  ROUGEL: 28.789  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 30438.7,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "db8a37b32727429b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5884  ROUGE2: 22.1723  ROUGEL: 28.7905  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 31973.7,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bdc320bb10c44e32",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5866  ROUGE2: 22.1706  ROUGEL: 28.789  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 30438.7,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "42ec4d7de01c4c34",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79363980323076  FID_SCORE: 23.410796374801066",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 17.5975,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "aae64d7a8ba54908",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.780624158978462  FID_SCORE: 23.78968355756865",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 16.9831,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9ebd198cfcfd4572",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "12 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Lenovo_8xH200_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/Lenovo_8xH200_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/Lenovo_8xH200_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86017",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 11.6149,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9e1afb1ad7b541cf",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "3",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR650_V3_3xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR650_V3_3xL40S_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR650_V3_3xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.23535730698143",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 9480.82,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d1a61983c5f34c6c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "3",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR650_V3_3xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR650_V3_3xL40S_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR650_V3_3xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.25897829249658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 9302,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "738f13cb49114ffa",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "3",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR650_V3_3xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR650_V3_3xL40S_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR650_V3_3xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0516  ROUGE2: 20.0942  ROUGEL: 29.9288  GEN_LEN: 4111570",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 2593.65,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c3d81304d4354b33",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "3",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR650_V3_3xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR650_V3_3xL40S_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR650_V3_3xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0516  ROUGE2: 20.0939  ROUGEL: 29.9288  GEN_LEN: 4111576",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 2475.22,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "eacbcb7d34514c72",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "3",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR650_V3_3xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR650_V3_3xL40S_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR650_V3_3xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 132436,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5cb00c8913d141ee",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "3",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR650_V3_3xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR650_V3_3xL40S_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR650_V3_3xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 132008,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c1a3a3fc221a44ae",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "3",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR650_V3_3xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR650_V3_3xL40S_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR650_V3_3xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.336",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 2290.08,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7dc4f5f41e384419",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "3",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR650_V3_3xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR650_V3_3xL40S_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR650_V3_3xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.317",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 2201.83,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6038e9e4134843ea",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/a",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "3",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 32GB M321R4GA3BB6-CQKDS",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR650_V3_3xL40S_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR650_V3_3xL40S_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR650_V3_3xL40S_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 43.6883,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a11e3b97759d41d1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 43.6883,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bca3e10fd6f54316",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 47655.3,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "61fe1f7438624e31",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 35006.8,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "064de6ba81aa494d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0394  ROUGE2: 20.0943  ROUGEL: 29.9329  GEN_LEN: 4100159",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 14073.6,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e646525864594aa9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0404  ROUGE2: 20.0949  ROUGEL: 29.9329  GEN_LEN: 4100496",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 13083.5,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c84c41f3ee884012",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5999  ROUGE2: 22.1861  ROUGEL: 28.805  TOKENS_PER_SAMPLE: 291.4",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 15875.8,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bf52f318abf8491c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5887  ROUGE2: 22.1721  ROUGEL: 28.7905  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 13074.7,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5d57867037354137",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5999  ROUGE2: 22.1861  ROUGEL: 28.805  TOKENS_PER_SAMPLE: 291.4",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 15875.8,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3cad48b43768402e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5887  ROUGE2: 22.1721  ROUGEL: 28.7905  TOKENS_PER_SAMPLE: 291.7",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 13074.7,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b37b755c61e449c6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 541887,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a5db8302a357433e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 500148,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "36a3b055587a44b1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.316",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 10867,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fe9405af1b4144d2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.323",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 9001.86,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d240feffb9904102",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.775710510313512  FID_SCORE: 23.591378885495033",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 11.827,
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8d6da76f244b4278",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.788790368437766  FID_SCORE: 23.667217941120725",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 11.6801,
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b99e2d2a4e4d440e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.5",
    "system.host_memory_capacity": "3 TB",
    "system.host_memory_configuration": "24x 128GB HMCT04MEERA131N",
    "system.host_network_card_count": "4",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "84",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "10 TB SSD",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.5, cuDNN 8.9.7, Driver 555.42",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Lenovo",
    "system.sw_notes": "",
    "system.system_name": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SR675_V3_8xH100_NVL_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Lenovo/systems/SR675_V3_8xH100_NVL_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.3329  ROUGE2: 22.0197  ROUGEL: 28.598  TOKENS_PER_SAMPLE: 300.5",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NeuralMagic",
    "Platform": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 948.198,
    "Scenario": "Offline",
    "SystemName": "Crusoe Cloud L40S (8x L40S PCIe, vLLM, FP8)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8299e3dd5e014aff",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "1.5T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.3 MiB (40 instances), L1i cache: 1.3 MiB (40 instances), L2 cache: 40 MiB (40 instances), L3 cache: 160 MiB (5 instances)",
    "system.host_processor_core_count": "4",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.3T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "Crusoe Cloud L40S (8x L40S PCIe, vLLM, FP8)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "",
    "system_file_name": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NeuralMagic/systems/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.4766  ROUGE2: 22.0865  ROUGEL: 28.6953  TOKENS_PER_SAMPLE: 295.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NeuralMagic",
    "Platform": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 592.265,
    "Scenario": "Server",
    "SystemName": "Crusoe Cloud L40S (8x L40S PCIe, vLLM, FP8)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "994bbea7f1a341c7",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "1.5T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.3 MiB (40 instances), L1i cache: 1.3 MiB (40 instances), L2 cache: 40 MiB (40 instances), L3 cache: 160 MiB (5 instances)",
    "system.host_processor_core_count": "4",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.3T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "Crusoe Cloud L40S (8x L40S PCIe, vLLM, FP8)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "",
    "system_file_name": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NeuralMagic/systems/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.7986  ROUGE2: 22.3524  ROUGEL: 29.161  TOKENS_PER_SAMPLE: 274.0",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "B200-SXM-180GBx1_TRT",
    "Result": 11264.4,
    "Scenario": "Offline",
    "SystemName": "NVIDIA B200 (1x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5875c39c70854982",
    "errors": 0,
    "framework": "TensorRT 10.1.0, CUDA 12.7",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4410Y",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "B200 TGP 1000W. Private git hash for code and TRTLLM were used to generate the preview results. The git hash are eba031f9e2e6cf3d1cdce0549511d27adf01a3f4 and 4e5b175cc80320789ba6846ced80a87f25e70fb2",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "180 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.1.0, CUDA 12.7",
    "system.host_memory_capacity": "408GB",
    "system.host_memory_configuration": "6x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "2x 10Gbe",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "12",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Silver 4410Y",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "B200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.1.0, CUDA 12.7, cuDNN 8.9.7, Driver 565",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "Private git hash for code and TRTLLM were used to generate the preview results. The git hash are eba031f9e2e6cf3d1cdce0549511d27adf01a3f4 and 4e5b175cc80320789ba6846ced80a87f25e70fb2",
    "system.system_name": "NVIDIA B200 (1x B200-SXM-180GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "B200-SXM-180GBx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/B200-SXM-180GBx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.8023  ROUGE2: 22.355  ROUGEL: 29.1623  TOKENS_PER_SAMPLE: 273.9",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "B200-SXM-180GBx1_TRT",
    "Result": 10755.6,
    "Scenario": "Server",
    "SystemName": "NVIDIA B200 (1x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f3086f2193bb40a4",
    "errors": 0,
    "framework": "TensorRT 10.1.0, CUDA 12.7",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4410Y",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "B200 TGP 1000W. Private git hash for code and TRTLLM were used to generate the preview results. The git hash are eba031f9e2e6cf3d1cdce0549511d27adf01a3f4 and 4e5b175cc80320789ba6846ced80a87f25e70fb2",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "180 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.1.0, CUDA 12.7",
    "system.host_memory_capacity": "408GB",
    "system.host_memory_configuration": "6x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "2x 10Gbe",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "12",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Silver 4410Y",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "B200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.1.0, CUDA 12.7, cuDNN 8.9.7, Driver 565",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "Private git hash for code and TRTLLM were used to generate the preview results. The git hash are eba031f9e2e6cf3d1cdce0549511d27adf01a3f4 and 4e5b175cc80320789ba6846ced80a87f25e70fb2",
    "system.system_name": "NVIDIA B200 (1x B200-SXM-180GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "B200-SXM-180GBx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/B200-SXM-180GBx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.7986  ROUGE2: 22.3524  ROUGEL: 29.161  TOKENS_PER_SAMPLE: 274.0",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "B200-SXM-180GBx1_TRT",
    "Result": 11264.4,
    "Scenario": "Offline",
    "SystemName": "NVIDIA B200 (1x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c2da4cca7f8c4a8d",
    "errors": 0,
    "framework": "TensorRT 10.1.0, CUDA 12.7",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4410Y",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "B200 TGP 1000W. Private git hash for code and TRTLLM were used to generate the preview results. The git hash are eba031f9e2e6cf3d1cdce0549511d27adf01a3f4 and 4e5b175cc80320789ba6846ced80a87f25e70fb2",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "180 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.1.0, CUDA 12.7",
    "system.host_memory_capacity": "408GB",
    "system.host_memory_configuration": "6x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "2x 10Gbe",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "12",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Silver 4410Y",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "B200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.1.0, CUDA 12.7, cuDNN 8.9.7, Driver 565",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "Private git hash for code and TRTLLM were used to generate the preview results. The git hash are eba031f9e2e6cf3d1cdce0549511d27adf01a3f4 and 4e5b175cc80320789ba6846ced80a87f25e70fb2",
    "system.system_name": "NVIDIA B200 (1x B200-SXM-180GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "B200-SXM-180GBx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/B200-SXM-180GBx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.8023  ROUGE2: 22.355  ROUGEL: 29.1623  TOKENS_PER_SAMPLE: 273.9",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "B200-SXM-180GBx1_TRT",
    "Result": 10755.6,
    "Scenario": "Server",
    "SystemName": "NVIDIA B200 (1x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7c61a69a4ce94f70",
    "errors": 0,
    "framework": "TensorRT 10.1.0, CUDA 12.7",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4410Y",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "B200 TGP 1000W. Private git hash for code and TRTLLM were used to generate the preview results. The git hash are eba031f9e2e6cf3d1cdce0549511d27adf01a3f4 and 4e5b175cc80320789ba6846ced80a87f25e70fb2",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "180 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.1.0, CUDA 12.7",
    "system.host_memory_capacity": "408GB",
    "system.host_memory_configuration": "6x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "2x 10Gbe",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "Ethernet on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "12",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Silver 4410Y",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "B200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.1.0, CUDA 12.7, cuDNN 8.9.7, Driver 565",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "preview",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "Private git hash for code and TRTLLM were used to generate the preview results. The git hash are eba031f9e2e6cf3d1cdce0549511d27adf01a3f4 and 4e5b175cc80320789ba6846ced80a87f25e70fb2",
    "system.system_name": "NVIDIA B200 (1x B200-SXM-180GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "B200-SXM-180GBx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/B200-SXM-180GBx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 595658,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f7bc1edaa58943e2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 510155,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "01f537d53967442b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 361613,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bcb99a2b44de460a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 340067,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f24c742ffc5b4e45",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 19739.8,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d759ff5147d84bb9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0996  ROUGE2: 20.1107  ROUGEL: 29.9733  GEN_LEN: 4114082",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 19233.8,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1fc532fb2df64b4a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 19739.8,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "07c91a9edf4545be",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0996  ROUGE2: 20.1107  ROUGEL: 29.9733  GEN_LEN: 4114082",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 19233.8,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "47dd2bf86fcf4d2a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5437  ROUGE2: 22.1222  ROUGEL: 28.7396  TOKENS_PER_SAMPLE: 290.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 24524.9,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7138c58328964e0e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5435  ROUGE2: 22.122  ROUGEL: 28.7395  TOKENS_PER_SAMPLE: 290.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 21605.8,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8ffb0c3b5c7541c6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5437  ROUGE2: 22.1222  ROUGEL: 28.7396  TOKENS_PER_SAMPLE: 290.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 24524.9,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "73728479d1ca4ea9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5435  ROUGE2: 22.122  ROUGEL: 28.7395  TOKENS_PER_SAMPLE: 290.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 21605.8,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ab14d468cb284f0f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3448  ROUGE2: 23.2415  ROUGEL: 30.3087  TOKENS_PER_SAMPLE: 146.0  gsm8k_accuracy: 73.12  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 52415.9,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5b547f884eba47f0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3537  ROUGE2: 23.2446  ROUGEL: 30.3114  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 50795.6,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "46bf49a0613049ce",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.78304835319519  FID_SCORE: 23.454395533934246",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 16.3484,
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d6943799618844fa",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.782496818602084  FID_SCORE: 23.783885939397976",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 15.7189,
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "597b327b1a3f4cf1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "DGX-H100_H100-SXM-80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/DGX-H100_H100-SXM-80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 86731.2,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9bbf31358c73407b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 81009.7,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1b246ca575dc49ab",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 53420.6,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "372c4e84be124922",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 51014.2,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "69d3912efd5a43dc",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2627.69,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "410c8d452aef4024",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1002  ROUGE2: 20.1114  ROUGEL: 29.9742  GEN_LEN: 4114259",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2513.38,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8945865c53b04a8d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2627.69,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fc1ba15a851041fe",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1002  ROUGE2: 20.1114  ROUGEL: 29.9742  GEN_LEN: 4114259",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2513.38,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6dc9caecd4c94263",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5631  ROUGE2: 22.1578  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 4067.52,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7148ce73d794495b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.563  ROUGE2: 22.1576  ROUGEL: 28.7742  TOKENS_PER_SAMPLE: 291.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 3883.67,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "027f1af4fd7d487f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5631  ROUGE2: 22.1578  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 4067.52,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "738dc0bd6ae94f73",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.563  ROUGE2: 22.1576  ROUGEL: 28.7742  TOKENS_PER_SAMPLE: 291.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 3883.67,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "79bc025364d340b0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3572  ROUGE2: 23.2487  ROUGEL: 30.3161  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.92",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 8021.46,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "31a6a0c198954263",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3563  ROUGE2: 23.2486  ROUGEL: 30.3161  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.94",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 7450.27,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fca13a038b7b44d3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.780162643492222  FID_SCORE: 23.69402235901714",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.30033,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fdb0c761547b4fe4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.785339580476283  FID_SCORE: 23.682069447732033",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2.01829,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "988cb5bb1dda499e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "144 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x Mellanox MT2894 [ConnectX-6 Lx]",
    "system.host_networking": "Ethernet(IPoIB); Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet(IPoIB)/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA GH200 144GB HBM3e",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 560.30",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5631  ROUGE2: 22.1578  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx1_TRT",
    "Result": 4487.88,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "693be369354f42ea",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air/liquid cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA12",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GB-CTSx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GB-CTSx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5629  ROUGE2: 22.1577  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx1_TRT",
    "Result": 4202.3,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fa44b541511d4470",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air/liquid cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA12",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GB-CTSx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GB-CTSx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5631  ROUGE2: 22.1578  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx1_TRT",
    "Result": 4487.88,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f88fa3026f3540e3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air/liquid cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA12",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GB-CTSx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GB-CTSx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5629  ROUGE2: 22.1577  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx1_TRT",
    "Result": 4202.3,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e50c8f96e84c44a7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air/liquid cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA12",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GB-CTSx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GB-CTSx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5631  ROUGE2: 22.1578  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx8_TRT",
    "Result": 34864.2,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bb51c989aa5d4a0e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air/liquid cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA12",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GB-CTSx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GB-CTSx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5618  ROUGE2: 22.1563  ROUGEL: 28.7731  TOKENS_PER_SAMPLE: 291.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx8_TRT",
    "Result": 32789.7,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "903b5af9d64c4532",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air/liquid cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA12",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GB-CTSx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GB-CTSx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5631  ROUGE2: 22.1578  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx8_TRT",
    "Result": 34864.2,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "88b49451206a4715",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air/liquid cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA12",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GB-CTSx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GB-CTSx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5618  ROUGE2: 22.1563  ROUGEL: 28.7731  TOKENS_PER_SAMPLE: 291.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx8_TRT",
    "Result": 32789.7,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "58445342ab134046",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air/liquid cooling",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA12",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 1000W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GB-CTSx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GB-CTSx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT",
    "Result": 2579.51,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "079fc13d21ea4b7b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1016  ROUGE2: 20.1124  ROUGEL: 29.9751  GEN_LEN: 4114376",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT",
    "Result": 2405.86,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4324c03b232d44ee",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT",
    "Result": 2579.51,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "80c983728059443c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1016  ROUGE2: 20.1124  ROUGEL: 29.9751  GEN_LEN: 4114376",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT",
    "Result": 2405.86,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bee91fa481c445b0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 54.7136,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "747ed65358d04c5f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 54.7136,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9e010c4519834c79",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 73309.5,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7c2b85f0441a4281",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 57609.3,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6ad39edeaef44e7b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 63950.4,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6dd0d59d32654474",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 51212,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6b47e838b8ef44fe",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 637342,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "536e8a522a4347e5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 585208,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "491c33932f834185",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 390953,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ce06099339f447c5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 370083,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ce8322783dba4ecf",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 20086.1,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b621eb32b6af490b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1027  ROUGE2: 20.1139  ROUGEL: 29.9764  GEN_LEN: 4113784",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 19243.3,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "15f0b1fd01324bdd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 20086.1,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3f5b3171cff24b13",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1027  ROUGE2: 20.1139  ROUGEL: 29.9764  GEN_LEN: 4113784",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 19243.3,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "649e423eef344602",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.563  ROUGE2: 22.1578  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 31302.7,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ac50d45cdaad408a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5616  ROUGE2: 22.1566  ROUGEL: 28.7725  TOKENS_PER_SAMPLE: 291.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 29228.2,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bd53cf6a72f4487f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.563  ROUGE2: 22.1578  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 31302.7,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cbff741756d74a51",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5616  ROUGE2: 22.1566  ROUGEL: 28.7725  TOKENS_PER_SAMPLE: 291.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 29228.2,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9951c8b5c6be4460",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3568  ROUGE2: 23.2496  ROUGEL: 30.3171  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 59022.3,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1badcf0834b0465e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3535  ROUGE2: 23.2468  ROUGEL: 30.3146  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.12  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 57177.2,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "974724fd05bd4219",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.076",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 756960,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "49598e7f8f1646bf",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.076",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 632229,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3479096f58364c72",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.283",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 14439,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a0e942560c7b4143",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.325",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 13604,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6ac38d5647604677",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.783374754488467  FID_SCORE: 23.616124120013183",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 17.4186,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8cec111bdb9c4e83",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.77436184436083  FID_SCORE: 23.7889031261833",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 16.782,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "77ac27eb69044dc2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 41.664,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e7bd6b42e3414c91",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 4613.619383259915,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0acfdc5809754a81",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 41.664,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bf66707f18f449f8",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 4613.619383259915,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "01a7533bed75415e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 54063.2,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e072c8f1d25b4d95",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 5531.247344461301,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5459b3cd76c24a3f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 41599.4,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f1171b57290d41f6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 5235.63,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fea086bf6f8b4e40",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 46534.6,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "64ca9f328f5d4b3d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 5628.78770718232,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a4bf64a7e6864c99",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.9872537694998",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 39804.3,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ccf94bcfe23d42bd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.9872537694998",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 5639.263333333329,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6c5a72d181bf4518",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 503719,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4bfda600d7bd4c9e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 5997.418914473679,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9cd39029cd484118",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 420107,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ba9775451c2c4770",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 6068.710000000003,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9edab5a672864a49",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 305223,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4af0888b355149a6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 6035.110518518512,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b928bede21e54d85",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 280045,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "47904dbf5b6a48c2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 6064.624999999997,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f3530c69f939441a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 13096.6,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "eff671a7e624456e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 4775.270359848483,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dd842d05c64846fd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0987  ROUGE2: 20.1115  ROUGEL: 29.9736  GEN_LEN: 4114209",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 11700.8,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "abad7cd01e354426",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0987  ROUGE2: 20.1115  ROUGEL: 29.9736  GEN_LEN: 4114209",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 4722.561172741678,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e1781b5d36164f44",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 13096.6,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0d4d08500e0c4ce3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 4775.270359848483,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0dea0266604f42e9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0987  ROUGE2: 20.1115  ROUGEL: 29.9736  GEN_LEN: 4114209",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 11700.8,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a13246525e3348a4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0987  ROUGE2: 20.1115  ROUGEL: 29.9736  GEN_LEN: 4114209",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 4722.561172741678,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fc60f3da5ee741a6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.563  ROUGE2: 22.1578  ROUGEL: 28.7741  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 25262.1,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9bd28eb493374f5f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.563  ROUGE2: 22.1578  ROUGEL: 28.7741  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 6152.984435173287,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9a07353c60444d6b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5622  ROUGE2: 22.1565  ROUGEL: 28.7734  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 23113.1,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3c67ec37b3e441e4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5622  ROUGE2: 22.1565  ROUGEL: 28.7734  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 6280.213999999994,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ab0bdd90f62043d0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.563  ROUGE2: 22.1578  ROUGEL: 28.7741  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 25262.1,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c1f64c0907d94b6c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.563  ROUGE2: 22.1578  ROUGEL: 28.7741  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 6152.984435173287,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ec6b93c8152541c4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5622  ROUGE2: 22.1565  ROUGEL: 28.7734  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 23113.1,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4ce059fb8f0340bc",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5622  ROUGE2: 22.1565  ROUGEL: 28.7734  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 6280.213999999994,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7a64c60c1be3476e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3568  ROUGE2: 23.2496  ROUGEL: 30.3171  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 48987.9,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "80865c46ec5a4dfe",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3568  ROUGE2: 23.2496  ROUGEL: 30.3171  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 6154.803549382717,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "29d61a95405b41ef",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3548  ROUGE2: 23.2479  ROUGEL: 30.3149  TOKENS_PER_SAMPLE: 146.0  gsm8k_accuracy: 73.12  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 45497,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dcfb7d52721f407e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3548  ROUGE2: 23.2479  ROUGEL: 30.3149  TOKENS_PER_SAMPLE: 146.0  gsm8k_accuracy: 73.12  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 6174.896328382817,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c77c80f76a294d0b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.076",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 556234,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1f38978ff9aa4004",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.076",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 4954.031546707506,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5754b07376904156",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.076",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 480131,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "95a309ae824444e6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.076",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 5013.79116666667,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "07e7dd75c96048a3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.268",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 10802.5,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e91083ea6e5143ff",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.268",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 5019.128805237312,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3cbc2a7a32b6418c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.320",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 9602.95,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "88b0a68300724cf6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.320",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 4987.039666666663,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9b27ea8341ac4f3e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.792848083078862  FID_SCORE: 23.538694089414037",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 13.202,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6b308b58139a49a6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.792848083078862  FID_SCORE: 23.538694089414037",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 5573.811127596441,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f056f32116104034",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.789476112425326  FID_SCORE: 23.744204398924808",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 12.708,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "92100b81a851432a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.789476112425326  FID_SCORE: 23.744204398924808",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_MaxQ",
    "Result": 5487.744754098365,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3ba828f9933c493d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, MaxQ, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_MaxQ.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_MaxQ/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_MaxQ.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.5638  ROUGE2: 22.1581  ROUGEL: 28.7745  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_Triton",
    "Result": 31059.3,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bd65bed3a52a4b16",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54, Triton 24.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT, Triton)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_Triton.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_Triton.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5623  ROUGE2: 22.1574  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 292.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_Triton",
    "Result": 30128.4,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "97af6381765c4a0d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54, Triton 24.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT, Triton)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_Triton.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_Triton.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5638  ROUGE2: 22.1581  ROUGEL: 28.7745  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_Triton",
    "Result": 31059.3,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fcd8616d8dda468b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54, Triton 24.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT, Triton)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_Triton.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_Triton.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5623  ROUGE2: 22.1574  ROUGEL: 28.774  TOKENS_PER_SAMPLE: 292.2",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_Triton",
    "Result": 30128.4,
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fb9a1e4d80be4420",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54, Triton 24.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT, Triton)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx8_TRT_Triton.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/H200-SXM-141GBx8_TRT_Triton.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 42.9198  ROUGE2: 20.1178  ROUGEL: 29.9386  GEN_LEN: 4050052",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 64.4734,
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "08fc88dd0b144fc0",
    "errors": 0,
    "framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r36.3.1 L4T",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "Shared with host",
    "system.accelerator_memory_configuration": "LPDDR5",
    "system.accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "eMMC 5.1",
    "system.disk_drives": "eMMC 5.1",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "64GB 256-bit LPDDR5",
    "system.host_network_card_count": "1 Integrated",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "USB forwarded",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "12",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "64 GB eMMC, 5TB CIFS",
    "system.host_storage_type": "eMMC 5.1, CIFS mounted disk storage",
    "system.hw_notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Jetson r36.3.1 L4T",
    "system.other_hardware": "",
    "system.other_software_stack": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2, cuDNN 8.9.4",
    "system.power_management": "",
    "system.power_supply_details": "Dell USB-C 130.0W Adapter (HA130PM170)",
    "system.power_supply_quantity_and_rating_watts": "130W",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Orin_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/Orin_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/Orin_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 42.9603  ROUGE2: 20.1366  ROUGEL: 29.9612  GEN_LEN: 4047046",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/gptj-99/SingleStream",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 4176.62608,
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "84c8a244770a4df3",
    "errors": 0,
    "framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r36.3.1 L4T",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "Shared with host",
    "system.accelerator_memory_configuration": "LPDDR5",
    "system.accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "eMMC 5.1",
    "system.disk_drives": "eMMC 5.1",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "64GB 256-bit LPDDR5",
    "system.host_network_card_count": "1 Integrated",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "USB forwarded",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "12",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "64 GB eMMC, 5TB CIFS",
    "system.host_storage_type": "eMMC 5.1, CIFS mounted disk storage",
    "system.hw_notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Jetson r36.3.1 L4T",
    "system.other_hardware": "",
    "system.other_software_stack": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2, cuDNN 8.9.4",
    "system.power_management": "",
    "system.power_supply_details": "Dell USB-C 130.0W Adapter (HA130PM170)",
    "system.power_supply_quantity_and_rating_watts": "130W",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Orin_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/Orin_TRT/gptj-99/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/Orin_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80647490143776  FID_SCORE: 23.440386233648724",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 0.101697,
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "18881162c80b4b3c",
    "errors": 0,
    "framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r36.3.1 L4T",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "Shared with host",
    "system.accelerator_memory_configuration": "LPDDR5",
    "system.accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "eMMC 5.1",
    "system.disk_drives": "eMMC 5.1",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "64GB 256-bit LPDDR5",
    "system.host_network_card_count": "1 Integrated",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "USB forwarded",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "12",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "64 GB eMMC, 5TB CIFS",
    "system.host_storage_type": "eMMC 5.1, CIFS mounted disk storage",
    "system.hw_notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Jetson r36.3.1 L4T",
    "system.other_hardware": "",
    "system.other_software_stack": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2, cuDNN 8.9.4",
    "system.power_management": "",
    "system.power_supply_details": "Dell USB-C 130.0W Adapter (HA130PM170)",
    "system.power_supply_quantity_and_rating_watts": "130W",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Orin_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/Orin_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.799790530204774  FID_SCORE: 23.352912953334226",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/SingleStream",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT",
    "Result": 9966.781359,
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "49167866c80045bd",
    "errors": 0,
    "framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r36.3.1 L4T",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "Shared with host",
    "system.accelerator_memory_configuration": "LPDDR5",
    "system.accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "eMMC 5.1",
    "system.disk_drives": "eMMC 5.1",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "64GB 256-bit LPDDR5",
    "system.host_network_card_count": "1 Integrated",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "USB forwarded",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "12",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "64 GB eMMC, 5TB CIFS",
    "system.host_storage_type": "eMMC 5.1, CIFS mounted disk storage",
    "system.hw_notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Jetson r36.3.1 L4T",
    "system.other_hardware": "",
    "system.other_software_stack": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2, cuDNN 8.9.4",
    "system.power_management": "",
    "system.power_supply_details": "Dell USB-C 130.0W Adapter (HA130PM170)",
    "system.power_supply_quantity_and_rating_watts": "130W",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "system.system_type": "edge",
    "system.system_type_detail": "N/A",
    "system_file_name": "Orin_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/results/Orin_TRT/stable-diffusion-xl/SingleStream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/NVIDIA/systems/Orin_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 6.73664,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b3c4432c531a4b1b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 6.73664,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "284daf2768a44d8b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 9864.25,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9637fddfce8a4227",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 6501.91,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c0b0e574a41a4bf7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 8779.27,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "46f45bf29d684ba1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.96741537056405",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 4502.76,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ebe3655cb4dd4171",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0794  ROUGE2: 20.1138  ROUGEL: 29.9751  GEN_LEN: 4110737",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2695.15,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "95d412135b1d4fa2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0794  ROUGE2: 20.1138  ROUGEL: 29.9751  GEN_LEN: 4110737",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2159.58,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "948ec1133c2f4c86",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0794  ROUGE2: 20.1138  ROUGEL: 29.9751  GEN_LEN: 4110737",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2695.15,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b49190f0db524321",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0794  ROUGE2: 20.1138  ROUGEL: 29.9751  GEN_LEN: 4110737",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2159.58,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "13e2c79c341840d8",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 95104.5,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6715fef36e114c54",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 77012.2,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1e4b490344934d9d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.300",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1923.46,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "497ca93ba2384d70",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.331",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1731.13,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "388f17bc56254ffb",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD, Block Storage",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.6, Driver 550.90.07, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86175",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1.86148,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2495759c72b8412d",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "N/A",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024 GB",
    "system.host_memory_configuration": "DDR5-5600 64GB x16",
    "system.host_network_card_count": "1x 400Gb InfiniBand",
    "system.host_networking": "InfiniBand; Data bandwidth for PCIe-NIC: 50GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "512GB + 7TB (3.5TB x 2)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "QuantaGrid D54X-1U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "5.14.0-284.11.1.el9_2.x86_64",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1612.03,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bde2cc1086be46ae",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "N/A",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024 GB",
    "system.host_memory_configuration": "DDR5-5600 64GB x16",
    "system.host_network_card_count": "1x 400Gb InfiniBand",
    "system.host_networking": "InfiniBand; Data bandwidth for PCIe-NIC: 50GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "512GB + 7TB (3.5TB x 2)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "QuantaGrid D54X-1U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "5.14.0-284.11.1.el9_2.x86_64",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1241.42,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d8235f739ee24685",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "N/A",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024 GB",
    "system.host_memory_configuration": "DDR5-5600 64GB x16",
    "system.host_network_card_count": "1x 400Gb InfiniBand",
    "system.host_networking": "InfiniBand; Data bandwidth for PCIe-NIC: 50GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "512GB + 7TB (3.5TB x 2)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "QuantaGrid D54X-1U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "5.14.0-284.11.1.el9_2.x86_64",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.23785974349185",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 9962.84,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "74a4ec016ea347e7",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "N/A",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024 GB",
    "system.host_memory_configuration": "DDR5-5600 64GB x16",
    "system.host_network_card_count": "1x 400Gb InfiniBand",
    "system.host_networking": "InfiniBand; Data bandwidth for PCIe-NIC: 50GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "512GB + 7TB (3.5TB x 2)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "QuantaGrid D54X-1U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "5.14.0-284.11.1.el9_2.x86_64",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.23785974349185",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 9102.37,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a5fb01c055264ecd",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "N/A",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024 GB",
    "system.host_memory_configuration": "DDR5-5600 64GB x16",
    "system.host_network_card_count": "1x 400Gb InfiniBand",
    "system.host_networking": "InfiniBand; Data bandwidth for PCIe-NIC: 50GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "512GB + 7TB (3.5TB x 2)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "QuantaGrid D54X-1U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "5.14.0-284.11.1.el9_2.x86_64",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0482  ROUGE2: 20.1537  ROUGEL: 29.9649  GEN_LEN: 4105880",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 239.034,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b69b6644ba9c4781",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "N/A",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024 GB",
    "system.host_memory_configuration": "DDR5-5600 64GB x16",
    "system.host_network_card_count": "1x 400Gb InfiniBand",
    "system.host_networking": "InfiniBand; Data bandwidth for PCIe-NIC: 50GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "512GB + 7TB (3.5TB x 2)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "QuantaGrid D54X-1U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "5.14.0-284.11.1.el9_2.x86_64",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "ROUGE1: 43.1294  ROUGE2: 20.211  ROUGEL: 29.9883  GEN_LEN: 4114267",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 113.732,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b538189782314932",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "N/A",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024 GB",
    "system.host_memory_configuration": "DDR5-5600 64GB x16",
    "system.host_network_card_count": "1x 400Gb InfiniBand",
    "system.host_networking": "InfiniBand; Data bandwidth for PCIe-NIC: 50GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "512GB + 7TB (3.5TB x 2)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "QuantaGrid D54X-1U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "5.14.0-284.11.1.el9_2.x86_64",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 24491.1,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9bcb1fd6e3cc4838",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "N/A",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024 GB",
    "system.host_memory_configuration": "DDR5-5600 64GB x16",
    "system.host_network_card_count": "1x 400Gb InfiniBand",
    "system.host_networking": "InfiniBand; Data bandwidth for PCIe-NIC: 50GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "512GB + 7TB (3.5TB x 2)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "QuantaGrid D54X-1U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "5.14.0-284.11.1.el9_2.x86_64",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 22501.7,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6e3b2828bc8e44c4",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "N/A",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024 GB",
    "system.host_memory_configuration": "DDR5-5600 64GB x16",
    "system.host_network_card_count": "1x 400Gb InfiniBand",
    "system.host_networking": "InfiniBand; Data bandwidth for PCIe-NIC: 50GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "512GB + 7TB (3.5TB x 2)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "QuantaGrid D54X-1U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "5.14.0-284.11.1.el9_2.x86_64",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.357",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 372.132,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f7a3f960299d4962",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "N/A",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024 GB",
    "system.host_memory_configuration": "DDR5-5600 64GB x16",
    "system.host_network_card_count": "1x 400Gb InfiniBand",
    "system.host_networking": "InfiniBand; Data bandwidth for PCIe-NIC: 50GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "512GB + 7TB (3.5TB x 2)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "QuantaGrid D54X-1U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "5.14.0-284.11.1.el9_2.x86_64",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "mAP: 37.357",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 280.447,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5a48d67ec5674264",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "N/A",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024 GB",
    "system.host_memory_configuration": "DDR5-5600 64GB x16",
    "system.host_network_card_count": "1x 400Gb InfiniBand",
    "system.host_networking": "InfiniBand; Data bandwidth for PCIe-NIC: 50GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "512GB + 7TB (3.5TB x 2)",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "QuantaGrid D54X-1U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "5.14.0-284.11.1.el9_2.x86_64",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "DICE: 0.86111",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 18.447,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ece26061ea6c4d18",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86111",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 18.447,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f21a923e91644cfb",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 23131.4,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c5be5407aa8c4e5b",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 17759.3,
    "Scenario": "Server",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "30108965a05d4bc0",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 184239,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9fa10fcce65146bf",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 175023,
    "Scenario": "Server",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d1bc31d33c07474e",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 106363,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1c0a3520869843bc",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 100010,
    "Scenario": "Server",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "264594a1b70646fd",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 224868,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0dae3018d64741f3",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 188028,
    "Scenario": "Server",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ab98755ddd5f47de",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.312",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4633.9,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "95ae89ee26a34086",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.298",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4003.24,
    "Scenario": "Server",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "34a207d126884d40",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.793397405743598  FID_SCORE: 23.613682317785788",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4.91259,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1de21f1bfb854c6b",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.78107093989849  FID_SCORE: 23.871544544155654",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4.0094,
    "Scenario": "Server",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2f0c1f9f246b42ca",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "PCIe Gen5 x16, NVLink 600GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "52",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.90.07",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_H100_PCIe_80GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86017",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 15.551,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9d3ddc0f208a4404",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.23535730698143",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 13248.3,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "29e8ab7f8e724ebf",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.25897829249658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 12002.4,
    "Scenario": "Server",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "eacaa2d79c1e42fb",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 115424,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0d1ee6cfe8b34b49",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 84409,
    "Scenario": "Server",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6d577e6935ca469e",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.248",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 51911.1,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8be9966b05e247bf",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.248",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 51015.1,
    "Scenario": "Server",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "bba97e2067594dd7",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0913  ROUGE2: 20.1321  ROUGEL: 29.9767  GEN_LEN: 4113606",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 3463.19,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "75e04d72899547ca",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0892  ROUGE2: 20.1306  ROUGEL: 29.9753  GEN_LEN: 4113194",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 3096.45,
    "Scenario": "Server",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6ce5f14e146f4d8d",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0913  ROUGE2: 20.1321  ROUGEL: 29.9767  GEN_LEN: 4113606",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 3463.19,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b3dfed0118844b44",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0892  ROUGE2: 20.1306  ROUGEL: 29.9753  GEN_LEN: 4113194",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 3096.45,
    "Scenario": "Server",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8c9201d15ba94c6b",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 174603,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5fab25b59c3c4af1",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 150015,
    "Scenario": "Server",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2100c146b1eb4fba",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.341",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 3191.45,
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b22b557b2e734835",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.330",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 3001.4,
    "Scenario": "Server",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d2849a89c636493f",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "1 TB",
    "system.host_memory_configuration": " DDR4-4800 64GB x 16",
    "system.host_network_card_count": "2x 400Gb InfiniBand",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 252GB/s; PCIe-NIC: 100GB/s",
    "system.host_networking_topology": "Ethernet/InfiniBand on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "44",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "28 TB",
    "system.host_storage_type": "NVMe SSD 7TB x 4",
    "system.hw_notes": "QuantaGrid D54U-3U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.2",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/D54U_3U_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 6.77957,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ba19b19add5148c0",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 6.77957,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f5bc33c380a74c43",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 9196.01,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2ebb84cdc21640cc",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 7103.12,
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "58789023ca7c4869",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 8092.46,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "19f0e97498334160",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97309181332659",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 6600.99,
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c8a92dc4858e4f8d",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 80878.4,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e2d55608fc3c474c",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 77511.7,
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "192c7fd5b4464164",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 48197,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a8c4dad47506412e",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 46207.5,
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9804884e9b824d77",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0658  ROUGE2: 20.1299  ROUGEL: 29.9759  GEN_LEN: 4108404",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2803.72,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f6065a47620247e9",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0658  ROUGE2: 20.1298  ROUGEL: 29.9758  GEN_LEN: 4108405",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2160.12,
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e9d6caae4f5e4bd2",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0658  ROUGE2: 20.1299  ROUGEL: 29.9759  GEN_LEN: 4108404",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2803.72,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1dbe1680f996423e",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0658  ROUGE2: 20.1298  ROUGEL: 29.9758  GEN_LEN: 4108405",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2160.12,
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1992060539af44db",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5991  ROUGE2: 22.1726  ROUGEL: 28.8022  TOKENS_PER_SAMPLE: 291.8",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 3114.03,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "37f84c18ae5c43e8",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5947  ROUGE2: 22.1631  ROUGEL: 28.793  TOKENS_PER_SAMPLE: 291.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2619.09,
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "496474fe68d948f6",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 94990.9,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "764bbc2cebd041f4",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 73014.9,
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2fef665c53c44c90",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.301",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1923.2,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b69ec6171e5b4278",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.318",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1731.14,
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f7a172b931d74ab2",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.784094333946705  FID_SCORE: 23.590545454449398",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2.08805,
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dae3420b030647ec",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.784094333946705  FID_SCORE: 23.59054545444951",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1.84443,
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "3ce6a2fe3bf342da",
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "14 TB",
    "system.host_storage_type": "NVMe SSD 3.5TB x 4",
    "system.hw_notes": "QuantaGrid S74G-2U",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Rocky Linux 9.3",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, cuDNN 8.9.7.29, Driver 550.54.14",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Quanta_Cloud_Technology",
    "system.sw_notes": "",
    "system.system_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Quanta_Cloud_Technology/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.6053  ROUGE2: 22.2332  ROUGEL: 28.8873  TOKENS_PER_SAMPLE: 291.4",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/RedHat/results/L40S-RedHat-OpenShift/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "RedHat",
    "Platform": "L40S-RedHat-OpenShift",
    "Result": 1717.77,
    "Scenario": "Offline",
    "SystemName": "L40S-RedHat-OpenShift",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0c532e8a0dc346ae",
    "errors": 0,
    "framework": "CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480CL",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA L40S-48GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5",
    "system.accelerator_interconnect": "PCIe",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "HBM2",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "NA",
    "system.division": "closed",
    "system.framework": "CUDA 12.2",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB Micron DDR5",
    "system.host_network_card_count": "-",
    "system.host_networking": "Management: 1x Ethernet 10GB/Sec",
    "system.host_networking_topology": "-",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "PCIe",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480CL",
    "system.host_processor_vcpu_count": "-",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.75 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "NVIDIA L40S-48GB",
    "system.number_of_nodes": "1",
    "system.operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "system.other_software_stack.cuda_driver_version": "535.129.03",
    "system.other_software_stack.cuda_version": "12.2",
    "system.other_software_stack.vllm": "0.5.1",
    "system.status": "available",
    "system.submitter": "RedHat",
    "system.sw_notes": "Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "system.system_name": "L40S-RedHat-OpenShift",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "L40S-RedHat-OpenShift.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/RedHat/results/L40S-RedHat-OpenShift/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/RedHat/systems/L40S-RedHat-OpenShift.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.4633  ROUGE2: 22.0929  ROUGEL: 28.7123  TOKENS_PER_SAMPLE: 295.3",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/RedHat/results/L40S-RedHat-OpenShift/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "RedHat",
    "Platform": "L40S-RedHat-OpenShift",
    "Result": 1469.19,
    "Scenario": "Server",
    "SystemName": "L40S-RedHat-OpenShift",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "492350f312d74e7a",
    "errors": 0,
    "framework": "CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480CL",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA L40S-48GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5",
    "system.accelerator_interconnect": "PCIe",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "HBM2",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "NA",
    "system.division": "closed",
    "system.framework": "CUDA 12.2",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB Micron DDR5",
    "system.host_network_card_count": "-",
    "system.host_networking": "Management: 1x Ethernet 10GB/Sec",
    "system.host_networking_topology": "-",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "112",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "PCIe",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480CL",
    "system.host_processor_vcpu_count": "-",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.75 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "NVIDIA L40S-48GB",
    "system.number_of_nodes": "1",
    "system.operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "system.other_software_stack.cuda_driver_version": "535.129.03",
    "system.other_software_stack.cuda_version": "12.2",
    "system.other_software_stack.vllm": "0.5.1",
    "system.status": "available",
    "system.submitter": "RedHat",
    "system.sw_notes": "Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "system.system_name": "L40S-RedHat-OpenShift",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "L40S-RedHat-OpenShift.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/RedHat/results/L40S-RedHat-OpenShift/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/RedHat/systems/L40S-RedHat-OpenShift.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1595.13,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5432dc4ed54f4e46",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 8.10",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky Linux 8.10",
    "system.other_software_stack": "5.14.0-427.24.1.el9_4.x86_64",
    "system.status": "available",
    "system.submitter": "supermicro",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.53885196505269",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/1-node-2S-EMR-PyTorch/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1256.61,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c98f0784e58744bf",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 8.10",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky Linux 8.10",
    "system.other_software_stack": "5.14.0-427.24.1.el9_4.x86_64",
    "system.status": "available",
    "system.submitter": "supermicro",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/1-node-2S-EMR-PyTorch/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/1-node-2S-EMR-PyTorch/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 23674.2,
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1287929a4a864506",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 8.10",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky Linux 8.10",
    "system.other_software_stack": "5.14.0-427.24.1.el9_4.x86_64",
    "system.status": "available",
    "system.submitter": "supermicro",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/1-node-2S-EMR-PyTorch/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "acc: 75.730",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/1-node-2S-EMR-PyTorch/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 21001.6,
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "99742aa43ff14a31",
    "errors": 0,
    "framework": "PyTorch",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 8.10",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "Air",
    "system.division": "closed",
    "system.framework": "PyTorch",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "8 slots / 64GB each / per socket",
    "system.host_network_card_count": "2",
    "system.host_networking": "Ethernet Controller / 10GBASE-T",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "N/A",
    "system.host_processor_core_count": "64",
    "system.host_processor_frequency": "N/A",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "N/A",
    "system.host_storage_type": "N/A",
    "system.hw_notes": "QuantaGrid D54Q-2U",
    "system.number_of_nodes": "1",
    "system.operating_system": "Rocky Linux 8.10",
    "system.other_software_stack": "5.14.0-427.24.1.el9_4.x86_64",
    "system.status": "available",
    "system.submitter": "supermicro",
    "system.sw_notes": "N/A",
    "system.system_name": "1-node-2S-EMR-PyTorch",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "1-node-2S-EMR-PyTorch.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/1-node-2S-EMR-PyTorch/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/1-node-2S-EMR-PyTorch.json",
    "version": "v4.1",
    "weight_data_types": "INT8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 52.298,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "88f62de2130840bd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 52.298,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "84707a2b7d8e4ae5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 72222.5,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6a39903741704cec",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 57846.1,
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5aead2bc0b7b4248",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 61490.8,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "29ff77f1eecc4997",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97813754022663",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 51049.3,
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "50998e4f957840a0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 370389,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "86b6cd764d1c4f2a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 354036,
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5dc878e7766242f9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19539.2,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "67b49b9a8c9f40a6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1036  ROUGE2: 20.1145  ROUGEL: 29.9777  GEN_LEN: 4113966",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19810.7,
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b1b880f04aa6451e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19539.2,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b96e5ba480c74eac",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1036  ROUGE2: 20.1145  ROUGEL: 29.9777  GEN_LEN: 4113966",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19810.7,
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "535ba4e94e3a41ee",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6153  ROUGE2: 22.179  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 24216.8,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1dac5d1a06ad41c3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6147  ROUGE2: 22.1792  ROUGEL: 28.8001  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 23699.7,
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8615fd1be7784c71",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6153  ROUGE2: 22.179  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 24216.8,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "60615343991e42e1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6147  ROUGE2: 22.1792  ROUGEL: 28.8001  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 23699.7,
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "71dabb1c84934eb5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3541  ROUGE2: 23.2468  ROUGEL: 30.3101  TOKENS_PER_SAMPLE: 146.0  gsm8k_accuracy: 73.16  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 51269,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "077ad786140a4c18",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.351  ROUGE2: 23.2445  ROUGEL: 30.3143  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 50099.5,
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f6c57886ebfc4edd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 708730,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "587647989d174bd5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 632629,
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "987ab143ce6649c0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.328",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 14460.8,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ef353e1991c14dbc",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.303",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 13803,
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4e3c4b717c0a43ec",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.79114451110363  FID_SCORE: 23.493975285434658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 16.1466,
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dcc4cab02ee748f5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80437699943781  FID_SCORE: 23.589281368064178",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 15.7157,
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a657f54ae0904aa4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2.3 TB",
    "system.host_memory_configuration": "24x 96GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 1x NVIDIA B3220 200GbE/NDR200, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "96",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9654",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 52.1198,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f73b0700273c490b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 52.1198,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6d12f90cdc69412a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 71861.8,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a557333ec2a24c60",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 57488.7,
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6736fb7d11e74838",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 61128,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c3299574a173431b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97250285963494",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 50729.5,
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "95eb512896d943f5",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 359682,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a78ac2340deb4aa0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 354035,
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "02e45a10fcc34204",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19418.9,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d35e0e5a30d14c1d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0997  ROUGE2: 20.1116  ROUGEL: 29.9738  GEN_LEN: 4114213",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19304.4,
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "68c4c8b700e24280",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19418.9,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "21d43d3a50424ec8",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0997  ROUGE2: 20.1116  ROUGEL: 29.9738  GEN_LEN: 4114213",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19304.4,
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9cde4e1a6c11407a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6153  ROUGE2: 22.1789  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 24011.7,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1ae076ff18f74b40",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6147  ROUGE2: 22.1793  ROUGEL: 28.8001  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 21775.5,
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "257dd490f6eb4b69",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6153  ROUGE2: 22.1789  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 24011.7,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8c04547175ce4852",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6147  ROUGE2: 22.1793  ROUGEL: 28.8001  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 21775.5,
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "afd526d033ee471d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3545  ROUGE2: 23.2434  ROUGEL: 30.3185  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 50970.6,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6df49c3b64d0434a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.351  ROUGE2: 23.2457  ROUGEL: 30.3126  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 49864,
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e0bfe89c606c4f5c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 703377,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "801bc5337a4c41de",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 633551,
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e520136345354bab",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.301",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 14244.1,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5c5255d600c64b1a",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.290",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 13731.3,
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d0cb1d31ae9043ff",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.795211831629278  FID_SCORE: 23.64836127640251",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 16.0092,
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "792d79c04c944856",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.78228974968195  FID_SCORE: 23.54421763378764",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 15.6683,
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "21960296dc8e4afd",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1.5 TB",
    "system.host_memory_configuration": "24x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 9x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9474F",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 15.36TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 43.0794  ROUGE2: 20.1138  ROUGEL: 29.9751  GEN_LEN: 4110737",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2659.47,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ce6589e38f804220",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "8 TB SSD",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0794  ROUGE2: 20.1138  ROUGEL: 29.9751  GEN_LEN: 4110737",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2159.89,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1bde01a719554cfe",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "8 TB SSD",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0794  ROUGE2: 20.1138  ROUGEL: 29.9751  GEN_LEN: 4110737",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2659.47,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0a3bad69bf3b4e42",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "8 TB SSD",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0794  ROUGE2: 20.1138  ROUGEL: 29.9751  GEN_LEN: 4110737",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2159.89,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "06452d8494444757",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3e",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "480 GB",
    "system.host_memory_configuration": "15x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "8 TB SSD",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 9.1.0, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 52.2025,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "4d7e0e3be3ba4823",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 52.2025,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5a0f89ab332e46c7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 72876,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9f1e4148011745cc",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 58928.5,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "307287f924d145b6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 62036.9,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5411a7e769454dbb",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.97034778976895",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 52049.4,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "00b41062a57442ff",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 602108,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "ceec64fb641948ab",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 556101,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a6fab495f52d4cb8",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 372277,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "715730a5ddab4828",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 358000,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "69863e8a15014498",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19808.2,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "419ce343201e4558",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0997  ROUGE2: 20.1114  ROUGEL: 29.9739  GEN_LEN: 4114157",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19725.6,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9e30c5391e784561",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19808.2,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "37b357a271bb41cb",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0997  ROUGE2: 20.1114  ROUGEL: 29.9739  GEN_LEN: 4114157",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19725.6,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "16bffb70fd314b4d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6153  ROUGE2: 22.1789  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 24180.6,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dd0e2d784674415f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6147  ROUGE2: 22.1792  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 21888.6,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a13e2fa0f1d04ae9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6153  ROUGE2: 22.1789  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 24180.6,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b2266f67b1b34fc7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6147  ROUGE2: 22.1792  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 21888.6,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9476d930481f4cd0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3632  ROUGE2: 23.2559  ROUGEL: 30.3191  TOKENS_PER_SAMPLE: 146.0  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 52452,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "977352eb70cc42f6",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3565  ROUGE2: 23.2475  ROUGEL: 30.3154  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.86",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 51028.4,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d97327d9f15f4ed3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 710521,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e21ef03d1d704ed3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 633672,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a476abdf47f64999",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.318",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 14538.1,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "13bef7a178db4979",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.348",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 13979.3,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "748d3a6e815742e0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.797936390638352  FID_SCORE: 23.583744373037973",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 16.4933,
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1a35a3c282814d92",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.786237963438033  FID_SCORE: 23.646704952118284",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 16.0608,
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dbe37d4d1be7491b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Liquid-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "8x NVIDIA B3140H 400GbE/NDR, 1x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1x 30.72TB, 1x 480GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 52.2038,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "79ce5dd07faf4e5c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 52.2038,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "0b95e720c6674102",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 71806.2,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "23b979b951124179",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 57928.3,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "659b8e383c224827",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 62153.9,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5fd8c13bb9af4f85",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.98343184029112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 51570.7,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7bbe99605dff44e0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 592829,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9a58145e0fa94b21",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 548900,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f0df3c4572814246",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 363656,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "209ea0dfedcd4558",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 356561,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fec3a8d9b44f4054",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19803.6,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2b26b027a1214ea8",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1015  ROUGE2: 20.1128  ROUGEL: 29.9751  GEN_LEN: 4114215",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19635.2,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "349f3e1f70b24ac9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1017  ROUGE2: 20.1125  ROUGEL: 29.9751  GEN_LEN: 4114386",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19803.6,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "32dae2d20d284f25",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.1015  ROUGE2: 20.1128  ROUGEL: 29.9751  GEN_LEN: 4114215",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19635.2,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a32762ae8f8f4e62",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6153  ROUGE2: 22.1789  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 24140.1,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "182eaf80f8ca40b7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6148  ROUGE2: 22.1792  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 21986,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "81120882dd724b21",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6153  ROUGE2: 22.1789  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 24140.1,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1d77cb5fdc404f69",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.6148  ROUGE2: 22.1792  ROUGEL: 28.8  TOKENS_PER_SAMPLE: 290.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 21986,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "08ffe9b41e6c4c19",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3558  ROUGE2: 23.2472  ROUGEL: 30.3111  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.16  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 52353.8,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a2122892eb144eed",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3545  ROUGE2: 23.2472  ROUGEL: 30.3145  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.1  mbxp_accuracy: 59.88",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 50676.9,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c790a3af1a9b4203",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 707052,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f1684672daa94b6d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 634193,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1020e961d6b447be",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.307",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 14405.1,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "fce6fa95104148d1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.343",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 13803,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "6488018bd9ae4b72",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.779239302873613  FID_SCORE: 23.569384031419247",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 16.3778,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a89b23a308ae4193",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.78609716743231  FID_SCORE: 23.561546694316576",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 15.994,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8650f30470cc4858",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5 4800MHz",
    "system.host_network_card_count": "1x Intel X550T 10GbE, 8x NVIDIA ConnectX-7 400GbE/NDR",
    "system.host_networking": "Ethernet, Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 3.84TB, 1x 960GB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54.15",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Supermicro",
    "system.sw_notes": "",
    "system.system_name": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Supermicro/systems/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/3d-unet-99/Offline",
    "MlperfModel": "3d-unet-99",
    "Model": "3d-unet-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 51.8258,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cf279af27adc4fda",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/3d-unet-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "DICE: 0.86112",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 51.8258,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "01b1ac84e83743c8",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 69043.2,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "435f79fa0fac4ee2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.35676151551918",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 56008.8,
    "Scenario": "Server",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2ef483ee90574970",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.97056894987658",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 61778.8,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "dded2dcd4f59488b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "F1: 90.96690752142804",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 49613,
    "Scenario": "Server",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "835de3a84b1b4cb0",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 597885,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1cb5881f043546fa",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99/Server",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 510155,
    "Scenario": "Server",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "354afd081b9b46a9",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 369334,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "87586882490c4453",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99.9/Server",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 340067,
    "Scenario": "Server",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "da513c85ba004388",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/dlrm-v2-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 43.0394  ROUGE2: 20.0943  ROUGEL: 29.9329  GEN_LEN: 4100159",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 19711.1,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "aef910fe805f4b1c",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/gptj-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.039  ROUGE2: 20.0945  ROUGEL: 29.933  GEN_LEN: 4100192",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/gptj-99/Server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 19233.8,
    "Scenario": "Server",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "60562be312d14a7d",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/gptj-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5768  ROUGE2: 22.1293  ROUGEL: 28.7645  TOKENS_PER_SAMPLE: 292.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 24459.6,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2d76650cc93b4ac2",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5777  ROUGE2: 22.1298  ROUGEL: 28.7648  TOKENS_PER_SAMPLE: 292.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99/Server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 21327,
    "Scenario": "Server",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a47627dc08854c7b",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5768  ROUGE2: 22.1293  ROUGEL: 28.7645  TOKENS_PER_SAMPLE: 292.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 24459.6,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "faea1b8ba2684b09",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 44.5777  ROUGE2: 22.1298  ROUGEL: 28.7648  TOKENS_PER_SAMPLE: 292.1",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99.9/Server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 21327,
    "Scenario": "Server",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a3b5507018b844ad",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3664  ROUGE2: 23.2584  ROUGEL: 30.3279  TOKENS_PER_SAMPLE: 145.9  gsm8k_accuracy: 73.08  mbxp_accuracy: 59.86",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 52817.7,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d7244093f0f448f3",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.3528  ROUGE2: 23.2465  ROUGEL: 30.3132  TOKENS_PER_SAMPLE: 146.0  gsm8k_accuracy: 73.08  mbxp_accuracy: 59.9",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 50797.2,
    "Scenario": "Server",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "283cbbcf5adf4c20",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/resnet50/Offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 706789,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "cf633e5446224cae",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/resnet50/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 76.078",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/resnet50/Server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 584207,
    "Scenario": "Server",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d2e7e345a220451e",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/resnet50/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.286",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/retinanet/Offline",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 14405.3,
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1fecd7b638674fe1",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/retinanet/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "mAP: 37.332",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 12884.5,
    "Scenario": "Server",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "85e788bd6d1246d4",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "Infiniband NDR",
    "system.accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "system.accelerator_interconnect_topology": "NVLINK + NVSWITCH",
    "system.accelerator_memory_capacity": "81559 MiB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "80 GB",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "SMC IMMERSION COOLING TECHNOLOGY",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "closed",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB DDR5",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "SMC TECHNOLOGY",
    "system.power_supply_quantity_and_rating_watts": "SMC TECHNOLOGY",
    "system.status": "available",
    "system.submitter": "Sustainable_Metal_Cloud",
    "system.sw_notes": "",
    "system.system_name": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "SMC_H100_SXM_80GBX8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/retinanet/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/Sustainable_Metal_Cloud/systems/SMC_H100_SXM_80GBX8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u1_preview/resnet50/multistream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u1_preview",
    "Result": 0.290617,
    "Scenario": "MultiStream",
    "SystemName": "Supermicro SuperServer H13 (1x speedAI240 Preview)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "UntetherAI speedAI240 Preview",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "d39b26fccaa64978",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Preview",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "preview",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (1x speedAI240 Preview)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u1_preview.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u1_preview/resnet50/multistream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u1_preview.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u1_preview/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u1_preview",
    "Result": 70348.2,
    "Scenario": "Offline",
    "SystemName": "Supermicro SuperServer H13 (1x speedAI240 Preview)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "UntetherAI speedAI240 Preview",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8705afcfbea74969",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Preview",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "preview",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (1x speedAI240 Preview)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u1_preview.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u1_preview/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u1_preview.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u1_preview/resnet50/singlestream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u1_preview",
    "Result": 0.119199,
    "Scenario": "SingleStream",
    "SystemName": "Supermicro SuperServer H13 (1x speedAI240 Preview)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "UntetherAI speedAI240 Preview",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "aa82e458ba3d4f43",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Preview",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "preview",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (1x speedAI240 Preview)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u1_preview.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u1_preview/resnet50/singlestream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u1_preview.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u1_preview_dc/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u1_preview_dc",
    "Result": 70348.6,
    "Scenario": "Offline",
    "SystemName": "Supermicro SuperServer H13 (1x speedAI240 Preview)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "UntetherAI speedAI240 Preview",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "03b4f69214494e57",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Preview",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "preview",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (1x speedAI240 Preview)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u1_preview_dc.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u1_preview_dc/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u1_preview_dc.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u1_preview_dc/resnet50/server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u1_preview_dc",
    "Result": 70096.9,
    "Scenario": "Server",
    "SystemName": "Supermicro SuperServer H13 (1x speedAI240 Preview)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "UntetherAI speedAI240 Preview",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "86a508e59c0e43b7",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Preview",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "preview",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (1x speedAI240 Preview)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u1_preview_dc.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u1_preview_dc/resnet50/server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u1_preview_dc.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u1_slim/resnet50/multistream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u1_slim",
    "Result": 0.285447,
    "Scenario": "MultiStream",
    "SystemName": "Supermicro SuperServer H13 (1x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "f6bbd4d7a4db48ef",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (1x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u1_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u1_slim/resnet50/multistream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u1_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u1_slim/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u1_slim",
    "Result": 56277.1,
    "Scenario": "Offline",
    "SystemName": "Supermicro SuperServer H13 (1x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "c818d8c422254bee",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (1x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u1_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u1_slim/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u1_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u1_slim/resnet50/singlestream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u1_slim",
    "Result": 0.121029,
    "Scenario": "SingleStream",
    "SystemName": "Supermicro SuperServer H13 (1x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "8b4ccc9179bf4753",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (1x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u1_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u1_slim/resnet50/singlestream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u1_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u2_preview/resnet50/multistream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u2_preview",
    "Result": 0.208008,
    "Scenario": "MultiStream",
    "SystemName": "Supermicro SuperServer H13 (2x speedAI240 Preview)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "UntetherAI speedAI240 Preview",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "61ce03f5a880422b",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Preview",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "preview",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (2x speedAI240 Preview)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u2_preview.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u2_preview/resnet50/multistream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u2_preview.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.952",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u2_preview/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u2_preview",
    "Result": 140625,
    "Scenario": "Offline",
    "SystemName": "Supermicro SuperServer H13 (2x speedAI240 Preview)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "UntetherAI speedAI240 Preview",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "9ad75d5c442d4230",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Preview",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "preview",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (2x speedAI240 Preview)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u2_preview.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u2_preview/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u2_preview.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u2_preview/resnet50/singlestream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u2_preview",
    "Result": 0.118879,
    "Scenario": "SingleStream",
    "SystemName": "Supermicro SuperServer H13 (2x speedAI240 Preview)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "UntetherAI speedAI240 Preview",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "34efe2d09e814604",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Preview",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "preview",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (2x speedAI240 Preview)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u2_preview.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u2_preview/resnet50/singlestream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u2_preview.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u2_preview_dc/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u2_preview_dc",
    "Result": 140631,
    "Scenario": "Offline",
    "SystemName": "Supermicro SuperServer H13 (2x speedAI240 Preview)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "UntetherAI speedAI240 Preview",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a03ef699e76b4b2b",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Preview",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "preview",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (2x speedAI240 Preview)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u2_preview_dc.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u2_preview_dc/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u2_preview_dc.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.894",
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u2_preview_dc/resnet50/server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u2_preview_dc",
    "Result": 140239,
    "Scenario": "Server",
    "SystemName": "Supermicro SuperServer H13 (2x speedAI240 Preview)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "UntetherAI speedAI240 Preview",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "2608db3d6bd545a5",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Preview",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "preview",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (2x speedAI240 Preview)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u2_preview_dc.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u2_preview_dc/resnet50/server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u2_preview_dc.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u3_slim/resnet50/multistream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u3_slim",
    "Result": 0.212477,
    "Scenario": "MultiStream",
    "SystemName": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "322b83d47e3a4a91",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "3",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u3_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u3_slim/resnet50/multistream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u3_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u3_slim/resnet50/multistream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u3_slim",
    "Result": 61.316696672746566,
    "Scenario": "MultiStream",
    "SystemName": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "millijoules",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "aaa94347d879494e",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "3",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u3_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u3_slim/resnet50/multistream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u3_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u3_slim/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u3_slim",
    "Result": 168720,
    "Scenario": "Offline",
    "SystemName": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "5cb7844a75cc4f26",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "3",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u3_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u3_slim/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u3_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u3_slim/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u3_slim",
    "Result": 398.32998477930016,
    "Scenario": "Offline",
    "SystemName": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "Watts",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "63810366148642cf",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "3",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u3_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u3_slim/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u3_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.920",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u3_slim/resnet50/singlestream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u3_slim",
    "Result": 0.120438,
    "Scenario": "SingleStream",
    "SystemName": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "44691f538e4448d1",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "3",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u3_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u3_slim/resnet50/singlestream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u3_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.920",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/h13_u3_slim/resnet50/singlestream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "h13_u3_slim",
    "Result": 29.238986918361313,
    "Scenario": "SingleStream",
    "SystemName": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "millijoules",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 3,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e4d9d21045064c44",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "3",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "4x 16 GB DDR5 (Samsung M321R2GA3PB0-CWMXJ 4800 MT/s)",
    "system.host_network_card_count": "1",
    "system.host_networking": "integrated",
    "system.host_networking_topology": "1GbE",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances); L1i cache: 512 KiB (16 instances); L2 cache: 16 MiB (16 instances); L3 cache: 64 MiB (4 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "1500 MHz (min); 3000 MHz (base); 3700 MHz (boost)",
    "system.host_processor_interconnect": "N/A",
    "system.host_processor_model_name": "AMD EPYC 9124 16-Core Processor",
    "system.host_processor_url": "https://www.amd.com/en/products/processors/server/epyc/4th-generation-9004-and-8004-series/amd-epyc-9124.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "931.5 GB",
    "system.host_storage_type": "Sabrent Rocket Q NVMe",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Supermicro SuperServer H13 (3x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "h13_u3_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/h13_u3_slim/resnet50/singlestream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/h13_u3_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/r760_u4_slim/resnet50/multistream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "r760_u4_slim",
    "Result": 0.169333,
    "Scenario": "MultiStream",
    "SystemName": "Dell PowerEdge R760xa (4x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "e0766a30c8a74158",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen 5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "16x 16 GB DDR5 (Samsung M321R2GA3BB6-CQKDS 4800 MT/s)",
    "system.host_network_card_count": "2",
    "system.host_networking": "embedded; integrated",
    "system.host_networking_topology": "Broadcom NetXtreme 1GbE (BCM5720); Broadcom Adv. Dual 25GbE",
    "system.host_processor_caches": "L1d cache: 3 MiB (64 instances); L1i cache: 2 MiB (64 instances); L2 cache: 128 MiB (64 instances); L3 cache: 120 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "800 MHz (min); 2100 MHz (base); 4100 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/232384/intel-xeon-gold-6448y-processor-60m-cache-2-10-ghz/specifications.html",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "480 GB (BOSS-N1); 3.8 TB (2x RAID)",
    "system.host_storage_type": "Dell NVMe ISE PE8010 RI M.2; Dell Ent NVMe P5520 RI",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell PowerEdge R760xa (4x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "2U rack server",
    "system_file_name": "r760_u4_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/r760_u4_slim/resnet50/multistream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/r760_u4_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.922",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/r760_u4_slim/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "r760_u4_slim",
    "Result": 221845,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7fd9b1145a3d4f88",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen 5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "16x 16 GB DDR5 (Samsung M321R2GA3BB6-CQKDS 4800 MT/s)",
    "system.host_network_card_count": "2",
    "system.host_networking": "embedded; integrated",
    "system.host_networking_topology": "Broadcom NetXtreme 1GbE (BCM5720); Broadcom Adv. Dual 25GbE",
    "system.host_processor_caches": "L1d cache: 3 MiB (64 instances); L1i cache: 2 MiB (64 instances); L2 cache: 128 MiB (64 instances); L3 cache: 120 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "800 MHz (min); 2100 MHz (base); 4100 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/232384/intel-xeon-gold-6448y-processor-60m-cache-2-10-ghz/specifications.html",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "480 GB (BOSS-N1); 3.8 TB (2x RAID)",
    "system.host_storage_type": "Dell NVMe ISE PE8010 RI M.2; Dell Ent NVMe P5520 RI",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell PowerEdge R760xa (4x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "2U rack server",
    "system_file_name": "r760_u4_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/r760_u4_slim/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/r760_u4_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.912",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/r760_u4_slim/resnet50/singlestream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "r760_u4_slim",
    "Result": 0.124016,
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge R760xa (4x speedAI240 Slim)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "1221dc49d2ab46d3",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "SKU: sai240L-F-A-ES. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen 5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "16x 16 GB DDR5 (Samsung M321R2GA3BB6-CQKDS 4800 MT/s)",
    "system.host_network_card_count": "2",
    "system.host_networking": "embedded; integrated",
    "system.host_networking_topology": "Broadcom NetXtreme 1GbE (BCM5720); Broadcom Adv. Dual 25GbE",
    "system.host_processor_caches": "L1d cache: 3 MiB (64 instances); L1i cache: 2 MiB (64 instances); L2 cache: 128 MiB (64 instances); L3 cache: 120 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "800 MHz (min); 2100 MHz (base); 4100 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/232384/intel-xeon-gold-6448y-processor-60m-cache-2-10-ghz/specifications.html",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "480 GB (BOSS-N1); 3.8 TB (2x RAID)",
    "system.host_storage_type": "Dell NVMe ISE PE8010 RI M.2; Dell Ent NVMe P5520 RI",
    "system.hw_notes": "SKU: sai240L-F-A-ES",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell PowerEdge R760xa (4x speedAI240 Slim)",
    "system.system_type": "edge",
    "system.system_type_detail": "2U rack server",
    "system_file_name": "r760_u4_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/r760_u4_slim/resnet50/singlestream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/r760_u4_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.916",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/r760_u6_slim/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "r760_u6_slim",
    "Result": 334462,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (6x speedAI240 Slim)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 6,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "a13998638e70441d",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen 5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "6",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "16x 16 GB DDR5 (Samsung M321R2GA3BB6-CQKDS 4800 MT/s)",
    "system.host_network_card_count": "2",
    "system.host_networking": "embedded; integrated",
    "system.host_networking_topology": "Broadcom NetXtreme 1GbE (BCM5720); Broadcom Adv. Dual 25GbE",
    "system.host_processor_caches": "L1d cache: 3 MiB (64 instances); L1i cache: 2 MiB (64 instances); L2 cache: 128 MiB (64 instances); L3 cache: 120 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "800 MHz (min); 2100 MHz (base); 4100 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/232384/intel-xeon-gold-6448y-processor-60m-cache-2-10-ghz/specifications.html",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "480 GB (BOSS-N1); 3.8 TB (2x RAID)",
    "system.host_storage_type": "Dell NVMe ISE PE8010 RI M.2; Dell Ent NVMe P5520 RI",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell PowerEdge R760xa (6x speedAI240 Slim)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "2U rack server",
    "system_file_name": "r760_u6_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/r760_u6_slim/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/r760_u6_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.916",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/r760_u6_slim/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "r760_u6_slim",
    "Result": 1021.3589743589744,
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (6x speedAI240 Slim)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 6,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "7bd7d4e17b404f92",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen 5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "6",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "16x 16 GB DDR5 (Samsung M321R2GA3BB6-CQKDS 4800 MT/s)",
    "system.host_network_card_count": "2",
    "system.host_networking": "embedded; integrated",
    "system.host_networking_topology": "Broadcom NetXtreme 1GbE (BCM5720); Broadcom Adv. Dual 25GbE",
    "system.host_processor_caches": "L1d cache: 3 MiB (64 instances); L1i cache: 2 MiB (64 instances); L2 cache: 128 MiB (64 instances); L3 cache: 120 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "800 MHz (min); 2100 MHz (base); 4100 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/232384/intel-xeon-gold-6448y-processor-60m-cache-2-10-ghz/specifications.html",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "480 GB (BOSS-N1); 3.8 TB (2x RAID)",
    "system.host_storage_type": "Dell NVMe ISE PE8010 RI M.2; Dell Ent NVMe P5520 RI",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell PowerEdge R760xa (6x speedAI240 Slim)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "2U rack server",
    "system_file_name": "r760_u6_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/r760_u6_slim/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/r760_u6_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.930",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/r760_u6_slim/resnet50/server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "r760_u6_slim",
    "Result": 309752,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (6x speedAI240 Slim)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 6,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "97abaa04341b4f63",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen 5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "6",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "16x 16 GB DDR5 (Samsung M321R2GA3BB6-CQKDS 4800 MT/s)",
    "system.host_network_card_count": "2",
    "system.host_networking": "embedded; integrated",
    "system.host_networking_topology": "Broadcom NetXtreme 1GbE (BCM5720); Broadcom Adv. Dual 25GbE",
    "system.host_processor_caches": "L1d cache: 3 MiB (64 instances); L1i cache: 2 MiB (64 instances); L2 cache: 128 MiB (64 instances); L3 cache: 120 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "800 MHz (min); 2100 MHz (base); 4100 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/232384/intel-xeon-gold-6448y-processor-60m-cache-2-10-ghz/specifications.html",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "480 GB (BOSS-N1); 3.8 TB (2x RAID)",
    "system.host_storage_type": "Dell NVMe ISE PE8010 RI M.2; Dell Ent NVMe P5520 RI",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell PowerEdge R760xa (6x speedAI240 Slim)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "2U rack server",
    "system_file_name": "r760_u6_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/r760_u6_slim/resnet50/server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/r760_u6_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "acc: 75.930",
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/UntetherAI/results/r760_u6_slim/resnet50/server",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "UntetherAI",
    "Platform": "r760_u6_slim",
    "Result": 985.5191347753744,
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (6x speedAI240 Slim)",
    "SystemType": "datacenter",
    "Units": "Watts",
    "accelerator_model_name": "UntetherAI speedAI240 Slim",
    "accelerators_per_node": 6,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 0,
    "datetime_last_commit": "",
    "debug_uid": "b5691f59cf734c25",
    "errors": 0,
    "framework": "UntetherAI imAIgine SDK v24.07.19",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen 5 16x (32 GT/s)",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "disabled",
    "system.accelerator_memory_configuration": "LPDDR5 64x",
    "system.accelerator_model_name": "UntetherAI speedAI240 Slim",
    "system.accelerator_on-chip_memories": "238 MB SRAM",
    "system.accelerators_per_node": "6",
    "system.cooling": "air",
    "system.division": "closed",
    "system.framework": "UntetherAI imAIgine SDK v24.07.19",
    "system.host_memory_capacity": "256 GB",
    "system.host_memory_configuration": "16x 16 GB DDR5 (Samsung M321R2GA3BB6-CQKDS 4800 MT/s)",
    "system.host_network_card_count": "2",
    "system.host_networking": "embedded; integrated",
    "system.host_networking_topology": "Broadcom NetXtreme 1GbE (BCM5720); Broadcom Adv. Dual 25GbE",
    "system.host_processor_caches": "L1d cache: 3 MiB (64 instances); L1i cache: 2 MiB (64 instances); L2 cache: 128 MiB (64 instances); L3 cache: 120 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "800 MHz (min); 2100 MHz (base); 4100 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/232384/intel-xeon-gold-6448y-processor-60m-cache-2-10-ghz/specifications.html",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "480 GB (BOSS-N1); 3.8 TB (2x RAID)",
    "system.host_storage_type": "Dell NVMe ISE PE8010 RI M.2; Dell Ent NVMe P5520 RI",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 6.5.0-44-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack.Docker": "27.1.0, build 6312585",
    "system.other_software_stack.KILT": "mlperf_4.1",
    "system.other_software_stack.Python": "3.10.12",
    "system.status": "available",
    "system.submitter": "UntetherAI",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell PowerEdge R760xa (6x speedAI240 Slim)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "2U rack server",
    "system_file_name": "r760_u6_slim.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/results/r760_u6_slim/resnet50/server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/closed/UntetherAI/systems/r760_u6_slim.json",
    "version": "v4.1",
    "weight_data_types": "float8"
  },
  {
    "Accuracy": "F1: 90.21494616303566",
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/cm-demo-gfursin-aws-g4dn.4xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "cm-demo-gfursin-aws-g4dn.4xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 381.124,
    "Scenario": "Offline",
    "SystemName": "aws-g4dn-4xlarge",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "1e1fbfb9a2144c66",
    "errors": 0,
    "framework": "TensorRT",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "cTuning.org/ae: Collective Mind demo for our reproducibility initiatives and artifact evaluation at ACM, IEEE and MLCommons ; automated by MLCommons CM v2.3.4 ; taken by Grigori Fursin",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.5.0-1023-aws-glibc2.31)",
    "system.accelerator_frequency": "1590.000000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "14.56805419921875 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "Tesla T4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "TensorRT",
    "system.host_memory_capacity": "63G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 256 KiB, L1i cache: 256 KiB, L2 cache: 8 MiB, L3 cache: 35.8 MiB",
    "system.host_processor_core_count": "8",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "769G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 20.04 (linux-6.5.0-1023-aws-glibc2.31)",
    "system.other_software_stack": "Python: 3.8.10, GCC-9.4.0",
    "system.status": "available",
    "system.submitter": "CTuning",
    "system.sw_notes": "cTuning.org/ae: Collective Mind demo for our reproducibility initiatives and artifact evaluation at ACM, IEEE and MLCommons ; automated by MLCommons CM v2.3.4 ; taken by Grigori Fursin",
    "system.system_name": "aws-g4dn-4xlarge",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "cm-demo-gfursin-aws-g4dn.4xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/CTuning/results/cm-demo-gfursin-aws-g4dn.4xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/CTuning/systems/cm-demo-gfursin-aws-g4dn.4xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.750536930561065  FID_SCORE: 23.46804710968439",
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/cm-demo-gfursin-scaleway-L4-1-24G-reference-gpu-pytorch-v2.3.1-default_config/stable-diffusion-xl/offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "CTuning",
    "Platform": "cm-demo-gfursin-scaleway-L4-1-24G-reference-gpu-pytorch-v2.3.1-default_config",
    "Result": 0.125716,
    "Scenario": "Offline",
    "SystemName": "scaleway-L4-1-24G",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "2396f47ce73b48c7",
    "errors": 0,
    "framework": "pytorch v2.3.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "AMD EPYC 7413 24-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "cTuning.org/ae: Collective Mind demo for our reproducibility initiatives and artifact evaluation at ACM, IEEE and MLCommons ; automated by MLCommons CM v2.3.4 ; taken by Grigori Fursin",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-116-generic-glibc2.35)",
    "system.accelerator_frequency": "2040.000000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "21.95147705078125 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA L4",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.3.1",
    "system.host_memory_capacity": "48G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (8 instances), L1i cache: 512 KiB (8 instances), L2 cache: 4 MiB (8 instances), L3 cache: 128 MiB (8 instances)",
    "system.host_processor_core_count": "8",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 7413 24-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "304G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-5.15.0-116-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "CTuning",
    "system.sw_notes": "cTuning.org/ae: Collective Mind demo for our reproducibility initiatives and artifact evaluation at ACM, IEEE and MLCommons ; automated by MLCommons CM v2.3.4 ; taken by Grigori Fursin",
    "system.system_name": "scaleway-L4-1-24G",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "cm-demo-gfursin-scaleway-L4-1-24G-reference-gpu-pytorch-v2.3.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/CTuning/results/cm-demo-gfursin-scaleway-L4-1-24G-reference-gpu-pytorch-v2.3.1-default_config/stable-diffusion-xl/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/CTuning/systems/cm-demo-gfursin-scaleway-L4-1-24G-reference-gpu-pytorch-v2.3.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "ROUGE1: 43.0343  ROUGE2: 20.0912  ROUGEL: 29.9254  GEN_LEN: 4102192",
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 19889.7,
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "a0e7dd4d87e242a7",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.0346  ROUGE2: 20.0913  ROUGEL: 29.9259  GEN_LEN: 4102422",
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99.9/Server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 19627.6,
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "a7d6804cca3d4fca",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "8x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "2048GB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 4.5 MiB (96 instances), L1i: 3 MiB (96 instances), L2: 192 MiB (96 instances), L3: 210 MiB (2 instances)",
    "system.host_processor_core_count": "48",
    "system.host_processor_frequency": "3.8GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2TB SSD, 673TB HPE ClusterStor",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 555.42.06",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99.9/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/systems/HPE_Cray_XD670_H100_SXM_80GBx8_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.4026  ROUGE2: 23.228  ROUGEL: 30.3021  TOKENS_PER_SAMPLE: 145.3  gsm8k_accuracy: 73.64  mbxp_accuracy: 59.98",
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/mixtral-8x7b/Offline",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 18839,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "2c6f2462927a433f",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/mixtral-8x7b/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 45.4098  ROUGE2: 23.2338  ROUGEL: 30.3109  TOKENS_PER_SAMPLE: 145.3  gsm8k_accuracy: 73.66  mbxp_accuracy: 60.0",
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/mixtral-8x7b/Server",
    "MlperfModel": "mixtral-8x7b",
    "Model": "mixtral-8x7b",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 17453.4,
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "f71a64b524a14526",
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "4x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "94 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "TensorRT 10.2.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "8x 400Gbe Infiniband",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d: 3 MiB, L1i: 2 MiB, L2: 128 MiB (64 instances), L3: 320 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "2.1GHz, Max Turbo=4.0GHz",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "1.8T SSD, 34 TB CIFS",
    "system.host_storage_type": "NVMe SSD, NFS mounted disk storage",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4 LTS",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 10.2.0, CUDA 12.4, cuDNN 8.9.7, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "4x 3200W",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/mixtral-8x7b/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/systems/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "DICE: 0.86017",
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/3d-unet-99.9/Offline",
    "MlperfModel": "3d-unet-99.9",
    "Model": "3d-unet-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 15.4277,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "e5f52e6ff0324343",
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 Switch",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.0.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB 36ASF8G72PZ-3G2E1",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "1Gbe",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.4, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/3d-unet-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/systems/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.80439346909523  FID_SCORE: 23.467040872846894",
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 1.79467,
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "648106abbc374f7f",
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 Switch",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "HBM2e",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "",
    "system.disk_drives": "",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.0.0, CUDA 12.4",
    "system.host_memory_capacity": "1024GB",
    "system.host_memory_configuration": "16x 64GB 36ASF8G72PZ-3G2E1",
    "system.host_network_card_count": "7-slots of 2-port 200G Infiniband (Max 2800GB HDR) or 2-port 100G Ethernet (Max 1400GbE)",
    "system.host_networking": "1Gbe",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "60",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6 TB",
    "system.host_storage_type": "NVMe SSD",
    "system.hw_notes": "",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.3",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.4, Driver 535.183.01",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "HPE",
    "system.sw_notes": "",
    "system.system_name": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/HPE/systems/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "F1: 90.87487229720105",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/7920t-kilt-onnxruntime_cpu/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_cpu",
    "Result": 2.68543,
    "Scenario": "Offline",
    "SystemName": "Dell Precision 7920 Tower",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "31491f84832e4981",
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "system.host_memory_capacity": "96 GB",
    "system.host_memory_configuration": "6x 16 GB",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Integrated",
    "system.host_processor_caches": "L1d cache: 768 KiB (24 instances); L1i cache: 768 KiB (24 instances); L2 cache: 24 MiB (24 instances); L3 cache: 35.8 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "1000 MHz (min); 2400 MHz (base); 4000 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/199343/intel-xeon-gold-6240r-processor-35-75m-cache-2-40-ghz/specifications.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "256 GB; 2 TB; 4 TB",
    "system.host_storage_type": "M.2 PCIe NVMe SSD (Micron 2300); M.2 PCIe 4.0 NVMe SSD (Samsung 990 PRO); SATA HDD (Seagate EXOS ST4000NM016A-2HZ130)",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack": "ONNX Runtime v1.18.1; Python v3.9.19; GCC v11.4.0",
    "system.status": "available",
    "system.submitter": "Krai",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell Precision 7920 Tower",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "7920t-kilt-onnxruntime_cpu.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/results/7920t-kilt-onnxruntime_cpu/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/systems/7920t-kilt-onnxruntime_cpu.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 90.87487229720105",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/7920t-kilt-onnxruntime_cpu/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_cpu",
    "Result": 285.046831,
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 7920 Tower",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "f78bdb3afe4e4b4c",
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "system.host_memory_capacity": "96 GB",
    "system.host_memory_configuration": "6x 16 GB",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Integrated",
    "system.host_processor_caches": "L1d cache: 768 KiB (24 instances); L1i cache: 768 KiB (24 instances); L2 cache: 24 MiB (24 instances); L3 cache: 35.8 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "1000 MHz (min); 2400 MHz (base); 4000 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/199343/intel-xeon-gold-6240r-processor-35-75m-cache-2-40-ghz/specifications.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "256 GB; 2 TB; 4 TB",
    "system.host_storage_type": "M.2 PCIe NVMe SSD (Micron 2300); M.2 PCIe 4.0 NVMe SSD (Samsung 990 PRO); SATA HDD (Seagate EXOS ST4000NM016A-2HZ130)",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack": "ONNX Runtime v1.18.1; Python v3.9.19; GCC v11.4.0",
    "system.status": "available",
    "system.submitter": "Krai",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell Precision 7920 Tower",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "7920t-kilt-onnxruntime_cpu.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/results/7920t-kilt-onnxruntime_cpu/bert-99/singlestream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/systems/7920t-kilt-onnxruntime_cpu.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "acc: 76.456",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/7920t-kilt-onnxruntime_cpu/resnet50/multistream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_cpu",
    "Result": 51.765414,
    "Scenario": "MultiStream",
    "SystemName": "Dell Precision 7920 Tower",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "6a261205cd7c46d0",
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "system.host_memory_capacity": "96 GB",
    "system.host_memory_configuration": "6x 16 GB",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Integrated",
    "system.host_processor_caches": "L1d cache: 768 KiB (24 instances); L1i cache: 768 KiB (24 instances); L2 cache: 24 MiB (24 instances); L3 cache: 35.8 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "1000 MHz (min); 2400 MHz (base); 4000 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/199343/intel-xeon-gold-6240r-processor-35-75m-cache-2-40-ghz/specifications.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "256 GB; 2 TB; 4 TB",
    "system.host_storage_type": "M.2 PCIe NVMe SSD (Micron 2300); M.2 PCIe 4.0 NVMe SSD (Samsung 990 PRO); SATA HDD (Seagate EXOS ST4000NM016A-2HZ130)",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack": "ONNX Runtime v1.18.1; Python v3.9.19; GCC v11.4.0",
    "system.status": "available",
    "system.submitter": "Krai",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell Precision 7920 Tower",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "7920t-kilt-onnxruntime_cpu.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/results/7920t-kilt-onnxruntime_cpu/resnet50/multistream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/systems/7920t-kilt-onnxruntime_cpu.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "acc: 76.456",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/7920t-kilt-onnxruntime_cpu/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_cpu",
    "Result": 149.84,
    "Scenario": "Offline",
    "SystemName": "Dell Precision 7920 Tower",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "ee9518be8b56474f",
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "system.host_memory_capacity": "96 GB",
    "system.host_memory_configuration": "6x 16 GB",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Integrated",
    "system.host_processor_caches": "L1d cache: 768 KiB (24 instances); L1i cache: 768 KiB (24 instances); L2 cache: 24 MiB (24 instances); L3 cache: 35.8 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "1000 MHz (min); 2400 MHz (base); 4000 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/199343/intel-xeon-gold-6240r-processor-35-75m-cache-2-40-ghz/specifications.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "256 GB; 2 TB; 4 TB",
    "system.host_storage_type": "M.2 PCIe NVMe SSD (Micron 2300); M.2 PCIe 4.0 NVMe SSD (Samsung 990 PRO); SATA HDD (Seagate EXOS ST4000NM016A-2HZ130)",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack": "ONNX Runtime v1.18.1; Python v3.9.19; GCC v11.4.0",
    "system.status": "available",
    "system.submitter": "Krai",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell Precision 7920 Tower",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "7920t-kilt-onnxruntime_cpu.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/results/7920t-kilt-onnxruntime_cpu/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/systems/7920t-kilt-onnxruntime_cpu.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "acc: 76.456",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/7920t-kilt-onnxruntime_cpu/resnet50/singlestream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_cpu",
    "Result": 11.359795,
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 7920 Tower",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "4e52df9e71b94ee2",
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "N/A",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "N/A",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "N/A",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "system.host_memory_capacity": "96 GB",
    "system.host_memory_configuration": "6x 16 GB",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Integrated",
    "system.host_processor_caches": "L1d cache: 768 KiB (24 instances); L1i cache: 768 KiB (24 instances); L2 cache: 24 MiB (24 instances); L3 cache: 35.8 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "1000 MHz (min); 2400 MHz (base); 4000 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/199343/intel-xeon-gold-6240r-processor-35-75m-cache-2-40-ghz/specifications.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "256 GB; 2 TB; 4 TB",
    "system.host_storage_type": "M.2 PCIe NVMe SSD (Micron 2300); M.2 PCIe 4.0 NVMe SSD (Samsung 990 PRO); SATA HDD (Seagate EXOS ST4000NM016A-2HZ130)",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack": "ONNX Runtime v1.18.1; Python v3.9.19; GCC v11.4.0",
    "system.status": "available",
    "system.submitter": "Krai",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell Precision 7920 Tower",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "7920t-kilt-onnxruntime_cpu.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/results/7920t-kilt-onnxruntime_cpu/resnet50/singlestream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/systems/7920t-kilt-onnxruntime_cpu.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 90.88232621193973",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/7920t-kilt-onnxruntime_gpu/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_gpu",
    "Result": 65.5708,
    "Scenario": "Offline",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "73332a4b88504e5e",
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "1170 MHz (base); 1695 MHz (turbo)",
    "system.accelerator_host_interconnect": "PCIe Gen 4",
    "system.accelerator_interconnect": "NVIDIA NVLink",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "1x 24 GB",
    "system.accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "system.host_memory_capacity": "96 GB",
    "system.host_memory_configuration": "6x 16 GB",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Integrated",
    "system.host_processor_caches": "L1d cache: 768 KiB (24 instances); L1i cache: 768 KiB (24 instances); L2 cache: 24 MiB (24 instances); L3 cache: 35.8 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "1000 MHz (min); 2400 MHz (base); 4000 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/199343/intel-xeon-gold-6240r-processor-35-75m-cache-2-40-ghz/specifications.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "256 GB; 2 TB; 4 TB",
    "system.host_storage_type": "M.2 PCIe NVMe SSD (Micron 2300); M.2 PCIe 4.0 NVMe SSD (Samsung 990 PRO); SATA HDD (Seagate EXOS ST4000NM016A-2HZ130)",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack": "CUDA v12.5; ONNX Runtime v1.18.1; Python v3.9.19; GCC v11.4.0",
    "system.status": "available",
    "system.submitter": "Krai",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "7920t-kilt-onnxruntime_gpu.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/results/7920t-kilt-onnxruntime_gpu/bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/systems/7920t-kilt-onnxruntime_gpu.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 90.88232621193973",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/7920t-kilt-onnxruntime_gpu/bert-99/singlestream",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_gpu",
    "Result": 15.877397,
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "c1aeff6de5824d38",
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "1170 MHz (base); 1695 MHz (turbo)",
    "system.accelerator_host_interconnect": "PCIe Gen 4",
    "system.accelerator_interconnect": "NVIDIA NVLink",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "1x 24 GB",
    "system.accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "system.host_memory_capacity": "96 GB",
    "system.host_memory_configuration": "6x 16 GB",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Integrated",
    "system.host_processor_caches": "L1d cache: 768 KiB (24 instances); L1i cache: 768 KiB (24 instances); L2 cache: 24 MiB (24 instances); L3 cache: 35.8 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "1000 MHz (min); 2400 MHz (base); 4000 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/199343/intel-xeon-gold-6240r-processor-35-75m-cache-2-40-ghz/specifications.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "256 GB; 2 TB; 4 TB",
    "system.host_storage_type": "M.2 PCIe NVMe SSD (Micron 2300); M.2 PCIe 4.0 NVMe SSD (Samsung 990 PRO); SATA HDD (Seagate EXOS ST4000NM016A-2HZ130)",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack": "CUDA v12.5; ONNX Runtime v1.18.1; Python v3.9.19; GCC v11.4.0",
    "system.status": "available",
    "system.submitter": "Krai",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "7920t-kilt-onnxruntime_gpu.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/results/7920t-kilt-onnxruntime_gpu/bert-99/singlestream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/systems/7920t-kilt-onnxruntime_gpu.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "acc: 76.456",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/7920t-kilt-onnxruntime_gpu/resnet50/multistream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_gpu",
    "Result": 7.773151,
    "Scenario": "MultiStream",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "92595a438cee4752",
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "1170 MHz (base); 1695 MHz (turbo)",
    "system.accelerator_host_interconnect": "PCIe Gen 4",
    "system.accelerator_interconnect": "NVIDIA NVLink",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "1x 24 GB",
    "system.accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "system.host_memory_capacity": "96 GB",
    "system.host_memory_configuration": "6x 16 GB",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Integrated",
    "system.host_processor_caches": "L1d cache: 768 KiB (24 instances); L1i cache: 768 KiB (24 instances); L2 cache: 24 MiB (24 instances); L3 cache: 35.8 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "1000 MHz (min); 2400 MHz (base); 4000 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/199343/intel-xeon-gold-6240r-processor-35-75m-cache-2-40-ghz/specifications.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "256 GB; 2 TB; 4 TB",
    "system.host_storage_type": "M.2 PCIe NVMe SSD (Micron 2300); M.2 PCIe 4.0 NVMe SSD (Samsung 990 PRO); SATA HDD (Seagate EXOS ST4000NM016A-2HZ130)",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack": "CUDA v12.5; ONNX Runtime v1.18.1; Python v3.9.19; GCC v11.4.0",
    "system.status": "available",
    "system.submitter": "Krai",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "7920t-kilt-onnxruntime_gpu.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/results/7920t-kilt-onnxruntime_gpu/resnet50/multistream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/systems/7920t-kilt-onnxruntime_gpu.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "acc: 76.456",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/7920t-kilt-onnxruntime_gpu/resnet50/offline",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_gpu",
    "Result": 1090.09,
    "Scenario": "Offline",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "ca19b1ed8b494018",
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "1170 MHz (base); 1695 MHz (turbo)",
    "system.accelerator_host_interconnect": "PCIe Gen 4",
    "system.accelerator_interconnect": "NVIDIA NVLink",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "1x 24 GB",
    "system.accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "system.host_memory_capacity": "96 GB",
    "system.host_memory_configuration": "6x 16 GB",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Integrated",
    "system.host_processor_caches": "L1d cache: 768 KiB (24 instances); L1i cache: 768 KiB (24 instances); L2 cache: 24 MiB (24 instances); L3 cache: 35.8 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "1000 MHz (min); 2400 MHz (base); 4000 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/199343/intel-xeon-gold-6240r-processor-35-75m-cache-2-40-ghz/specifications.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "256 GB; 2 TB; 4 TB",
    "system.host_storage_type": "M.2 PCIe NVMe SSD (Micron 2300); M.2 PCIe 4.0 NVMe SSD (Samsung 990 PRO); SATA HDD (Seagate EXOS ST4000NM016A-2HZ130)",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack": "CUDA v12.5; ONNX Runtime v1.18.1; Python v3.9.19; GCC v11.4.0",
    "system.status": "available",
    "system.submitter": "Krai",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "7920t-kilt-onnxruntime_gpu.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/results/7920t-kilt-onnxruntime_gpu/resnet50/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/systems/7920t-kilt-onnxruntime_gpu.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "acc: 76.454",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Krai/results/7920t-kilt-onnxruntime_gpu/resnet50/singlestream",
    "MlperfModel": "resnet",
    "Model": "resnet50",
    "Organization": "Krai",
    "Platform": "7920t-kilt-onnxruntime_gpu",
    "Result": 4.435463,
    "Scenario": "SingleStream",
    "SystemName": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "a0e8fd09e3e7421e",
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.accelerator_frequency": "1170 MHz (base); 1695 MHz (turbo)",
    "system.accelerator_host_interconnect": "PCIe Gen 4",
    "system.accelerator_interconnect": "NVIDIA NVLink",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "24 GB",
    "system.accelerator_memory_configuration": "1x 24 GB",
    "system.accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "KRAI Inference Library Technology (KILT) with ONNX Runtime support",
    "system.host_memory_capacity": "96 GB",
    "system.host_memory_configuration": "6x 16 GB",
    "system.host_network_card_count": "1",
    "system.host_networking": "Ethernet",
    "system.host_networking_topology": "Integrated",
    "system.host_processor_caches": "L1d cache: 768 KiB (24 instances); L1i cache: 768 KiB (24 instances); L2 cache: 24 MiB (24 instances); L3 cache: 35.8 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "1000 MHz (min); 2400 MHz (base); 4000 MHz (boost)",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "system.host_processor_url": "https://www.intel.com/content/www/us/en/products/sku/199343/intel-xeon-gold-6240r-processor-35-75m-cache-2-40-ghz/specifications.html",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "256 GB; 2 TB; 4 TB",
    "system.host_storage_type": "M.2 PCIe NVMe SSD (Micron 2300); M.2 PCIe 4.0 NVMe SSD (Samsung 990 PRO); SATA HDD (Seagate EXOS ST4000NM016A-2HZ130)",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "system.other_software_stack": "CUDA v12.5; ONNX Runtime v1.18.1; Python v3.9.19; GCC v11.4.0",
    "system.status": "available",
    "system.submitter": "Krai",
    "system.sw_notes": "Powered by the KRAI X and KILT technologies",
    "system.system_name": "Dell Precision 7920 Tower (1x NVIDIA RTX A5000 GPU)",
    "system.system_type": "edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "7920t-kilt-onnxruntime_gpu.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/results/7920t-kilt-onnxruntime_gpu/resnet50/singlestream",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Krai/systems/7920t-kilt-onnxruntime_gpu.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "ROUGE1: 44.5491  ROUGE2: 22.1761  ROUGEL: 28.7877  TOKENS_PER_SAMPLE: 293.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/4xH100-SXM-80GB_vLLM_FP8-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NeuralMagic",
    "Platform": "4xH100-SXM-80GB_vLLM_FP8-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 1468.24,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR H100 'beaker' (4x H100-SXM-80GB, vLLM, FP8)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "5199544dc41a427b",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.4. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-35-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "2.1T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 3 MiB (64 instances), L1i cache: 2 MiB (64 instances), L2 cache: 128 MiB (64 instances), L3 cache: 120 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "4100.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "15T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-35-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.4. ",
    "system.system_name": "SYS-821GE-TNHR H100 'beaker' (4x H100-SXM-80GB, vLLM, FP8)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "",
    "system_file_name": "4xH100-SXM-80GB_vLLM_FP8-reference-cpu-pytorch-v2.3.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/4xH100-SXM-80GB_vLLM_FP8-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/4xH100-SXM-80GB_vLLM_FP8-reference-cpu-pytorch-v2.3.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.2003  ROUGE2: 21.8589  ROUGEL: 28.4858  TOKENS_PER_SAMPLE: 586.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NeuralMagic",
    "Platform": "4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 1577.11,
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR H100 'beaker' (4x H100-SXM-80GB, vLLM, GPTQ)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "581fb25395f645e5",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.4. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-35-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "2.1T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 3 MiB (64 instances), L1i cache: 2 MiB (64 instances), L2 cache: 128 MiB (64 instances), L3 cache: 120 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "4100.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "15T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-35-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.4. ",
    "system.system_name": "SYS-821GE-TNHR H100 'beaker' (4x H100-SXM-80GB, vLLM, GPTQ)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "",
    "system_file_name": "4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "ROUGE1: 44.1657  ROUGE2: 21.8046  ROUGEL: 28.4386  TOKENS_PER_SAMPLE: 291.2",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/server",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NeuralMagic",
    "Platform": "4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 1164.04,
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR H100 'beaker' (4x H100-SXM-80GB, vLLM, GPTQ)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "aa148b2a6f3547a4",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.4. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-35-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "80 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "4",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "2.1T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 3 MiB (64 instances), L1i cache: 2 MiB (64 instances), L2 cache: 128 MiB (64 instances), L3 cache: 120 MiB (2 instances)",
    "system.host_processor_core_count": "32",
    "system.host_processor_frequency": "4100.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "15T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-35-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.4. ",
    "system.system_name": "SYS-821GE-TNHR H100 'beaker' (4x H100-SXM-80GB, vLLM, GPTQ)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "",
    "system_file_name": "4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/4xH100-SXM-80GB_vLLM_GPTQ-reference-cpu-pytorch-v2.3.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int4"
  },
  {
    "Accuracy": "F1: 88.42042174998099",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 16.1606,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "ff09b6aca55a4a3a",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/bert-base-pruned90-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 87.88571389692375",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned95_obs_quant-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 32.3193,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "f643c018b420444e",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/bert-base-pruned95_obs_quant-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 89.65191480026783",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 1.98105,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "e946bcf5a2cd4c79",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/bert-large-base-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 90.29174382621062",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 7.03354,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "64a6e448280549a5",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.4308347276475",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 40.4069,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "fe2278264da24a12",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 90.36718210138123",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 52.0686,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "2bef25f50bbf447b",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.80558974686677",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 17.251,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "8f68151216f24c59",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-base_quant-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.89066465550044",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 17.542,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "a014a0e6e50e4052",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/mobilebert-none-base-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 88.31078542237867",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 15.9513,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "f967b85fec64483d",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/obert-base-pruned90-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 89.65191480026783",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 1.96602,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "a276d84cba384027",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/obert-large-base-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 90.01097011863615",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 11.8665,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "6776ba26849c40b1",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.17851587480281",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config",
    "Result": 7.24483,
    "Scenario": "Offline",
    "SystemName": "ASUS_Vivobook",
    "SystemType": "edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "449b0ce0cdef4bf0",
    "errors": 0,
    "framework": "deepsparse v1.8.0",
    "has_power": false,
    "host_processor_core_count": 6,
    "host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.device": "cpu",
    "system.division": "open",
    "system.framework": "deepsparse v1.8.0",
    "system.host_memory_capacity": "19G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 192 KiB (6 instances), L1i cache: 192 KiB (6 instances), L2 cache: 3 MiB (6 instances), L3 cache: 8 MiB (2 instances)",
    "system.host_processor_core_count": "6",
    "system.host_processor_frequency": "4056.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 5 5500U with Radeon Graphics",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "108G",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.implementation": "reference",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-44-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.run_config": "default_config",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "ASUS_Vivobook",
    "system.system_type": "edge",
    "system.system_type_detail": "edge server",
    "system_file_name": "ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/ASUS_Vivobook-reference-cpu-deepsparse_v1.8.0-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 44.0047  ROUGE2: 21.7276  ROUGEL: 28.4008  TOKENS_PER_SAMPLE: 291.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/llama2-70b-99/offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NeuralMagic",
    "Platform": "GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config",
    "Result": 424.895,
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids RTX 4090 (2x RTX 4090, vLLM, FP8)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "6bf77e8b453b4c5e",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "system.accelerator_frequency": "2520.000000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "202G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "system.other_software_stack": "Python: 3.11.4, LLVM-10.0.1",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "GATE Overflow Intel Sapphire Rapids RTX 4090 (2x RTX 4090, vLLM, FP8)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "onpremise",
    "system_file_name": "GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/llama2-70b-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "ROUGE1: 44.0047  ROUGE2: 21.7276  ROUGEL: 28.4008  TOKENS_PER_SAMPLE: 291.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/llama2-70b-99.9/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NeuralMagic",
    "Platform": "GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config",
    "Result": 424.895,
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids RTX 4090 (2x RTX 4090, vLLM, FP8)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "6f5de3b9e1454bf1",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "system.accelerator_frequency": "2520.000000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "202G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "system.other_software_stack": "Python: 3.11.4, LLVM-10.0.1",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "GATE Overflow Intel Sapphire Rapids RTX 4090 (2x RTX 4090, vLLM, FP8)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "onpremise",
    "system_file_name": "GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/llama2-70b-99.9/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "ROUGE1: 41.6468  ROUGE2: 19.5564  ROUGEL: 26.4202  TOKENS_PER_SAMPLE: 296.5",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "neuralmagic_Llama-2-7b-chat-hf-FP8",
    "Organization": "NeuralMagic",
    "Platform": "GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config",
    "Result": 1871.84,
    "Scenario": "Offline",
    "SystemName": "GATE Overflow Intel Sapphire Rapids RTX 4090 (2x RTX 4090, vLLM, FP8)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "768c10e0742e4a12",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "system.accelerator_frequency": "2520.000000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "202G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "system.other_software_stack": "Python: 3.11.4, LLVM-10.0.1",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "GATE Overflow Intel Sapphire Rapids RTX 4090 (2x RTX 4090, vLLM, FP8)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "onpremise",
    "system_file_name": "GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 42.0442  ROUGE2: 19.8615  ROUGEL: 26.7971  TOKENS_PER_SAMPLE: 283.5",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "neuralmagic_Llama-2-7b-chat-hf-FP8",
    "Organization": "NeuralMagic",
    "Platform": "GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config",
    "Result": 1954.36,
    "Scenario": "Server",
    "SystemName": "GATE Overflow Intel Sapphire Rapids RTX 4090 (2x RTX 4090, vLLM, FP8)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "a4574e84eb4542a6",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "system.accelerator_frequency": "2520.000000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64703369140625 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "2",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "202G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "system.other_software_stack": "Python: 3.11.4, LLVM-10.0.1",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "GATE Overflow Intel Sapphire Rapids RTX 4090 (2x RTX 4090, vLLM, FP8)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "onpremise",
    "system_file_name": "GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/GO_2xRTX4090-reference-cpu-pytorch-v2.2.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "AUC: 80.199",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/GO_Intel_SPR-intel-cpu-pytorch-vdefault-default_config/dlrm-v2-99/offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NeuralMagic",
    "Platform": "GO_Intel_SPR-intel-cpu-pytorch-vdefault-default_config",
    "Result": 822.557,
    "Scenario": "Offline",
    "SystemName": "GO Intel SPR 1S 24C",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "90b27ed082e9414a",
    "errors": 0,
    "framework": "pytorch v2.2.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "pytorch v2.2.1",
    "system.host_memory_capacity": "202G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.1 MiB (24 instances), L1i cache: 768 KiB (24 instances), L2 cache: 48 MiB (24 instances), L3 cache: 45 MiB (1 instance)",
    "system.host_processor_core_count": "24",
    "system.host_processor_frequency": "4800.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "6.9T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "system.other_software_stack": "Python: 3.11.4, LLVM-10.0.1",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "GO Intel SPR 1S 24C",
    "system.system_type": "datacenter",
    "system.system_type_detail": "onpremise",
    "system_file_name": "GO_Intel_SPR-intel-cpu-pytorch-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/GO_Intel_SPR-intel-cpu-pytorch-vdefault-default_config/dlrm-v2-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/GO_Intel_SPR-intel-cpu-pytorch-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 41.7123  ROUGE2: 19.6143  ROUGEL: 26.4603  TOKENS_PER_SAMPLE: 296.6",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "neuralmagic_Llama-2-7b-chat-hf-FP8",
    "Organization": "NeuralMagic",
    "Platform": "pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config",
    "Result": 1337.46,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5 (1x RTX 4090)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "1fde0bd29c8a4e8f",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "2610.000000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64971923828125 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5 (1x RTX 4090)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "onpremise",
    "system_file_name": "pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 42.0303  ROUGE2: 19.868  ROUGEL: 26.8128  TOKENS_PER_SAMPLE: 285.7",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/server",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "neuralmagic_Llama-2-7b-chat-hf-FP8",
    "Organization": "NeuralMagic",
    "Platform": "pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config",
    "Result": 1429.85,
    "Scenario": "Server",
    "SystemName": "PCSPECIALIST AMD AM5 (1x RTX 4090)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "c2c9750fcf314dec",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "2610.000000 MHz",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "23.64971923828125 GB",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5 (1x RTX 4090)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "onpremise",
    "system_file_name": "pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/pcspecialist_amd_am5-reference-gpu-pytorch-v2.2.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "F1: 88.42042174998099",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-base-pruned90-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 98.963,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "e1524be00bdd4b6a",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-base-pruned90-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 89.65191480026783",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-base-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 11.974,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "fa0f8e804d8e4f47",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-large-base-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 90.26839357448662",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-large-pruned80_quant-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 91.7981,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "7193631a91ce4b82",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/bert-large-pruned80_quant-none-vnni-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.4308347276475",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 214.937,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "653b5dea093049a9",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50-none-vnni-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 90.40462194474198",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-14layer_pruned50_quant-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 360.571,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "a4463e1e740e4068",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-14layer_pruned50_quant-none-vnni-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.7887526723603",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-base_quant-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 213.347,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "6ff0ffc1bc064739",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.89066465550044",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "mobilebert-none-base-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 114.492,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "06669b9050b348b2",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/mobilebert-none-base-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 88.31078542237867",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-base-pruned90-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 97.3622,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "c8d9b76f95c94ad5",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-base-pruned90-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 89.65191480026783",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-base-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 11.9721,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "269d347d5c1b4b6c",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-base-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 90.17832662822171",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 38.4994,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "68dca0b85f564509",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95-none-vnni-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 90.0299132434367",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned95_quant-none-vnni-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 104.14,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "0f205e7c45c94c0a",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "F1: 90.1356467730578",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 40.0699,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "3d9b7086bc994230",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "F1: 90.17969189468576",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "obert-large-pruned97-quant-none-bert-99",
    "Organization": "NeuralMagic",
    "Platform": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config",
    "Result": 105.626,
    "Scenario": "Offline",
    "SystemName": "PCSPECIALIST AMD AM5",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "f01b288601174df8",
    "errors": 0,
    "framework": "deepsparse v1.5.2",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.1. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "N/A",
    "system.accelerator_memory_configuration": "N/A",
    "system.accelerator_model_name": "N/A",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "0",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "deepsparse v1.5.2",
    "system.host_memory_capacity": "128G",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 512 KiB (16 instances), L1i cache: 512 KiB (16 instances), L2 cache: 16 MiB (16 instances), L3 cache: 64 MiB (2 instances)",
    "system.host_processor_core_count": "16",
    "system.host_processor_frequency": "5881.0000",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "18T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-6.5.0-41-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, GCC-11.4.0",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.1. ",
    "system.system_name": "PCSPECIALIST AMD AM5",
    "system.system_type": "datacenter,edge",
    "system.system_type_detail": "workstation",
    "system_file_name": "phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned97-quant-none-bert-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "ROUGE1: 44.1411  ROUGE2: 21.8139  ROUGEL: 28.4395  TOKENS_PER_SAMPLE: 292.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NeuralMagic",
    "Platform": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 923.333,
    "Scenario": "Offline",
    "SystemName": "Crusoe Cloud L40S (8x L40S PCIe, vLLM)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "d807e0b4adb9407c",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "1.5T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.3 MiB (40 instances), L1i cache: 1.3 MiB (40 instances), L2 cache: 40 MiB (40 instances), L3 cache: 160 MiB (5 instances)",
    "system.host_processor_core_count": "4",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.3T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "Crusoe Cloud L40S (8x L40S PCIe, vLLM)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "ROUGE1: 44.1411  ROUGE2: 21.8139  ROUGEL: 28.4395  TOKENS_PER_SAMPLE: 292.9",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99.9/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NeuralMagic",
    "Platform": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 923.333,
    "Scenario": "Offline",
    "SystemName": "Crusoe Cloud L40S (8x L40S PCIe, vLLM)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "e859a3c3abaf4a65",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "1.5T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.3 MiB (40 instances), L1i cache: 1.3 MiB (40 instances), L2 cache: 40 MiB (40 instances), L3 cache: 160 MiB (5 instances)",
    "system.host_processor_core_count": "4",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.3T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "Crusoe Cloud L40S (8x L40S PCIe, vLLM)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99.9/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "ROUGE1: 41.6143  ROUGE2: 19.5677  ROUGEL: 26.4225  TOKENS_PER_SAMPLE: 296.6",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "neuralmagic_Llama-2-7b-chat-hf-FP8",
    "Organization": "NeuralMagic",
    "Platform": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 1989.1,
    "Scenario": "Offline",
    "SystemName": "Crusoe Cloud L40S (8x L40S PCIe, vLLM)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "10157d4f869148c0",
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen4 x16",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "48 GB",
    "system.accelerator_memory_configuration": "GDDR6",
    "system.accelerator_model_name": "NVIDIA L40S",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "8",
    "system.cooling": "air",
    "system.division": "open",
    "system.framework": "vLLM 0.5.2",
    "system.host_memory_capacity": "1.5T",
    "system.host_memory_configuration": "undefined",
    "system.host_network_card_count": "1",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "N/A",
    "system.host_processor_caches": "L1d cache: 1.3 MiB (40 instances), L1i cache: 1.3 MiB (40 instances), L2 cache: 40 MiB (40 instances), L3 cache: 160 MiB (5 instances)",
    "system.host_processor_core_count": "4",
    "system.host_processor_frequency": "undefined",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "6.3T",
    "system.host_storage_type": "SSD",
    "system.hw_notes": "",
    "system.number_of_nodes": "1",
    "system.operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "system.other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
    "system.status": "available",
    "system.submitter": "NeuralMagic",
    "system.sw_notes": "Automated by MLCommons CM v2.3.3. ",
    "system.system_name": "Crusoe Cloud L40S (8x L40S PCIe, vLLM)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "edge server",
    "system_file_name": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/neuralmagic_Llama-2-7b-chat-hf-FP8/offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NeuralMagic/systems/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config.json",
    "version": "v4.1",
    "weight_data_types": "fp32"
  },
  {
    "Accuracy": "ROUGE1: 42.9783  ROUGE2: 24.3368  ROUGEL: 31.4041  TOKENS_PER_SAMPLE: 164.6",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/H200-SXM-141GBx1_TRT_DepthPruned/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT_DepthPruned",
    "Result": 11189.1,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "c2b7612d94aa4864",
    "errors": 0,
    "framework": "CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (1x H200-SXM-141GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx1_TRT_DepthPruned.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NVIDIA/results/H200-SXM-141GBx1_TRT_DepthPruned/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NVIDIA/systems/H200-SXM-141GBx1_TRT_DepthPruned.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.280030560195446  FID_SCORE: 28.42806073285817",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/H200-SXM-141GBx1_TRT_LCM/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT_LCM",
    "Result": 10.7891,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "38078d0cc3334adc",
    "errors": 0,
    "framework": "CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (1x H200-SXM-141GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx1_TRT_LCM.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NVIDIA/results/H200-SXM-141GBx1_TRT_LCM/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NVIDIA/systems/H200-SXM-141GBx1_TRT_LCM.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "ROUGE1: 44.46  ROUGE2: 22.4526  ROUGEL: 29.9493  TOKENS_PER_SAMPLE: 234.4",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/H200-SXM-141GBx1_TRT_Sparse/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT_Sparse",
    "Result": 4575.06,
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "9fed7da170ed4cbc",
    "errors": 0,
    "framework": "CUDA 12.4",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "PCIe Gen5 x16",
    "system.accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "141 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "CUDA 12.4",
    "system.host_memory_capacity": "2 TB",
    "system.host_memory_configuration": "32x 64GB MTC40F2046S1RC48BA1",
    "system.host_network_card_count": "10x 400Gbe Infiniband",
    "system.host_networking": "Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "56",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "system.host_processors_per_node": "2",
    "system.host_storage_capacity": "2 TB SSD, 5 TB CIFS",
    "system.host_storage_type": "NVMe SSD, CIFS mounted disk storage",
    "system.hw_notes": "H200 TGP 700W",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.4",
    "system.other_hardware": "",
    "system.other_software_stack": "CUDA 12.4, Driver 550.54",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA H200 (1x H200-SXM-141GB)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "H200-SXM-141GBx1_TRT_Sparse.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NVIDIA/results/H200-SXM-141GBx1_TRT_Sparse/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NVIDIA/systems/H200-SXM-141GBx1_TRT_Sparse.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "ROUGE1: 43.2263  ROUGE2: 24.3279  ROUGEL: 31.3816  TOKENS_PER_SAMPLE: 166.3",
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/Orin_TRT_DepthPruned/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_DepthPruned",
    "Result": 184.893,
    "Scenario": "Offline",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "SystemType": "datacenter",
    "Units": "Tokens/s",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "b0a00ef1d4c44da0",
    "errors": 0,
    "framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Jetson r36.3.1 L4T",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "N/A",
    "system.accelerator_interconnect": "N/A",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "Shared with host",
    "system.accelerator_memory_configuration": "LPDDR5",
    "system.accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "eMMC 5.1",
    "system.disk_drives": "eMMC 5.1",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2",
    "system.host_memory_capacity": "64 GB",
    "system.host_memory_configuration": "64GB 256-bit LPDDR5",
    "system.host_network_card_count": "1 Integrated",
    "system.host_networking": "Gig Ethernet",
    "system.host_networking_topology": "USB forwarded",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "12",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "64 GB eMMC, 5TB CIFS",
    "system.host_storage_type": "eMMC 5.1, CIFS mounted disk storage",
    "system.hw_notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Jetson r36.3.1 L4T",
    "system.other_hardware": "",
    "system.other_software_stack": "Jetpack 6.0, TensorRT 10.1, CUDA 12.2, cuDNN 8.9.4",
    "system.power_management": "",
    "system.power_supply_details": "Dell USB-C 130.0W Adapter (HA130PM170)",
    "system.power_supply_quantity_and_rating_watts": "130W",
    "system.status": "available",
    "system.submitter": "NVIDIA",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "Orin_TRT_DepthPruned.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NVIDIA/results/Orin_TRT_DepthPruned/llama2-70b-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/NVIDIA/systems/Orin_TRT_DepthPruned.json",
    "version": "v4.1",
    "weight_data_types": "fp16"
  },
  {
    "Accuracy": "AUC: 80.166",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 62061.8,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "326734ebd0ef45ca",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.65, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "AUC: 80.233",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 40885.9,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "60f44b4f62844a4c",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.65, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "int8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.793520182073117  FID_SCORE: 23.416755634899232",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2.32815,
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "a2c4d2d95c374eac",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.65, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Offline",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  },
  {
    "Accuracy": "CLIP_SCORE: 31.78172011911869  FID_SCORE: 23.667417520141555",
    "Availability": "available",
    "Division": "open",
    "Location": "open/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "MlperfModel": "stable-diffusion-xl",
    "Model": "stable-diffusion-xl",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1.80046,
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "benchmark_branch": "main",
    "benchmark_name": "mlperf-inference",
    "benchmark_version": "4.1",
    "benchmark_version_alias": "4.1",
    "compliance": 1,
    "datetime_last_commit": "",
    "debug_uid": "4ed5761203604516",
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "system.accelerator_frequency": "",
    "system.accelerator_host_interconnect": "NVLink-C2C",
    "system.accelerator_interconnect": "1x 400Gbe Infiniband",
    "system.accelerator_interconnect_topology": "",
    "system.accelerator_memory_capacity": "96 GB",
    "system.accelerator_memory_configuration": "HBM3",
    "system.accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "system.accelerator_on-chip_memories": "",
    "system.accelerators_per_node": "1",
    "system.boot_firmware_version": "",
    "system.cooling": "Air-cooled",
    "system.disk_controllers": "NVMe",
    "system.disk_drives": "SSD",
    "system.division": "open",
    "system.filesystem": "",
    "system.framework": "TensorRT 9.3.0, CUDA 12.2",
    "system.host_memory_capacity": "512 GB",
    "system.host_memory_configuration": "16x 16DP (32GB) LPDDR5x",
    "system.host_network_card_count": "1x 10Gbe Intel Ethernet X550T",
    "system.host_networking": "Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s",
    "system.host_networking_topology": "Ethernet/Infiniband on switching network",
    "system.host_processor_caches": "",
    "system.host_processor_core_count": "72",
    "system.host_processor_frequency": "",
    "system.host_processor_interconnect": "",
    "system.host_processor_model_name": "NVIDIA Grace CPU",
    "system.host_processors_per_node": "1",
    "system.host_storage_capacity": "15 TB Block Volume",
    "system.host_storage_type": "NVMe SSD, Block storage",
    "system.hw_notes": "NVIDIA MGX Reference Platform;",
    "system.management_firmware_version": "",
    "system.network_speed_mbit": "",
    "system.nics_enabled_connected": "",
    "system.nics_enabled_firmware": "",
    "system.nics_enabled_os": "",
    "system.number_of_nodes": "1",
    "system.number_of_type_nics_installed": "",
    "system.operating_system": "Ubuntu 22.04.2",
    "system.other_hardware": "",
    "system.other_software_stack": "TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.65, DALI 1.28.0",
    "system.power_management": "",
    "system.power_supply_details": "",
    "system.power_supply_quantity_and_rating_watts": "",
    "system.status": "available",
    "system.submitter": "Oracle",
    "system.sw_notes": "",
    "system.system_name": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "system.system_type": "datacenter",
    "system.system_type_detail": "N/A",
    "system_file_name": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "url_repo": "https://github.com/mlcommons/inference_results_v4.1/tree/main",
    "url_result": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/stable-diffusion-xl/Server",
    "url_system_file": "https://github.com/mlcommons/inference_results_v4.1/tree/main/open/Oracle/systems/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT.json",
    "version": "v4.1",
    "weight_data_types": "fp8"
  }
]
